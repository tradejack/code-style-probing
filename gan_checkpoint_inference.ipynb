{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44753db5-cdb9-471b-8e5d-8406503e4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26c4dd7-21d4-45e1-98ff-700e26fc33ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0992, requires_grad=True), tensor(0.1858, requires_grad=True))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"checkpoint/codet5_gan_batch_8_1657908305_epoch_0.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd73514e-a6be-44a1-a744-05928c6b3408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0894, requires_grad=True), tensor(0.1721, requires_grad=True))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"checkpoint/codet5_gan_batch_8_1657908305_epoch_1.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00eea866-cd63-4cf1-b48e-ec434f0c1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1006, requires_grad=True), tensor(0.1726, requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"checkpoint/codet5_gan_batch_8_1657908305_epoch_2.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d41a8e-4623-4964-8d27-b4a21d1036d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0944, requires_grad=True), tensor(0.1727, requires_grad=True))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"checkpoint/codet5_gan_batch_8_1657908305_epoch_3.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c71518-00b7-48ea-927c-ae34dc3c65df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0991, requires_grad=True), tensor(0.1729, requires_grad=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"checkpoint/codet5_gan_batch_8_1657908305_epoch_4.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b18ce7-0020-4aef-8acd-205bdb3e4651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0503, requires_grad=True), tensor(0.0278, requires_grad=True))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"checkpoint/plbart_token_level_embed_with_new_loss_batch_8_1657011226_epoch_0.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f45f3052-92cf-4708-825f-6e7c53e503b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0648, requires_grad=True), tensor(0.0278, requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_with_new_loss_batch_8_1657011226_epoch_1.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ad32f5-5027-4296-bd7e-479e0c775be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0646, requires_grad=True), tensor(0.0278, requires_grad=True))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_with_new_loss_batch_8_1657011226_epoch_2.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a247a5f7-f6b5-452e-bd80-e1cb7b972dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0629, requires_grad=True), tensor(0.0277, requires_grad=True))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_with_new_loss_batch_8_1657011226_epoch_3.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf38fa64-6fc6-4396-8650-e01df59f9725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0180, requires_grad=True), tensor(0.0263, requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_batch_8_1656726351_epoch_4.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e3ee84-9471-4583-b874-e31cf69b083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0180, requires_grad=True), tensor(0.0263, requires_grad=True))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_batch_8_1656726351_epoch_5.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b34b04-3c0f-4038-ae21-22c619c25df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0180, requires_grad=True), tensor(0.0263, requires_grad=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_batch_8_1656726351_epoch_6.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f967f7b-cf4f-4539-a06d-d1798b644ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0180, requires_grad=True), tensor(0.0263, requires_grad=True))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_batch_8_1656726351_epoch_7.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e4595-4ef4-4bd6-8de4-2dc86d44fe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160b25a2-e7e3-41e8-a49f-72b5020f17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data import (\n",
    "    STYLE_DIM,\n",
    "    get_data_loader,\n",
    "    cluster_labels_no_outliers,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    ")\n",
    "\n",
    "from model import InRepPlusGAN, Discriminator\n",
    "\n",
    "generator = InRepPlusGAN(style_dim=STYLE_DIM)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e6c86-7f29-4edf-ba81-b0d3be5b2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(\n",
    "        vocab_size=generator.config.vocab_size,\n",
    "        embedding_layer=generator.encoder.embed_tokens,\n",
    "        embedding_dim=generator.config.d_model,\n",
    "        output_size=128,\n",
    "        style_dim=STYLE_DIM,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1afcc36-3344-4b70-97eb-c45972752bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5104809-3953-45d2-bae4-3850b90733e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = tokenizer([\"def hello_world(): print('Hello World')\"], padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03626c89-240e-40cc-92b2-601a2130f9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d92d5817-4755-4a23-9362-af6e0a938ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import label_tensor_to_one_hot\n",
    "\n",
    "style_encoding = label_tensor_to_one_hot(\n",
    "    torch.Tensor([17]).long(), STYLE_DIM\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c8ac74f1-f039-4511-8934-4a00969fe673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b3d09b4c-59c6-4380-b3e9-c5bc9a141ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_inference(ckpt, input_batch):\n",
    "    PATH = ckpt\n",
    "    checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "    generator = InRepPlusGAN(style_dim=STYLE_DIM)#.to(device)\n",
    "    generator.load_state_dict(checkpoint['g_state_dict'])\n",
    "    generator_output, modifier_output = generator(\n",
    "        input_ids=input_batch[\"input_ids\"],\n",
    "        attention_mask=input_batch[\"attention_mask\"],\n",
    "        style_encoding=style_encoding,\n",
    "    )\n",
    "    generated_tokens = generator_output.logits.argmax(-1)\n",
    "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c9278382-80db-44f3-b048-27d01d51f3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Salesforce/codet5-base/resolve/main/config.json from cache at /data/users/cting3/.cache/huggingface/transformers/f1adf9032ebe26d0dd0b9c4917416e2db960b7e8b8e68f0612e8e5d5379488f5.20220fde7ff6c94c24bdcd615678f6a4374f3176abdc061beecc43a906725837\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/CodeT5/pretrained_models/codet5_base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Salesforce/codet5-base/resolve/main/pytorch_model.bin from cache at /data/users/cting3/.cache/huggingface/transformers/1afeeca5d5f5a78dca99d501138e9d6ffc6ff52d8048459ca67b3752e7b4d325.200e87e8e909da91038103a5ef6266da8d95a33855e53ec2031712515063c45c\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Salesforce/codet5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "output = checkpoint_inference(\"checkpoint/codet5_gan_full_no_outliers_batch_8_1657914615_epoch_1.pt\", input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a7bc4712-e269-4bba-adc3-bf6ce45796f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " objective fed receiver fedXpath receiver receiver receiver receiver receiver receiver objective objective fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed receiver receiver receiver receiver receiver receiver receiver fed fed receiver fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed fed\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d231e002-b208-4f20-8656-f0620855fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file results_codet5/checkpoint-21000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Salesforce/codet5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file results_codet5/checkpoint-21000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at results_codet5/checkpoint-21000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"results_codet5/checkpoint-21000\", num_labels=26).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c346a1d6-e0d0-4d2d-9047-c9b0e051db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = tokenizer(output, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e6f46fd9-fb4f-4257-916f-56a2144b3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, T5ForConditionalGeneration\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    "    #data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9061f1e-ef67-4aeb-b7f2-2f12cb87b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc8d9ce7-0cb0-4a7c-819a-d2ad402ab058",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch[\"labels\"] = [[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "86ec6ef8-3346-4260-8a46-dce055395087",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_set = Dataset.from_dict(output_batch)\n",
    "# infer_set, infer_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a38612d4-5e75-4962-8a6e-4682bf21c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[19]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = trainer.predict(infer_set)\n",
    "logits, labels, inputs = pred\n",
    "predictions = np.argmax(logits[0], axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cd9ea9e8-1ad3-4348-b87a-71ee016902d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "31c98ade-8a4e-49ee-95b7-47bd0cce3746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26c8a556-59fc-401d-a4a3-61d365a0252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_pred): # this part prob wont work, parameter should be removed from trainer probably\n",
    "    try:\n",
    "        logits, labels, inputs = eval_pred\n",
    "    except:\n",
    "        logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits[0], axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dcdad2e2-a10e-4980-bb49-58485e57176c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [103]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [102]\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m     logits, labels \u001b[38;5;241m=\u001b[39m eval_pred\n\u001b[1;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetric\u001b[49m\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metric' is not defined"
     ]
    }
   ],
   "source": [
    "compute_metrics(pred.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c9b18-5227-4754-a04c-6267f9a571d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generator = InRepPlusGAN(style_dim=STYLE_DIM)#.to(device)\n",
    "# generator.load_state_dict(checkpoint['g_state_dict'])\n",
    "generator_output, modifier_output = generator(\n",
    "    input_ids=input_batch[\"input_ids\"],\n",
    "    attention_mask=input_batch[\"attention_mask\"],\n",
    "    style_encoding=style_encoding,\n",
    ")\n",
    "generated_tokens = generator_output.logits.argmax(-1)\n",
    "generated_text_batch = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "generated_text_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5abb20-b7c6-41da-9f57-d9b1e32bb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generated_text_batch = tokenizer.batch_decode(generated_tokens)\n",
    "generated_input_batch = tokenizer(generated_text_batch, max_length=1024, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ff4e87-ac48-44cf-bdd9-9d5e49a0fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_encoding = generator.get_encoding(**generated_input_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "482960e8-cf2f-4b2b-8793-54c56555f5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c9d34e-0243-41e0-b1c8-3ef01a72de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1696, -0.1361,  0.1512,  ...,  0.1206, -0.0296,  0.1654],\n",
       "         [-0.2737,  0.4388,  0.0367,  ..., -0.3705,  0.0986,  0.9460],\n",
       "         [-0.2157, -0.9253,  1.1519,  ..., -0.0858,  0.1850,  0.9281],\n",
       "         ...,\n",
       "         [ 1.0032, -1.0735, -0.1932,  ...,  1.2176,  1.2246,  0.0746],\n",
       "         [ 0.8282, -1.1856, -0.1770,  ...,  1.2326,  1.4042,  0.1314],\n",
       "         [ 0.8852, -1.1173, -0.2209,  ...,  1.2250,  1.3229,  0.1277]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f1222-475b-460e-a86c-9b361c292d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ae24f8-aa70-4d4c-8df4-14cbd15a077e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-620000e28d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInRepPlusGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTYLE_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m generator_output, modifier_output = generator(\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = InRepPlusGAN(style_dim=STYLE_DIM)#.to(device)\n",
    "generator.load_state_dict(checkpoint['g_state_dict'])\n",
    "generator_output, modifier_output = generator(\n",
    "    input_ids=input_batch[\"input_ids\"],\n",
    "    attention_mask=input_batch[\"attention_mask\"],\n",
    "    style_encoding=style_encoding,\n",
    ")\n",
    "generated_tokens = generator_output.logits.argmax(-1)\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce799db-2325-4463-8669-7ee98011d7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, hidden_dim = modifier_output.shape\n",
    "modifier_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c563425-dcc6-4f2d-85bd-81917317e6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 786432])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifier_output.view(batch_size, seq_len*hidden_dim).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8aec65e-69d8-4510-8f96-0400845bedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim = torch.nn.CosineSimilarity(dim=-1, eps=1e-08)(generated_encoding, modifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b6645c-6104-4444-b850-59bc72583e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0402, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-cossim.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7663f94a-af92-440b-96e2-05adbb1aa081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0503, requires_grad=True), tensor(0.0278, requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"checkpoint/plbart_token_level_embed_with_new_loss_batch_8_1657011226_epoch_0.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "checkpoint[\"g_loss\"], checkpoint[\"d_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d5a4f63-daf0-4ede-a49a-41edb2bee065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return return']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "generator = InRepPlusGAN(style_dim=STYLE_DIM)#.to(device)\n",
    "generator.load_state_dict(checkpoint['g_state_dict'])\n",
    "generator_output, modifier_output = generator(\n",
    "    input_ids=input_batch[\"input_ids\"],\n",
    "    attention_mask=input_batch[\"attention_mask\"],\n",
    "    style_encoding=style_encoding,\n",
    ")\n",
    "generated_tokens = generator_output.logits.argmax(-1)\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d338e14d-186e-42e0-a21f-17ef1d7eccfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_output.logits.argmax(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93dd2e1-21a5-4277-a007-290bba2e1fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from data import train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "825834bb-18f7-4d6d-955e-7b3d341a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c62bb6-fbc8-47c9-892a-b585be625783",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(train_dataset[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eba45db6-9dc6-43d9-b42e-1392e8b87131",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = train_dataset[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d095873f-c793-4051-86db-af071363a666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# coding: utf-8 \"\"\" Wavefront REST API <p>The Wavefront REST API enables you to interact with Wavefront servers using standard REST API tools. You can use the REST API to automate commonly executed operations such as automatically tagging sources.</p><p>When you make REST API calls outside the Wavefront REST API documentation you must add the header \\\\\"Authorization: Bearer &lt;&lt;API-TOKEN&gt;&gt;\\\\\" to your HTTP requests.</p> # noqa: E501 OpenAPI spec version: v2 Contact: chitimba@wavefront.com Generated by: https://github.com/swagger-api/swagger-codegen.git \"\"\" from __future__ import absolute_import import unittest import wavefront_api_client from wavefront_api_client.models.service_account import ServiceAccount # noqa: E501 from wavefront_api_client.rest import ApiException class TestServiceAccount(unittest.TestCase): \"\"\"ServiceAccount unit test stubs\"\"\" def setUp(self): pass def tearDown(self): pass def testServiceAccount(self): \"\"\"Test ServiceAccount\"\"\" # FIXME: construct object with mandatory attributes with example values # model = wavefront_api_client.models.service_account.ServiceAccount() # noqa: E501 pass if __name__ == \\'__main__\\': unittest.main()']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([example], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e62526-2e69-43aa-bff7-26139ae0558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import label_tensor_to_one_hot\n",
    "\n",
    "style_encoding = label_tensor_to_one_hot(\n",
    "    torch.Tensor([1]).long(), STYLE_DIM\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99d7cb8-7c96-4c48-8ee8-4b9f6a360efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# coding: utf-8 \"\"\" Wavefront REST API <p>The Wavefront REST API enables you to interact with Wavefront servers using standard REST API tools. You can use the REST API to automate commonly executed operations such as automatically tagging sources.</p><p>When you make REST API calls outside the Wavefront REST API documentation you must add the header \\\\\"Authorization: Bearer &lt;&lt;API-TOKEN&gt;&gt;\\\\\" to your HTTP requests.</p> # noqa: E501 OpenAPI spec version: v2 Contact: chitimba@wavefront.com Generated by: https://github.com/swagger-api/swagger-codegen.git \"\"\" from __future__ import absolute_import import unittest import wavefront_api_client from wavefront_api_client.models.service_account import ServiceAccount # noqa: E501 from wavefront_api_client.rest import ApiException class TestServiceAccount(unittest.TestCase): \"\"\"ServiceAccount unit test stubs\"\"\" def setUp(self): pass def tearDown(self): pass def testServiceAccount(self): \"\"\"Test ServiceAccount\"\"\" # FIXME: construct object with mandatory attributes with example values # model = wavefront_api_client.models.service_account.ServiceAccount() # noqa: E501 pass if __name__ == \\'__main__\\': unittest.main()']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([example], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dc831b2-175e-4ed6-864b-ca27d735f54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 not 0 0 not not 0 not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not 0 0 0 0 0 0 0 0 0 0 not 0 not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 not not 0 not 0 0 0 not 0 not 0 not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 not 0 0 0 0 0 0 not not not not not not not not not not not not not not not not not not not not not not not not not not not not not 0 0 not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 not not not not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 not not not not 0 0 not not not not 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "style_encoding = label_tensor_to_one_hot(\n",
    "    torch.Tensor([17]).long(), STYLE_DIM\n",
    ")#.to(device)\n",
    "\n",
    "generator = InRepPlusGAN(style_dim=STYLE_DIM)#.to(device)\n",
    "generator.load_state_dict(checkpoint['g_state_dict'])\n",
    "generator_output, modifier_output = generator(\n",
    "    input_ids=torch.Tensor(example).long().unsqueeze(0),\n",
    "    # attention_mask=input_batch[\"attention_mask\"],\n",
    "    style_encoding=style_encoding,\n",
    ")\n",
    "generated_tokens = generator_output.logits.argmax(-1)\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff8564-a93e-4d5f-91dc-0a4790424551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
