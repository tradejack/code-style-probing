{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from pydoc import doc\n",
    "import re \n",
    "import os\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle combined py150k + bq datasets\n",
    "#py150\n",
    "#rerun this with identifiers so I can tell which metrics to which script\n",
    "py150k_df = pd.read_csv(\"data/py150k_metric_20220524.csv\")\n",
    "bigquery_df = pd.read_csv(\"data/bigquery_metric_20220526.csv\")\n",
    "\n",
    "combined_df = pd.concat([py150k_df, bigquery_df], axis = 0) # ignore_index = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215050\n"
     ]
    }
   ],
   "source": [
    "#internal metrics are generated now and everything is stored in dataframe should be ready for clustering\n",
    "target_features = [\"comment_density\", \"snake_case_ratio\", \"lower_camel_case_ratio\", \"upper_camel_case_ratio\", \"func_decorators_avg\", \"class_decorators_avg\",\n",
    " \"ds_density\", \"class_parents_ratio\"]\n",
    "target_features = [\n",
    "    \"snake_case_var_ratio\", \n",
    "    \"snake_case_method_ratio\",\n",
    "    \"snake_case_class_ratio\",\n",
    "    \"upper_camel_case_var_ratio\",\n",
    "    \"upper_camel_case_method_ratio\",\n",
    "    \"upper_camel_case_class_ratio\",\n",
    "    \"lower_camel_case_var_ratio\",\n",
    "    \"lower_camel_case_method_ratio\",\n",
    "    \"lower_camel_case_class_ratio\",\n",
    "    \"func_decorators_avg\",\n",
    "    \"class_decorators_avg\",\n",
    "    \"class_parents_avg\",\n",
    "    \"ds_density\",\n",
    "    \"comment_density\",\n",
    "    \"comprehensions_avg\",\n",
    "    \"generators_avg\",\n",
    "    \"lambda_avg\",\n",
    "]\n",
    "#add generators \n",
    "\n",
    "#store params and dataframe for reproducability\n",
    "\n",
    "#change feature set to store as a different experiment\n",
    "feature_set = 'feature_set_1'\n",
    "min_samples = 100\n",
    "min_cluster_size = 500\n",
    "cluster_selection_epsilon = 0.01\n",
    "#get filename and the features\n",
    "\n",
    "clean_metrics_df = combined_df\n",
    "X = clean_metrics_df[target_features].to_numpy()\n",
    "X = np.nan_to_num(X, nan=0)\n",
    "\n",
    "print (len(clean_metrics_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle\n",
    "\n",
    "#clustering = DBSCAN(eps=3, min_samples=2)\n",
    "#clustering.fit_predict(X)\n",
    "\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_samples=min_samples, min_cluster_size=min_cluster_size, \n",
    "                            cluster_selection_epsilon=cluster_selection_epsilon, prediction_data=True).fit(X)\n",
    "print(len(clusterer.labels_))\n",
    "with open(f'data/combined_dataset/clusters/{feature_set}/full_feature_clusterer.pickle', 'wb') as handle:\n",
    "    pickle.dump(clusterer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "color_palette = sns.color_palette('Paired', 110000)\n",
    "print(len(color_palette))\n",
    "\n",
    "cluster_colors = [color_palette[x] if x >= 0\n",
    "                  else (0.5, 0.5, 0.5)\n",
    "                  for x in clusterer.labels_]\n",
    "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                         zip(cluster_colors, clusterer.probabilities_)]\n",
    "\n",
    "#save hyperparams + meta info for experiment\n",
    "with open(f'data/combined_dataset/clusters/{feature_set}/feature_list_params.txt', 'w') as f:\n",
    "    f.write(f\"Hyperparameters: min_samples={min_samples}, min_cluster_size={min_cluster_size}, \\\n",
    "        cluster_selection_epsilon={cluster_selection_epsilon}, prediction_data=True\\n\")\n",
    "    f.write(\"Features:\\n\")\n",
    "    for item in target_features:\n",
    "        f.write(f\"{item}\\n\")\n",
    "    f.write(f\"Full feature cluster count: {len(set(clusterer.labels_))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = TSNE().fit_transform(X)\n",
    "#open with np.loadtxt\n",
    "np.savetxt(f'data/combined_dataset/clusters/{feature_set}/projection.txt', projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"number of clusters\", len(set(clusterer.labels_)))\n",
    "print (set(clusterer.labels_))\n",
    "#print (*projection.T)\n",
    "\n",
    "plt.scatter(*projection.T, s=50, linewidth=0, c=cluster_member_colors, alpha=0.25)\n",
    "plt.title(\"full_feature_cluster\")\n",
    "plt.savefig(f\"data/combined_dataset/clusters/{feature_set}/plots/full_feature_clusterer.jpg\")\n",
    "\n",
    "\n",
    "X = clean_metrics_df[target_features].to_numpy()\n",
    "X = np.nan_to_num(X, nan=0)\n",
    "\n",
    "#clean_metrics_df[target_features].to_csv(f'example_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "#clustering = DBSCAN(eps=3, min_samples=2)\n",
    "#clustering.fit_predict(X)\n",
    "feature_pairs = list(combinations(target_features, 2))\n",
    "print (len(feature_pairs))\n",
    "#feature_pairs = [feature_pairs[0]]\n",
    "for pair in feature_pairs:\n",
    "    feat_x = pair[0]\n",
    "    feat_y = pair[1]\n",
    "    #feature pair\n",
    "    feature_pair = clean_metrics_df[list(pair)].to_numpy()\n",
    "    feature_pair = np.nan_to_num(feature_pair, nan=0)\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(min_samples=50, min_cluster_size=1000, cluster_selection_epsilon=0.01, prediction_data=True).fit(feature_pair)\n",
    "    #save clusterer\n",
    "    with open(f'data/combined_dataset/clusters/{feature_set}/{feat_x}-{feat_y}_clusterer.pickle', 'wb') as handle:\n",
    "        pickle.dump(clusterer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    color_palette = sns.color_palette('Paired', 110000)\n",
    "    #print(len(color_palette))\n",
    "\n",
    "    cluster_colors = [color_palette[x] if x >= 0\n",
    "                    else (0.5, 0.5, 0.5)\n",
    "                    for x in clusterer.labels_]\n",
    "    cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                            zip(cluster_colors, clusterer.probabilities_)]\n",
    "\n",
    "    print (f\"{feat_x}-{feat_y}_clusterer\")\n",
    "    print (\"number of clusters\", len(set(clusterer.labels_)))\n",
    "    plt.scatter(*feature_pair.T, s=50, linewidth=0, c=cluster_member_colors, alpha=0.25)\n",
    "    plt.title(f\"{feat_x}-{feat_y}, {len(set(clusterer.labels_))} clusters\")\n",
    "    plt.xlabel(f\"{feat_x}\")\n",
    "    plt.ylabel(f\"{feat_y}\")\n",
    "    plt.savefig(f\"data/combined_dataset/clusters/{feature_set}/plots/{feat_x}-{feat_y}_clusterer.jpg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac9e7467ab50678fb25b34fbfebaa7dd0935f663e602be01974fdf6c9ce75ada"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
