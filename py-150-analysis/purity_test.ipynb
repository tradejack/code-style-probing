{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94e841b-d210-40e5-8e77-df27bbd881cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from tsnecuda import TSNE\n",
    "# install T-SNE with cuda => 10x faster, highly recommended if running in CUDA machine\n",
    "# !conda install tsnecuda -c conda-forge -y\n",
    "\n",
    "# !pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8e9652-f2fe-494e-9faa-b69c01e15ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type_map = {}\n",
    "with open('user_type_map.json') as json_file:\n",
    "    user_type_map = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82589c05-f56b-4121-9930-1d64a60e0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_repo_feat(data_df):\n",
    "    return data_df.apply(\n",
    "        lambda row: f\"{row['user_name']}/{row['repo_name']}\", axis=1\n",
    "    ).tolist()\n",
    "\n",
    "\n",
    "def get_watch_count_feat(data_df):\n",
    "    watch_count = (\n",
    "        pd.read_csv(\"../data/watch_count_public_data.csv\")\n",
    "        .rename(columns={\"repo_name\": \"user/repo\"})\n",
    "        .drop(columns=\"Record Count\")\n",
    "    )\n",
    "    return data_df.join(watch_count.set_index(\"user/repo\"), on=\"user/repo\")[\n",
    "        \"watch_count\"\n",
    "    ].tolist()\n",
    "\n",
    "\n",
    "\n",
    "def get_user_repo_by_file_name(file_name):\n",
    "    # get the repo and username from script file name\n",
    "    script_file_name_regex = re.compile(r\"data/([^/]+)/([^/]+)/.+\")\n",
    "    match = script_file_name_regex.search(file_name)\n",
    "    username = match.group(1)\n",
    "    repo_name = match.group(2)\n",
    "    return username, repo_name\n",
    "\n",
    "def read_py150k_code(filename, limit=None):\n",
    "    filenames = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            filenames += [line.strip()]\n",
    "            if limit and len(filenames) >= limit:\n",
    "                break\n",
    "\n",
    "    return filenames\n",
    "\n",
    "PY150K_TRAIN_CODE = \"../data/py150/py150_files/python100k_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba885957-c2ec-4e4f-ac09-07a65cb78640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_freq_users(user_freq_dist, freq_thresh = 1000):\n",
    "    users = []\n",
    "    for user, freq in user_freq_dist:\n",
    "        if freq < freq_thresh: continue\n",
    "        users += [user]\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f215262-9ff1-4113-a7f6-c8f6c86915ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# sample code for loading Py150k code\n",
    "code_filenames = read_py150k_code(PY150K_TRAIN_CODE)\n",
    "u_list = []\n",
    "r_list = []\n",
    "for name in code_filenames:\n",
    "    username, repo_name = get_user_repo_by_file_name(name)\n",
    "    u_list += [username]\n",
    "    r_list += [repo_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5edff897-951b-4de8-a4d0-e2f6443a2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/py150k_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934c5026-82ea-45a3-8239-338ee98f4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = data.copy()\n",
    "train_data_df[\"user_name\"] = u_list\n",
    "train_data_df[\"repo_name\"] = r_list\n",
    "train_data_df[\"user/repo\"] = get_user_repo_feat(train_data_df)\n",
    "train_data_df[\"user_type\"] = [user_type_map[u] for u in u_list]\n",
    "train_data_df[\"watch_count\"] = get_watch_count_feat(train_data_df)\n",
    "train_plot_df = train_data_df.dropna(subset=[\"watch_count\"])\n",
    "train_data_df_user_only = train_data_df[train_data_df[\"user_type\"] == \"User\"]\n",
    "train_data_df_org_only = train_data_df[train_data_df[\"user_type\"] == \"Organization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304538f1-f3b0-4bd4-be75-63d19cf15698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_clusters(sample_df, labels):\n",
    "    sample_size = len(sample_df)\n",
    "    labels_cat = np.unique(labels)\n",
    "    prob_dist = {k:v/sample_size for k,v in dict(Counter(labels)).items()}\n",
    "    results = []\n",
    "    return np.random.choice(labels_cat, sample_size, p=[prob_dist[l] for l in labels_cat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade3edca-b784-48d3-8677-88f1c3954354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rules = [\n",
    " 'snake_case_var_ratio',\n",
    " 'snake_case_class_ratio',\n",
    " 'snake_case_method_ratio',\n",
    " 'upper_camel_case_var_ratio',\n",
    " 'upper_camel_case_class_ratio',\n",
    " 'upper_camel_case_method_ratio',\n",
    " 'lower_camel_case_var_ratio',\n",
    " 'lower_camel_case_class_ratio',\n",
    " 'lower_camel_case_method_ratio',\n",
    " 'func_decorators_avg',\n",
    " 'class_decorators_avg',\n",
    " 'class_parents_avg',\n",
    " 'comprehensions_avg',\n",
    " 'generators_avg',\n",
    " 'lambda_avg',\n",
    " 'comment_density',\n",
    " 'ds_density',\n",
    "]\n",
    "len(full_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb52782-2af0-4759-891f-359a3ba683da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_columns(data, rules):\n",
    "    columns = data.columns\n",
    "    results = set()\n",
    "    for col in columns:\n",
    "        match_flag = True\n",
    "        \n",
    "        for rule in rules:\n",
    "            match_flag = rule in col and match_flag\n",
    "        \n",
    "        if match_flag:    \n",
    "            results.add(col)\n",
    "    return results\n",
    "\n",
    "id_subset = get_filtered_columns(data, [\"case\"]).union(get_filtered_columns(data, [\"id\"]))\n",
    "case_ratio_subset = get_filtered_columns(data, [\"case\", \"ratio\"])\n",
    "normalized_subset = get_filtered_columns(data, [\"ratio\"])\n",
    "density_subset = get_filtered_columns(data, [\"density\"])\n",
    "full_subset = set()\n",
    "for rule in full_rules:\n",
    "    full_subset = full_subset.union(get_filtered_columns(data, [rule]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a081d6-30a8-4487-ba9a-226bb5defc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def purity(cluster_labels, gold_labels):\n",
    "    cluster_num = np.unique(cluster_labels).shape[0]\n",
    "    cluster_sets = {}\n",
    "    for cluster_label in np.unique(cluster_labels):\n",
    "        cluster_sets[cluster_label] = []\n",
    "    \n",
    "    for idx, cluster_label in enumerate(cluster_labels):\n",
    "        cluster_sets[cluster_label].append(gold_labels[idx])\n",
    "    \n",
    "    total_correct_pred = 0\n",
    "    for c in np.unique(cluster_labels):\n",
    "        label_counter = Counter(cluster_sets[c])\n",
    "        pred_label, _ = label_counter.most_common(1)[0]\n",
    "        total_correct_pred += label_counter[pred_label]\n",
    "    \n",
    "    purity = total_correct_pred / len(cluster_labels)\n",
    "    \n",
    "    return purity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09df3b9c-4d91-4024-89c1-80cf08b3de64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tav', 852),\n",
       " ('anandology', 435),\n",
       " ('CollabQ', 397),\n",
       " ('kuri65536', 391),\n",
       " ('azoft-dev-team', 329),\n",
       " ('jmcnamara', 309),\n",
       " ('RoseOu', 234),\n",
       " ('cool-RR', 229),\n",
       " ('dcramer', 221),\n",
       " ('kayhayen', 211),\n",
       " ('babble', 200),\n",
       " ('rwl', 199),\n",
       " ('daviddrysdale', 197),\n",
       " ('nlloyd', 194),\n",
       " ('powdahound', 181),\n",
       " ('Akagi201', 157),\n",
       " ('benoitc', 150),\n",
       " ('lsaffre', 149),\n",
       " ('amrdraz', 147),\n",
       " ('spulec', 145)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "user_counter = Counter(train_data_df_user_only[\"user_name\"])\n",
    "user_freq_dist = user_counter.most_common(20)[:]\n",
    "selected_users = get_high_freq_users(user_freq_dist, 0)\n",
    "user_to_idx = {user:idx for idx, user in enumerate(selected_users)}\n",
    "user_bool = train_data_df['user_name'].apply(lambda user: user in selected_users)\n",
    "user_freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a13723-df6d-47f7-b46a-30189fa53200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/xv13qnjd0hq2t8887xc0bmx80000gn/T/ipykernel_38968/3676517837.py:6: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X = sample[subset]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5327, 87)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data_df[user_bool].loc[:]\n",
    "author_class = sample[\"user_name\"].apply(lambda user: user_to_idx[user]).to_numpy()\n",
    "\n",
    "\n",
    "subset = full_subset\n",
    "X = sample[subset]\n",
    "\n",
    "len(sample), len(sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6022cf05-1299-404f-a7f7-5e31336674e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.160503097428196"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_clusters = random_sample_clusters(sample, author_class)\n",
    "purity(baseline_clusters, author_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbec5ece-ac0f-497a-b9ff-ef2b14860f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 10\n",
      "purity:  0.25098554533508544\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 6\n",
      "purity:  0.2348413741317815\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 6\n",
      "purity:  0.2370940491834053\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 6\n",
      "purity:  0.2370940491834053\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.16932607471372255\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 1\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 9\n",
      "purity:  0.2487328702834616\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 6\n",
      "purity:  0.2348413741317815\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 6\n",
      "purity:  0.2370940491834053\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 6\n",
      "purity:  0.2370940491834053\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.16932607471372255\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 1\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 9\n",
      "purity:  0.2487328702834616\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 6\n",
      "purity:  0.2348413741317815\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 6\n",
      "purity:  0.2370940491834053\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 6\n",
      "purity:  0.2370940491834053\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.16932607471372255\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 1\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 5\n",
      "purity:  0.16932607471372255\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.15993992866529003\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 1\n",
      "purity:  0.15993992866529003\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "# External Evaluation of Purity on Author\n",
    "\n",
    "min_samples_sizes = [50, 100, 500, 1000]\n",
    "min_cluster_sizes = [50, 100, 500, 1000]\n",
    "epslons = [0.01, 0.05, 0.1, 0.5]#np.linspace(0, 1, 3, endpoint=True)\n",
    "min_samples_params = []\n",
    "min_cluster_size_params = []\n",
    "epsilon_params = []\n",
    "cluster_nums = []\n",
    "purities = []\n",
    "for e in epslons:\n",
    "    for m in min_samples_sizes:\n",
    "        for n in min_cluster_sizes:\n",
    "            ep = round(float(e),2)\n",
    "            clusterer = hdbscan.HDBSCAN(min_samples=int(m), min_cluster_size=int(n), cluster_selection_epsilon = ep, prediction_data=True).fit(X.to_numpy())\n",
    "            cluster_num = np.unique(clusterer.labels_).shape[0]\n",
    "            p = purity(clusterer.labels_, author_class)\n",
    "            \n",
    "            print(\"min_samples\", int(m))\n",
    "            print(\"min_cluster_size\", int(n))\n",
    "            print(\"epsilon\", ep)\n",
    "            print(\"cluster num\", cluster_num)\n",
    "            print(\"purity: \", p)\n",
    "            print(\"========================\")\n",
    "            \n",
    "            min_samples_params += [int(m)]\n",
    "            min_cluster_size_params += [int(n)]\n",
    "            epsilon_params += [ep]\n",
    "            cluster_nums += [cluster_num]\n",
    "            purities += [p]\n",
    "            \n",
    "pd.DataFrame({\n",
    "    \"min_sample\": min_samples_params,\n",
    "    \"min_cluster_size\": min_cluster_size_params,\n",
    "    \"epsilon\": epsilon_params,\n",
    "    \"cluster_num\": cluster_nums,\n",
    "    \"purity\": purities,\n",
    "}).to_csv(\"purity_author_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3129302f-8e72-4d9c-83b1-e9a41a074ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anhstudios', 5069),\n",
       " ('openstack', 3111),\n",
       " ('AppScale', 1898),\n",
       " ('cloudera', 1033),\n",
       " ('dropbox', 805),\n",
       " ('dimagi', 785),\n",
       " ('mozilla', 753),\n",
       " ('GoogleCloudPlatform', 712),\n",
       " ('enthought', 700),\n",
       " ('google', 621),\n",
       " ('django', 606),\n",
       " ('saltstack', 593),\n",
       " ('BU-NU-CLOUD-SP16', 501),\n",
       " ('getsentry', 439),\n",
       " ('Azure', 438),\n",
       " ('CenterForOpenScience', 433),\n",
       " ('StackStorm', 417),\n",
       " ('fp7-ofelia', 343),\n",
       " ('freenas', 325),\n",
       " ('sympy', 315)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_counter = Counter(train_data_df_org_only[\"user_name\"])\n",
    "org_freq_dist = org_counter.most_common(20)[:]\n",
    "selected_orgs = get_high_freq_users(org_freq_dist, 0)\n",
    "org_to_idx = {org:idx for idx, org in enumerate(selected_orgs)}\n",
    "org_bool = train_data_df['user_name'].apply(lambda org: org in selected_orgs)\n",
    "org_freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78d47cff-bce7-47ad-a662-e2235a13a46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/xv13qnjd0hq2t8887xc0bmx80000gn/T/ipykernel_38968/914625274.py:6: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X = sample[subset]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19897, 87)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data_df[org_bool].loc[:]\n",
    "org_class = sample[\"user_name\"].apply(lambda org: org_to_idx[org]).to_numpy()\n",
    "\n",
    "\n",
    "subset = full_subset\n",
    "X = sample[subset]\n",
    "\n",
    "len(sample), len(sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22a335f-2255-49ea-89d8-7827f6dada9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2547620244257928"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_clusters = random_sample_clusters(sample, org_class)\n",
    "purity(baseline_clusters, org_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ba3554e-9dec-4741-ada6-9270b820566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 18\n",
      "purity:  0.42820525707393076\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 9\n",
      "purity:  0.4213197969543147\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.41061466552746645\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.41061466552746645\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 9\n",
      "purity:  0.42116902045534504\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 9\n",
      "purity:  0.42116902045534504\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.41006181836457756\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.41006181836457756\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.4072473237171433\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.01\n",
      "cluster num 5\n",
      "purity:  0.4072473237171433\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.01\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 14\n",
      "purity:  0.42860732773784993\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 8\n",
      "purity:  0.4215208322862743\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.41061466552746645\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.41061466552746645\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 9\n",
      "purity:  0.42116902045534504\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 9\n",
      "purity:  0.42116902045534504\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.41006181836457756\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.41006181836457756\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.4072473237171433\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.05\n",
      "cluster num 5\n",
      "purity:  0.4072473237171433\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.05\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 13\n",
      "purity:  0.42860732773784993\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 8\n",
      "purity:  0.4215208322862743\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.41061466552746645\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.41061466552746645\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 8\n",
      "purity:  0.42071669095843595\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 8\n",
      "purity:  0.42071669095843595\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.41006181836457756\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.41006181836457756\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.4127757953460321\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.4072473237171433\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.1\n",
      "cluster num 5\n",
      "purity:  0.4072473237171433\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.1\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.3771422827561944\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.3771422827561944\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.3771422827561944\n",
      "========================\n",
      "min_samples 50\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.3771422827561944\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.37824797708197216\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.37824797708197216\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.37824797708197216\n",
      "========================\n",
      "min_samples 100\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.37824797708197216\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 500\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38251997788611347\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 50\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 100\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 500\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n",
      "min_samples 1000\n",
      "min_cluster_size 1000\n",
      "epsilon 0.5\n",
      "cluster num 3\n",
      "purity:  0.38161531889229533\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "# External Evaluation of Purity on Author\n",
    "\n",
    "min_samples_sizes = [50, 100, 500, 1000]\n",
    "min_cluster_sizes = [50, 100, 500, 1000]\n",
    "epslons = [0.01, 0.05, 0.1, 0.5]#np.linspace(0, 1, 3, endpoint=True)\n",
    "min_samples_params = []\n",
    "min_cluster_size_params = []\n",
    "epsilon_params = []\n",
    "cluster_nums = []\n",
    "purities = []\n",
    "for e in epslons:\n",
    "    for m in min_samples_sizes:\n",
    "        for n in min_cluster_sizes:\n",
    "            ep = round(float(e),2)\n",
    "            clusterer = hdbscan.HDBSCAN(min_samples=int(m), min_cluster_size=int(n), cluster_selection_epsilon = ep, prediction_data=True).fit(X.to_numpy())\n",
    "            cluster_num = np.unique(clusterer.labels_).shape[0]\n",
    "            p = purity(clusterer.labels_, org_class)\n",
    "            \n",
    "            print(\"min_samples\", int(m))\n",
    "            print(\"min_cluster_size\", int(n))\n",
    "            print(\"epsilon\", ep)\n",
    "            print(\"cluster num\", cluster_num)\n",
    "            print(\"purity: \", p)\n",
    "            print(\"========================\")\n",
    "            \n",
    "            min_samples_params += [int(m)]\n",
    "            min_cluster_size_params += [int(n)]\n",
    "            epsilon_params += [ep]\n",
    "            cluster_nums += [cluster_num]\n",
    "            purities += [p]\n",
    "            \n",
    "pd.DataFrame({\n",
    "    \"min_sample\": min_samples_params,\n",
    "    \"min_cluster_size\": min_cluster_size_params,\n",
    "    \"epsilon\": epsilon_params,\n",
    "    \"cluster_num\": cluster_nums,\n",
    "    \"purity\": purities,\n",
    "}).to_csv(\"purity_org_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68fd13ac-a592-4b76-a626-6a1155ef8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_type_map = {}\n",
    "# with open('user_type_map.json') as json_file:\n",
    "#     user_type_map = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7651d41a-0849-412f-9cb5-024c4a08af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # auth = (\"cting3\", \"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\")\n",
    "# auth = (\"ken-daohuei\", \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f328219f-4114-4dd5-8b81-e67b0b2a45af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44cc6eea-35bb-4493-ac88-b6462dcbdd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b161c927694b8ebf1e66e2cd371a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for idx in tqdm(range(len(all_users))):\n",
    "#     if idx % 500 == 0:\n",
    "#         with open(\"user_type_map.json\", \"w\") as outfile:\n",
    "#             json.dump(user_type_map, outfile, indent=4)\n",
    "            \n",
    "#     user = all_users[idx]\n",
    "#     if user in user_type_map.keys(): continue\n",
    "#     while True:\n",
    "#         response = requests.get(f\"https://api.github.com/users/{all_users[idx]}\", auth=auth)\n",
    "#         if response.status_code != 403:\n",
    "#             data_dict = json.loads(response.text)\n",
    "#             if \"type\" in data_dict.keys():\n",
    "#                 user_type_map[all_users[idx]] = data_dict[\"type\"]\n",
    "#             else:\n",
    "#                 user_type_map[all_users[idx]] = None\n",
    "#             break\n",
    "#         print(response.text)\n",
    "#         time.sleep(30)\n",
    "#     time.sleep(0.01)\n",
    "    \n",
    "# with open(\"user_type_map.json\", \"w\") as outfile:\n",
    "#     json.dump(user_type_map, outfile, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
