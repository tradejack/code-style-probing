{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6240a9c3-2a43-4db5-b5a8-0b317774946e",
   "metadata": {},
   "source": [
    "# Parallel Corpora for Seq2seq Generation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7add233d-91ab-406e-9de2-c673a3cb3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import astunparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea632508-01f1-4962-9861-0fbc5065c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"/data/users/cting3/CodeNest/code-style-probing/data/eval_parallel_corpora/eval_set_individual_feat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad2e0af-bbd8-4ab2-9e6b-3836b7cc00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b1833e-b478-4a43-b685-db05c5d2336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = df[[\"content\", \"uncommented_content\"]].copy().rename(columns={\"content\": \"X\", \"uncommented_content\": \"Y\"})\n",
    "class_df = df[[\"uncommented_content\", \"no_class_content\"]].copy().rename(columns={\"uncommented_content\": \"X\", \"no_class_content\": \"Y\"})\n",
    "docstring_df = df[[\"uncommented_content\", \"no_docstring_content\"]].copy().rename(columns={\"uncommented_content\": \"X\", \"no_docstring_content\": \"Y\"})\n",
    "list_comp_df = df[[\"uncommented_content\", \"no_comp_content\"]].copy().rename(columns={\"uncommented_content\": \"X\", \"no_comp_content\": \"Y\"})\n",
    "casing_df = df[[\"uncommented_content\", \"no_casing_content\"]].copy().rename(columns={\"uncommented_content\": \"X\", \"no_casing_content\": \"Y\"})\n",
    "\n",
    "df_list = [\n",
    "    comment_df, class_df,docstring_df, list_comp_df, casing_df\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c4697a-73e6-44bb-bd70-a9e5f5dbc7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279611\n",
      "156637\n",
      "75999\n",
      "21935\n",
      "235040\n"
     ]
    }
   ],
   "source": [
    "for idx, feature_df in enumerate(df_list):\n",
    "    feature_df = feature_df[feature_df[\"X\"].notnull()]\n",
    "    feature_df = feature_df[feature_df[\"Y\"].notnull()]\n",
    "    feature_df = feature_df.query(f\"X != Y\")\n",
    "    print(len(feature_df))\n",
    "    df_list[idx] = feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489202b9-50e4-4bb5-825d-c09fc14bd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[279611, 156637, 75999, 21935, 235040]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(feat_df) for feat_df in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833ac988-c5f8-4048-999a-b5ee4e89c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommented_df = df[[\"content\", \"uncommented_content\"]].rename(columns={\"content\": \"X\", \"uncommented_content\": \"Y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d439ac9-6340-4d8f-8aa1-45af2acfe5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import jinja2\\nfrom gofedlib.utils import getS...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from collections import Counter\\nwith open(\"/h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__author__ = 'tonycastronova'\\n\\nimport dateti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#!/usr/bin/env python3\\n# -*- coding: utf-8, v...</td>\n",
       "      <td>\\n__author__ = 'morta@digitus.itk.ppke.hu'\\nim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># bo.zhang@ki.se\\n# Chimeric MS/MS estimation ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393643</th>\n",
       "      <td># Geopy will get the distance between pairs of...</td>\n",
       "      <td>\\nimport geopy\\nbase_path = '.'\\nfrom pyspark....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393644</th>\n",
       "      <td>f = CurrentFont()\\ng = CurrentGlyph()\\n\\nlayer...</td>\n",
       "      <td>\\nf = CurrentFont()\\ng = CurrentGlyph()\\nlayer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393645</th>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Copyright 2016 Yelp...</td>\n",
       "      <td>\\nfrom __future__ import absolute_import\\nimpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393646</th>\n",
       "      <td>#!/usr/bin/python\\n\\n# Python library for Adaf...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393647</th>\n",
       "      <td>from __future__ import absolute_import\\n\\nimpo...</td>\n",
       "      <td>\\nfrom __future__ import absolute_import\\nimpo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393648 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        X  \\\n",
       "0       import jinja2\\nfrom gofedlib.utils import getS...   \n",
       "1       from collections import Counter\\nwith open(\"/h...   \n",
       "2       __author__ = 'tonycastronova'\\n\\nimport dateti...   \n",
       "3       #!/usr/bin/env python3\\n# -*- coding: utf-8, v...   \n",
       "4       # bo.zhang@ki.se\\n# Chimeric MS/MS estimation ...   \n",
       "...                                                   ...   \n",
       "393643  # Geopy will get the distance between pairs of...   \n",
       "393644  f = CurrentFont()\\ng = CurrentGlyph()\\n\\nlayer...   \n",
       "393645  # -*- coding: utf-8 -*-\\n# Copyright 2016 Yelp...   \n",
       "393646  #!/usr/bin/python\\n\\n# Python library for Adaf...   \n",
       "393647  from __future__ import absolute_import\\n\\nimpo...   \n",
       "\n",
       "                                                        Y  \n",
       "0                                                     NaN  \n",
       "1                                                     NaN  \n",
       "2                                                     NaN  \n",
       "3       \\n__author__ = 'morta@digitus.itk.ppke.hu'\\nim...  \n",
       "4                                                     NaN  \n",
       "...                                                   ...  \n",
       "393643  \\nimport geopy\\nbase_path = '.'\\nfrom pyspark....  \n",
       "393644  \\nf = CurrentFont()\\ng = CurrentGlyph()\\nlayer...  \n",
       "393645  \\nfrom __future__ import absolute_import\\nimpo...  \n",
       "393646                                                NaN  \n",
       "393647  \\nfrom __future__ import absolute_import\\nimpo...  \n",
       "\n",
       "[393648 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncommented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195de3a5-0220-431d-bc1e-a7f519dd81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re\n",
    "\n",
    "fname_prefix = \"/data/users/cting3/CodeNest/code-style-probing/\"\n",
    "feat_name = \"no_class_no_super\"\n",
    "\n",
    "# csv_fname = \"eval_set_individual_feat.csv\"\n",
    "\n",
    "\n",
    "# df = pd.read_csv(fname_prefix + f\"data/eval_parallel_corpora/{csv_fname}\")\n",
    "\n",
    "uncommented_df = df[[\"content\", \"uncommented_content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10316ec7-101d-4e73-bd71-8a699f04a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_df = pd.read_csv(\"data/evaluation_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b36d8-2b76-45cf-b92c-99be059f0aca",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7f8626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class MyClass: \n",
      "\t\"\"\"A simple example class\"\"\" \n",
      "\ti = 12345 # le epic comment\n",
      "\twhoa = [i + 1 for i in range(0,10)]\n",
      "\n",
      "\tdef f(self):\n",
      "\t\treturn 'hello world'\n"
     ]
    }
   ],
   "source": [
    "fname_prefix = \"/data/users/team2_capstone/code-style-probing/\"\n",
    "test = \"class MyClass: \\n\\t\\\"\\\"\\\"A simple example class\\\"\\\"\\\" \\n\\ti = 12345 # le epic comment\\n\\tWhoa = [i + 1 for i in range(0,10)]\\n\\n\\tdef f(self):\\n\\t\\treturn 'hello world'\"\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaaf7190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "def uncomment(source):\n",
    "    \"\"\" \n",
    "    Takes input code and returns code with comments stripped\n",
    "    Input: code (str)\n",
    "    Output: code (str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parse = ast.unparse(ast.parse(source))\n",
    "    except:\n",
    "        parse = 'nan'\n",
    "    return parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8739379-7fe0-474a-8e8c-329afb151d6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m uncomment(\u001b[43mtest\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "uncomment(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a980b23c-04c1-4081-bfdf-1208ff12c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_204716/247637156.py:2: DtypeWarning: Columns (84,85,86,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bq_df = pd.read_csv(\"data/labeled_code/combined_data_uncommented.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bq_df = pd.read_csv(\"data/labeled_code/combined_data_uncommented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4b1825-3de2-478e-90af-60f6f11dcdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>line_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comment_total_len</th>\n",
       "      <th>comment_avg_len</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>id_total</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>id_total_var</th>\n",
       "      <th>...</th>\n",
       "      <th>filepath</th>\n",
       "      <th>forks</th>\n",
       "      <th>issue_events</th>\n",
       "      <th>stars</th>\n",
       "      <th>parse_error</th>\n",
       "      <th>func_async_count</th>\n",
       "      <th>file</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "      <th>uncommented_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/00/wikihouse/urls.py</td>\n",
       "      <td>19</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>\"\"\" Provides ``mapping`` of url paths to reque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>363.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>51.833333</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>381.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/0rpc/zerorpc-python/zerorpc/events.py</td>\n",
       "      <td>-1</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Open Source Initiat...</td>\n",
       "      <td>import msgpack\\nimport gevent.pool\\nimport gev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/0xadada/dockdj/app/manage.py</td>\n",
       "      <td>19</td>\n",
       "      <td>#!/usr/bin/env python\\n\"\"\"Django's command lin...</td>\n",
       "      <td>\"\"\"Django's command line utility.\"\"\"\\nimport o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/1stvamp/hippybot/setup.py</td>\n",
       "      <td>16</td>\n",
       "      <td>\"\"\"Installer for hippybot\\n\"\"\"\\n\\nimport os\\nc...</td>\n",
       "      <td>\"\"\"Installer for hippybot\\n\"\"\"\\nimport os\\ncwd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/2buntu/2buntu-blog/manage.py</td>\n",
       "      <td>19</td>\n",
       "      <td>#!/usr/bin/env python\\nimport os\\nimport sys\\n...</td>\n",
       "      <td>import os\\nimport sys\\nif __name__ == '__main_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/2buntu/2buntu-blog/twobuntu/categories/mi...</td>\n",
       "      <td>21</td>\n",
       "      <td># -*- coding: utf-8 -*-\\nfrom __future__ impor...</td>\n",
       "      <td>from __future__ import unicode_literals\\nfrom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/2buntu/2buntu-blog/twobuntu/news/views.py</td>\n",
       "      <td>2</td>\n",
       "      <td>import twitter\\nfrom django.contrib import mes...</td>\n",
       "      <td>import twitter\\nfrom django.contrib import mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>48.933333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/2degrees/django-wsgi/django_wsgi/exc.py</td>\n",
       "      <td>-1</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n#####################...</td>\n",
       "      <td>\"\"\"\\nExceptions raised by :mod:`django_wsgi.`\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/2gis/badger-api/common/storage.py</td>\n",
       "      <td>-1</td>\n",
       "      <td>import boto\\nimport boto.s3.connection\\n\\nfrom...</td>\n",
       "      <td>import boto\\nimport boto.s3.connection\\nfrom d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data/2gis/badger-api/stages/models.py</td>\n",
       "      <td>-1</td>\n",
       "      <td>from django.db import models\\nimport datetime\\...</td>\n",
       "      <td>from django.db import models\\nimport datetime\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  line_count  comment_count  comment_total_len  \\\n",
       "0             0           0       116.0            2.0               44.0   \n",
       "1             1           1       363.0           24.0             1244.0   \n",
       "2             2           2        13.0            1.0               21.0   \n",
       "3             3           3        34.0            0.0                0.0   \n",
       "4             4           4        11.0            1.0               21.0   \n",
       "5             5           5        27.0            1.0               23.0   \n",
       "6             6           6        36.0            0.0                0.0   \n",
       "7             7           7        35.0           15.0              734.0   \n",
       "8             8           8        29.0            0.0                0.0   \n",
       "9             9           9        22.0            0.0                0.0   \n",
       "\n",
       "   comment_avg_len  comment_density  id_total  lower_case  id_total_var  ...  \\\n",
       "0        22.000000         0.017241       1.0         1.0           1.0  ...   \n",
       "1        51.833333         0.066116     381.0       214.0         333.0  ...   \n",
       "2        21.000000         0.076923       3.0         3.0           3.0  ...   \n",
       "3         0.000000         0.000000      26.0        18.0          26.0  ...   \n",
       "4        21.000000         0.090909       3.0         3.0           3.0  ...   \n",
       "5        23.000000         0.037037      23.0         9.0          22.0  ...   \n",
       "6         0.000000         0.000000      22.0        18.0          21.0  ...   \n",
       "7        48.933333         0.428571       3.0         0.0           1.0  ...   \n",
       "8         0.000000         0.000000      31.0         8.0          29.0  ...   \n",
       "9         0.000000         0.000000      40.0        28.0          37.0  ...   \n",
       "\n",
       "   filepath  forks  issue_events  stars  parse_error  func_async_count  \\\n",
       "0       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "1       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "2       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "3       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "4       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "5       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "6       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "7       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "8       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "9       NaN    NaN           NaN    NaN          NaN               NaN   \n",
       "\n",
       "                                                file  labels  \\\n",
       "0                          data/00/wikihouse/urls.py      19   \n",
       "1         data/0rpc/zerorpc-python/zerorpc/events.py      -1   \n",
       "2                  data/0xadada/dockdj/app/manage.py      19   \n",
       "3                     data/1stvamp/hippybot/setup.py      16   \n",
       "4                  data/2buntu/2buntu-blog/manage.py      19   \n",
       "5  data/2buntu/2buntu-blog/twobuntu/categories/mi...      21   \n",
       "6     data/2buntu/2buntu-blog/twobuntu/news/views.py       2   \n",
       "7       data/2degrees/django-wsgi/django_wsgi/exc.py      -1   \n",
       "8             data/2gis/badger-api/common/storage.py      -1   \n",
       "9              data/2gis/badger-api/stages/models.py      -1   \n",
       "\n",
       "                                             content  \\\n",
       "0  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "1  # -*- coding: utf-8 -*-\\n# Open Source Initiat...   \n",
       "2  #!/usr/bin/env python\\n\"\"\"Django's command lin...   \n",
       "3  \"\"\"Installer for hippybot\\n\"\"\"\\n\\nimport os\\nc...   \n",
       "4  #!/usr/bin/env python\\nimport os\\nimport sys\\n...   \n",
       "5  # -*- coding: utf-8 -*-\\nfrom __future__ impor...   \n",
       "6  import twitter\\nfrom django.contrib import mes...   \n",
       "7  # -*- coding: utf-8 -*-\\n#####################...   \n",
       "8  import boto\\nimport boto.s3.connection\\n\\nfrom...   \n",
       "9  from django.db import models\\nimport datetime\\...   \n",
       "\n",
       "                                 uncommented_content  \n",
       "0  \"\"\" Provides ``mapping`` of url paths to reque...  \n",
       "1  import msgpack\\nimport gevent.pool\\nimport gev...  \n",
       "2  \"\"\"Django's command line utility.\"\"\"\\nimport o...  \n",
       "3  \"\"\"Installer for hippybot\\n\"\"\"\\nimport os\\ncwd...  \n",
       "4  import os\\nimport sys\\nif __name__ == '__main_...  \n",
       "5  from __future__ import unicode_literals\\nfrom ...  \n",
       "6  import twitter\\nfrom django.contrib import mes...  \n",
       "7  \"\"\"\\nExceptions raised by :mod:`django_wsgi.`\\...  \n",
       "8  import boto\\nimport boto.s3.connection\\nfrom d...  \n",
       "9  from django.db import models\\nimport datetime\\...  \n",
       "\n",
       "[10 rows x 97 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792006c1-7b1c-4538-b6af-f28761051787",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_df['uncomped_content'] = bq_df['content'].apply(for_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d125c799-8b68-452b-8ca0-35e14a48cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_df.to_csv(\"data/combined_data_uncommented.csv\") #remember to tell karl to dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a307d58-9a30-4090-8f88-4f445e8ab8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_comment_set_df = eval_set_df.copy()\n",
    "\n",
    "processed_scripts = []\n",
    "uncommented_scripts = []\n",
    "for idx, script in enumerate(tqdm(eval_class_set_df['content'])):\n",
    "    processed_scripts += [uncomment(script)]\n",
    "    \n",
    "eval_comment_set_df['uncommented_content'] = processed_scripts\n",
    "eval_comment_set_df.to_csv(\"data/eval_parallel_corpora/eval_set_no_comment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb0039-576d-4902-87af-e35c71ba1008",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96154a30-3326-4a45-8560-8f5669ac321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_init_func(func_node):\n",
    "    return func_node.name == \"__init__\"\n",
    "def is_super_expr(expr_node):\n",
    "    for node in ast.walk(expr_node):\n",
    "        if hasattr(node, \"func\") and type(node.func) == ast.Name:\n",
    "            if node.func.id == \"super\":\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f251df02-c9fb-49b0-977f-194ecd047c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astunparse\n",
    "import ast\n",
    "def extract_func_from_class_node(class_node, no_super):\n",
    "    func_list = class_node.body\n",
    "    for func_node in func_list:\n",
    "        if type(func_node) != ast.FunctionDef:\n",
    "            continue\n",
    "        \n",
    "        if no_super and is_init_func(func_node):\n",
    "            new_init_func_body = []\n",
    "            for node in func_node.body:\n",
    "                if is_super_expr(node): \n",
    "                    continue\n",
    "                new_init_func_body += [node]\n",
    "            func_node.body = new_init_func_body\n",
    "    \n",
    "        arg_list = func_node.args.args\n",
    "        new_arg_list = []\n",
    "        for arg in arg_list:\n",
    "            if arg.arg == \"self\" or arg.arg == \"cls\":\n",
    "                continue\n",
    "            new_arg_list += [arg]\n",
    "        func_node.args.args = new_arg_list\n",
    "    return func_list\n",
    "def remove_class_from_ast(ast_tree, no_super):\n",
    "    class_nodes = []\n",
    "    for node in ast.walk(ast_tree):\n",
    "        for idx, child in enumerate(ast.iter_child_nodes(node)):\n",
    "            if type(child) == ast.ClassDef:\n",
    "                child.parent = node\n",
    "                if type(node) in [ast.If, ast.Try, ast.For]:\n",
    "                    if child in node.body:\n",
    "                        # it is in the if\n",
    "                        child.idx = node.body.index(child)\n",
    "                    elif child in node.orelse:\n",
    "                        # it is in the else\n",
    "                        child.idx = node.orelse.index(child)\n",
    "                        child.is_else = True\n",
    "                    elif child in node.finalbody:\n",
    "                        child.idx = node.finalbody.index(child)\n",
    "                        child.is_final = True\n",
    "                    else:\n",
    "                        raise(f\"Not in the body, another speciall case may happen, please look into this node: {ast.dump(node)}\")\n",
    "                else:\n",
    "                    child.idx = node.body.index(child)\n",
    "                    \n",
    "                class_nodes = [child] + class_nodes\n",
    "    \n",
    "    if len(class_nodes) == 0:\n",
    "        # nothing to change\n",
    "        return None\n",
    "    \n",
    "    for class_node in class_nodes:\n",
    "        func_list = extract_func_from_class_node(class_node, no_super)\n",
    "        idx = class_node.idx\n",
    "        \n",
    "        # addressing classes in the else condition\n",
    "        if hasattr(class_node, \"is_else\") and class_node.is_else:\n",
    "            class_node.parent.orelse.pop(idx)\n",
    "            class_node.parent.orelse = class_node.parent.orelse[:idx] + func_list + class_node.parent.orelse[idx:]\n",
    "        elif hasattr(class_node, \"is_final\") and class_node.is_final:\n",
    "            class_node.parent.finalbody.pop(idx)\n",
    "            class_node.parent.finalbody = class_node.parent.finalbody[:idx] + func_list + class_node.parent.finalbody[idx:]\n",
    "        else:\n",
    "            class_node.parent.body.pop(idx)\n",
    "            class_node.parent.body = class_node.parent.body[:idx] + func_list + class_node.parent.body[idx:]\n",
    "            \n",
    "    return ast_tree\n",
    "\n",
    "def remove_self_cls_str(script):\n",
    "    return script.replace(\"self.\", \"\").replace(\"cls.\", \"\")\n",
    "\n",
    "def remove_class(script, no_super=False):\n",
    "    ast_tree = ast.parse(script)\n",
    "    processed_ast_tree = remove_class_from_ast(ast_tree, no_super)\n",
    "    if processed_ast_tree:\n",
    "        return remove_self_cls_str(astunparse.unparse(processed_ast_tree))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c81be6-e430-4ffd-a800-2df01988e16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the removing classes method only works on python3 code, so we exclude py150k here\n",
    "bq_no_outlier_df = pd.read_csv(\"data/labeled_code/bq_data_no_outlier.csv\")\n",
    "processed_scripts = []\n",
    "for script in tqdm(bq_no_outlier_df['content']):\n",
    "    try:\n",
    "        processed_script = remove_class(script)\n",
    "        processed_scripts += [processed_script]\n",
    "    except SyntaxError:\n",
    "        processed_scripts += [None]\n",
    "    except Exception as e:\n",
    "        print(script)\n",
    "        print(e)\n",
    "        raise(e)\n",
    "bq_no_outlier_df['no_class_content'] = processed_scripts\n",
    "bq_no_outlier_df.to_csv(\"data/labeled_code/bq_data_no_outlier_no_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9812ab57-69b9-4a2c-bb85-199947b882b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bq_outlier_df = pd.read_csv(\"data/labeled_code/bq_data_outlier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934210c-4bc8-4f35-9a91-d1df0ffb7406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_scripts = []\n",
    "for idx, script in enumerate(tqdm(bq_outlier_df['content'])):\n",
    "    if \"Class\" not in script:\n",
    "        processed_scripts += [None]\n",
    "        continue\n",
    "    # if \"__init__\" not in script:\n",
    "    #     continue\n",
    "    try:\n",
    "        processed_script = remove_class(script)\n",
    "        processed_scripts += [processed_script\n",
    "    except SyntaxError:\n",
    "        processed_scripts += [None]\n",
    "    except Exception as e:\n",
    "        print(script)\n",
    "        print(e)\n",
    "        raise(e)\n",
    "    # break\n",
    "    \n",
    "bq_outlier_df['no_class_content'] = processed_scripts\n",
    "bq_outlier_df.to_csv(\"data/labeled_code/bq_data_outlier_no_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4f547-e9c6-40fd-90cf-adeb31fd3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_outlier_df = pd.read_csv(\"data/labeled_code/bq_data_outlier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e57ee6-227c-4c8c-bf23-ac2506448f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_scripts = []\n",
    "for idx, script in enumerate(tqdm(bq_outlier_df['content'])):\n",
    "    if \"Class\" not in script:\n",
    "        processed_scripts += [None]\n",
    "        continue\n",
    "    # if \"__init__\" not in script:\n",
    "    #     continue\n",
    "    try:\n",
    "        processed_script = remove_class(script, no_super=True)\n",
    "        processed_scripts += [processed_script]\n",
    "    except SyntaxError:\n",
    "        processed_scripts += [None]\n",
    "    except Exception as e:\n",
    "        print(script)\n",
    "        print(e)\n",
    "        raise(e)\n",
    "    # break\n",
    "    \n",
    "bq_outlier_df['no_class_content'] = processed_scripts\n",
    "bq_outlier_df.to_csv(\"data/labeled_code/bq_data_outlier_no_class_no_super.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75a540f-84bc-4b1a-a8b8-04148055a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_df = pd.read_csv(\"data/evaluation_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be4f9dc-640f-4993-b700-3ee9d9ef3c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08608d018e648ffa81fc6208587d963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(script) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m(\u001b[38;5;167;01mSyntaxError\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m     processed_script \u001b[38;5;241m=\u001b[39m \u001b[43mremove_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     processed_scripts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [processed_script]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mremove_class\u001b[0;34m(script, no_super)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_class\u001b[39m(script, no_super\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     74\u001b[0m     ast_tree \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mparse(script)\n\u001b[0;32m---> 75\u001b[0m     processed_ast_tree \u001b[38;5;241m=\u001b[39m \u001b[43mremove_class_from_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mast_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_super\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m processed_ast_tree:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m remove_self_cls_str(astunparse\u001b[38;5;241m.\u001b[39munparse(processed_ast_tree))\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mremove_class_from_ast\u001b[0;34m(ast_tree, no_super)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_class_from_ast\u001b[39m(ast_tree, no_super):\n\u001b[1;32m     26\u001b[0m     class_nodes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m ast\u001b[38;5;241m.\u001b[39mwalk(ast_tree):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ast\u001b[38;5;241m.\u001b[39miter_child_nodes(node)):\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(child) \u001b[38;5;241m==\u001b[39m ast\u001b[38;5;241m.\u001b[39mClassDef:\n",
      "File \u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/ast.py:343\u001b[0m, in \u001b[0;36mwalk\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m todo:\n\u001b[1;32m    342\u001b[0m     node \u001b[38;5;241m=\u001b[39m todo\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m--> 343\u001b[0m     \u001b[43mtodo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_child_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m node\n",
      "File \u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/ast.py:227\u001b[0m, in \u001b[0;36miter_child_nodes\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter_child_nodes\u001b[39m(node):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    Yield all direct child nodes of *node*, that is, all fields that are nodes\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    and all items of fields that are lists of nodes.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, field \u001b[38;5;129;01min\u001b[39;00m iter_fields(node):\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(field, AST):\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m field\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_class_set_df = eval_set_df.copy()\n",
    "\n",
    "processed_scripts = []\n",
    "uncommented_scripts = []\n",
    "for idx, script in enumerate(tqdm(eval_class_set_df['content'])):\n",
    "    uncommented_scripts += [uncomment(script)]\n",
    "    try:\n",
    "        if type(script) != str:\n",
    "            raise(SyntaxError)\n",
    "        processed_script = remove_class(script)\n",
    "        processed_scripts += [processed_script]\n",
    "    except SyntaxError:\n",
    "        processed_scripts += [None]\n",
    "    except Exception as e:\n",
    "        print(script)\n",
    "        print(e)\n",
    "        raise(e)\n",
    "eval_class_set_df['no_class_content'] = processed_scripts\n",
    "eval_class_set_df['content'] = uncommented_scripts\n",
    "eval_class_set_df.to_csv(\"data/eval_parallel_corpora/eval_set_no_class.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50179a8",
   "metadata": {},
   "source": [
    "## Docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05b556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ast\n",
      " class MyClass: \n",
      "\t\"\"\"A simple example class\"\"\" \n",
      "\ti = 12345 # le epic comment\n",
      "\tVAR = 1 \n",
      "\tWhoa = [i + 1 for i in range(0,10)]\n",
      "\n",
      "\tdef f(self):\n",
      "\t\treturn 'hello world'\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "test = \"import ast\\n class MyClass: \\n\\t\\\"\\\"\\\"A simple example class\\\"\\\"\\\" \\n\\ti = 12345 # le epic comment\\n\\tVAR = 1 \\n\\tWhoa = [i + 1 for i in range(0,10)]\\n\\n\\tdef f(self):\\n\\t\\treturn 'hello world'\"\n",
    "print (test)  #\"\\\"\\\"\\\"start doc\\\"\\\"\\\"\\n\n",
    "#import astor\n",
    "def undocstring(source):\n",
    "    try:\n",
    "        parsed = ast.parse(source)\n",
    "        \n",
    "        for node in ast.walk(parsed):\n",
    "            print(\"Node is : \",node)\n",
    "            #print(\"Node value is : \",node.body[0].value.s)\n",
    "                    \n",
    "            if not isinstance(node, (ast.Module)): #, ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef\n",
    "                continue\n",
    "\n",
    "            if not len(node.body):\n",
    "                continue\n",
    "\n",
    "            if not isinstance(node.body[0], ast.Expr):\n",
    "                continue\n",
    "\n",
    "            if not hasattr(node.body[0], 'value') or not isinstance(node.body[0].value, ast.Str):\n",
    "                continue\n",
    "\n",
    "            # Uncomment lines below if you want print what and where we are removing\n",
    "            # \n",
    "            # \n",
    "\n",
    "            node.body = node.body[1:]\n",
    "        class toLower(ast.NodeTransformer):\n",
    "\n",
    "            def visit_arg(self, node):\n",
    "                return ast.arg(**{**node.__dict__, 'arg':node.arg.lower()})\n",
    "            def visit_Name(self, node):\n",
    "                #print(\"node id is : \",node.id)\n",
    "                return ast.Name(**{**node.__dict__, 'id':node.id.lower()})\n",
    "\n",
    "        new_code = ast.unparse(parsed)#toLower().visit(parsed))\n",
    "        #print(new_code)\n",
    "        return new_code\n",
    "    except:\n",
    "        parsed = 'nan'\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_df = pd.read_csv(fname_prefix + \"data/labeled_code/bq_data_outlier.csv\")\n",
    "bq_df['no_docstring_content'] = bq_df['content'].apply(undocstring)\n",
    "bq_df['content'] = bq_df['content'].apply(uncomment)\n",
    "bq_df.to_csv(fname_prefix + \"data/labeled_code/bq_no_docstring_outlier.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b64e13-ed98-492a-bbc5-a06326bf0126",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273b485661e74350807ff0fd1713f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_set_no_docstring_df = eval_set_df.copy()\n",
    "\n",
    "processed_scripts = []\n",
    "uncommented_scripts = []\n",
    "for idx, script in enumerate(tqdm(eval_set_no_docstring_df['content'])):\n",
    "    uncommented_scripts += [uncomment(script)]\n",
    "    processed_scripts += [undocstring(script)]\n",
    "    \n",
    "eval_set_no_docstring_df['no_docstring_content'] = processed_scripts\n",
    "eval_set_no_docstring_df['content'] = uncommented_scripts\n",
    "eval_set_no_docstring_df.to_csv(\"data/eval_parallel_corpora/eval_set_no_docstring.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f4065-eb7e-44ce-b192-ab24f40c9603",
   "metadata": {},
   "source": [
    "## List Comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48699d03-01be-4989-9b51-a86d5eb4988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class MyClass: \\n\\t\"\"\"A simple example class\"\"\" \\n\\ti = 12345 # le epic comment\\n\\twhoa = [i + 1 for i in range(0,10)]\\n\\n\\tdef f(self):\\n\\t\\treturn \\'hello world\\''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ecd8a2f-e259-4324-ac88-758d8489a7ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'source.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import astor\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m parsed \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m ast\u001b[38;5;241m.\u001b[39mwalk(parsed):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#print(\"Inside For\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# let's work only on functions & classes definitions\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (ast\u001b[38;5;241m.\u001b[39mListComp)):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'source.py'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "#import astor\n",
    "\n",
    "parsed = ast.parse(open('source.py').read())\n",
    "\n",
    "for node in ast.walk(parsed):\n",
    "    #print(\"Inside For\")\n",
    "    # let's work only on functions & classes definitions\n",
    "    if not isinstance(node, (ast.ListComp)):\n",
    "        continue\n",
    "    for e in node.generators:\n",
    "        print(e)\n",
    "\n",
    "    if not len(node.generators):\n",
    "        continue\n",
    "\n",
    "    # Uncomment lines below if you want print what and where we are removing\n",
    "    print(node)\n",
    "    print(node.elt)\n",
    "    print(node.generators[0].target.id)\n",
    "    print(node.generators[0].target.id)\n",
    "\n",
    "\n",
    "\n",
    "    # node.body = node.body[1:]\n",
    "\n",
    "print('***** Processed source code output ******\\n=========================================')\n",
    "\n",
    "#print(astor.to_source(parsed))\n",
    "    \n",
    "class toForLoop(ast.NodeTransformer):\n",
    "    def visit_arg(self, node):\n",
    "        print(node.id)\n",
    "        #node.arg.replace(\"_\",\"\")\n",
    "        return ast.arg(**{**node.__dict__, 'arg':node.arg.lower()})\n",
    "    def visit_ListComp(self, node):\n",
    "        print(node.body)\n",
    "        #return ast.Name(**{**node.__dict__, 'id':node.id.lower()})\n",
    "\n",
    "toForLoop().visit_ListComp(ast.parse(parsed))\n",
    "# new_code = ast.unparse(toLower().visit_Name(ast.parse(parsed)))\n",
    "# print(new_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47190438-34b3-4ce1-8a77-5375d253963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def for_loop(text):\n",
    "    def wrap_if(body, compare):\n",
    "        return  ast.If(\n",
    "                    test= compare,\n",
    "                    body=[body],\n",
    "                    orelse=[])\n",
    "    \n",
    "    def wrap_for(body, a, index):\n",
    "        return ast.For(\n",
    "                    target = a.value.generators[index].target,\n",
    "                    iter = a.value.generators[index].iter,\n",
    "                    body = body,\n",
    "                    lineno = a.lineno + 1,\n",
    "                    orelse = [])\n",
    "    \n",
    "    def comp_to_expl(tree):\n",
    "       if hasattr(tree, 'body'):\n",
    "          i = 0\n",
    "          while i < len(tree.body):\n",
    "            if isinstance(a:=tree.body[i], ast.Assign) and isinstance(a.value, ast.ListComp):\n",
    "                for_loop_body = [ast.Expr(\n",
    "                                 value = ast.Call(\n",
    "                                           func = ast.Attribute(value = ast.Name(id = a.targets[0].id), attr = 'append', ctx = ast.Load()),\n",
    "                                           args = [a.value.elt],\n",
    "                                           keywords = [] ))]\n",
    "                \n",
    "                for ind, for_loop in enumerate(a.value.generators[::-1]):\n",
    "                    ind = len(a.value.generators) - 1 - ind\n",
    "                    for if_state in a.value.generators[ind].ifs:\n",
    "                        for_loop_body = wrap_if(for_loop_body, if_state)\n",
    "                        \n",
    "                    for_loop_body = wrap_for(for_loop_body, a, ind)                    \n",
    "\n",
    "                \n",
    "                tree.body = tree.body[:i] + \\\n",
    "                    [ast.Assign(\n",
    "                       targets=[ast.Name(id = a.targets[0].id)], value = ast.List(elts = []),\n",
    "                       lineno = a.lineno\n",
    "                    )] + \\\n",
    "                    [for_loop_body] + \\\n",
    "                    tree.body[i+1:]   \n",
    "                i += 1   \n",
    "            i += 1\n",
    "            \n",
    "       for i in getattr(tree, '_fields', []):\n",
    "          if isinstance(v:=getattr(tree, i, None), list):\n",
    "             for i in v: \n",
    "                comp_to_expl(i)\n",
    "          elif isinstance(v, ast.AST):\n",
    "             comp_to_expl(v)\n",
    "\n",
    "    try:\n",
    "        parsed = ast.parse(text)\n",
    "    except:\n",
    "        return \"Nan\"\n",
    "    \n",
    "    try:\n",
    "        comp_to_expl(parsed)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ast.unparse(parsed)\n",
    "# print(for_loop(open('source.py').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8d83378-9778-47e9-8e23-4f2284893aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_df['uncomped_content'] = bq_df['uncommented_content'].apply(for_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb5841-a6f6-4e9f-a51b-bdb6668a0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0896e1c-981c-4610-8cd6-c5901565eac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26784"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bq_df['uncommented_content'] != bq_df['uncomped_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a1b2c9-1628-49bb-ade9-8b13adc0ce41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0887c07eb09464dbe40d43598f5133b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (393648)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     processed_scripts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [for_loop(script)]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m eval_set_comp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_docstring_content\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m processed_scripts\n\u001b[1;32m     12\u001b[0m eval_set_comp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uncommented_scripts\n\u001b[1;32m     13\u001b[0m eval_set_comp_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/eval_parallel_corpora/eval_set_comp.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/pandas/core/frame.py:3612\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3611\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/pandas/core/frame.py:3784\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3775\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3777\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3782\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3783\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3784\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3787\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3788\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3789\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3790\u001b[0m     ):\n\u001b[1;32m   3791\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3792\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/pandas/core/frame.py:4509\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4509\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py_3_8/lib/python3.8/site-packages/pandas/core/common.py:531\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (393648)"
     ]
    }
   ],
   "source": [
    "eval_set_comp_df = eval_set_df.copy()\n",
    "\n",
    "processed_scripts = []\n",
    "uncommented_scripts = []\n",
    "for idx, script in enumerate(tqdm(eval_set_df['content'])):\n",
    "    uncommented_scripts += [uncomment(script)]\n",
    "    processed_scripts += [for_loop(script)]\n",
    "\n",
    "    break\n",
    "    \n",
    "eval_set_comp_df['no_docstring_content'] = processed_scripts\n",
    "eval_set_comp_df['content'] = uncommented_scripts\n",
    "eval_set_comp_df.to_csv(\"data/eval_parallel_corpora/eval_set_comp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931c015-d59a-4029-8803-4cd6ada6f921",
   "metadata": {},
   "source": [
    "# Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b96f425-d323-4b81-878f-cbfeb2deb4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Processed source code output ******\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "#note get exact function anish used to generate the data this is old data\n",
    "import ast\n",
    "#import astor\n",
    "\n",
    "\n",
    "print('***** Processed source code output ******\\n=========================================')\n",
    "\n",
    "#print(astor.to_source(parsed))\n",
    "\n",
    "\n",
    "\n",
    "class toLower(ast.NodeTransformer):\n",
    "\n",
    "    def visit_arg(self, node):\n",
    "\n",
    "        return ast.arg(**{**node.__dict__, 'arg':node.arg.lower().replace(\"_\",\"\")})\n",
    "    def visit_Name(self, node):\n",
    "        return ast.Name(**{**node.__dict__, 'id':node.id.lower()})\n",
    "    \n",
    "\n",
    "\n",
    "class toFuncLower(ast.NodeTransformer):\n",
    "    def visit_FunctionDef(self, node):\n",
    "        return ast.FunctionDef(**{**node.__dict__, 'name':node.name.lower().replace(\"_\",\"\")})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c041e24-7003-4a34-8608-fb0065dba2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncasing(script):\n",
    "\n",
    "    parsed = ast.parse(script)\n",
    "    for node in ast.walk(parsed):\n",
    "        if not isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef)):\n",
    "            continue\n",
    "\n",
    "        if not len(node.body):\n",
    "            continue\n",
    "\n",
    "        if not isinstance(node.body[0], ast.Expr):\n",
    "            continue\n",
    "\n",
    "        if not hasattr(node.body[0], 'value') or not isinstance(node.body[0].value, ast.Str):\n",
    "            continue\n",
    "\n",
    "        # Uncomment lines below if you want print what and where we are removing\n",
    "        # print(\"Node is : \",node)\n",
    "        # print(\"Node value is : \",node.body[0].value.s)\n",
    "\n",
    "        node.body = node.body[1:]\n",
    "        \n",
    "    new_code = astunparse.unparse(toLower().visit(parsed))\n",
    "    #print(new_code)\n",
    "    parsed_new = ast.parse(new_code)\n",
    "    final_code = astunparse.unparse(toFuncLower().visit(parsed_new))\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4580b8e8-2107-49a2-9211-05168a3fa823",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = eval_set_df[\"content\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "863e043f-a325-4991-83cd-1cac990596be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'security converge saved queries\\n\\nRevision ID: e38177dbf641\\nRevises: a8173232b786\\nCreate Date: 2020-11-20 14:24:03.643031\\n\\n'\n",
      "revision = 'e38177dbf641'\n",
      "down_revision = 'a8173232b786'\n",
      "from alembic import op\n",
      "from sqlalchemy.exc import SQLAlchemyError\n",
      "from sqlalchemy.orm import Session\n",
      "from superset.migrations.shared.security_converge import add_pvms, get_reversed_new_pvms, get_reversed_pvm_map, migrate_roles, Pvm\n",
      "new_pvms = {'SavedQuery': ('can_read', 'can_write')}\n",
      "pvm_map = {pvm('SavedQueryView', 'can_list'): (pvm('SavedQuery', 'can_read'),), pvm('SavedQueryView', 'can_show'): (pvm('SavedQuery', 'can_read'),), pvm('SavedQueryView', 'can_add'): (pvm('SavedQuery', 'can_write'),), pvm('SavedQueryView', 'can_edit'): (pvm('SavedQuery', 'can_write'),), pvm('SavedQueryView', 'can_delete'): (pvm('SavedQuery', 'can_write'),), pvm('SavedQueryView', 'muldelete'): (pvm('SavedQuery', 'can_write'),), pvm('SavedQueryView', 'can_mulexport'): (pvm('SavedQuery', 'can_read'),), pvm('SavedQueryViewApi', 'can_show'): (pvm('SavedQuery', 'can_read'),), pvm('SavedQueryViewApi', 'can_edit'): (pvm('SavedQuery', 'can_write'),), pvm('SavedQueryViewApi', 'can_list'): (pvm('SavedQuery', 'can_read'),), pvm('SavedQueryViewApi', 'can_add'): (pvm('SavedQuery', 'can_write'),), pvm('SavedQueryViewApi', 'muldelete'): (pvm('SavedQuery', 'can_write'),)}\n",
      "\n",
      "def upgrade():\n",
      "    bind = op.get_bind()\n",
      "    session = session(bind=bind)\n",
      "    add_pvms(session, new_pvms)\n",
      "    migrate_roles(session, pvm_map)\n",
      "    try:\n",
      "        session.commit()\n",
      "    except sqlalchemyerror as ex:\n",
      "        print(f'An error occurred while upgrading permissions: {ex}')\n",
      "        session.rollback()\n",
      "\n",
      "def downgrade():\n",
      "    bind = op.get_bind()\n",
      "    session = session(bind=bind)\n",
      "    add_pvms(session, get_reversed_new_pvms(pvm_map))\n",
      "    migrate_roles(session, get_reversed_pvm_map(pvm_map))\n",
      "    try:\n",
      "        session.commit()\n",
      "    except sqlalchemyerror as ex:\n",
      "        print(f'An error occurred while downgrading permissions: {ex}')\n",
      "        session.rollback()\n",
      "    pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(uncasing(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771654c-8a83-4538-9351-e041ec76fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
