{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re\n",
    "\n",
    "fname_prefix = \"/data/users/team2_capstone/code-style-probing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#uncommented prep\n",
    "combined_df = pd.read_csv(fname_prefix + \"data/labeled_code/bq_uncommented_outlier.csv\")\n",
    "combined_df = combined_df[combined_df['uncommented_content'].notnull()]\n",
    "#test_df = combined_df.query(\"content != uncommented_content\")\n",
    "#display(combined_df)\n",
    "#display(test_df)\n",
    "dataset = Dataset.from_pandas(combined_df).train_test_split(test_size=0.2)\n",
    "print (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#class prep\n",
    "#class_df= pd.read_csv(fname_prefix + \"data/labeled_code/bq_data_outlier_no_class.csv\")\n",
    "#class_df['uncommented_content'] = combined_df['uncommented_content']\n",
    "#class_df = class_df[class_df['uncommented_content'].notnull()]\n",
    "#class_df = class_df[class_df['no_class_content'].notnull()]\n",
    "#display (class_df)\n",
    "#dataset = Dataset.from_pandas(class_df).train_test_split(test_size=0.2)\n",
    "print (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combined_df = pd.read_csv(fname_prefix + \"data/labeled_code/bq_uncommented_outlier.csv\")\\ndocstring_df = pd.read_csv(fname_prefix + \"data/labeled_code/bq_no_docstring_outlier.csv\")\\ndocstring_df[\\'uncommented_content\\'] = combined_df[\\'uncommented_content\\']\\ndocstring_df = docstring_df[docstring_df[\\'uncommented_content\\'].notnull()]\\ndocstring_df = docstring_df[docstring_df[\\'no_docstring_content\\'].notnull()]\\n#display (docstring_df)\\ndataset = Dataset.from_pandas(docstring_df).train_test_split(test_size=0.2)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"combined_df = pd.read_csv(fname_prefix + \"data/labeled_code/bq_uncommented_outlier.csv\")\n",
    "docstring_df = pd.read_csv(fname_prefix + \"data/labeled_code/bq_no_docstring_outlier.csv\")\n",
    "docstring_df['uncommented_content'] = combined_df['uncommented_content']\n",
    "docstring_df = docstring_df[docstring_df['uncommented_content'].notnull()]\n",
    "docstring_df = docstring_df[docstring_df['no_docstring_content'].notnull()]\n",
    "#display (docstring_df)\n",
    "dataset = Dataset.from_pandas(docstring_df).train_test_split(test_size=0.2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/1e2aacf615bc83f25a9d748eccb762b335eee01a29ab7a8db9b8e86cc851d489.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/7eaa9b856402f05e8fdd452951872ecd3c2692ea9abb86b7ab62b07e3bc5f7de.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/a3e93db547e41cdd21f01826d07c5679e111b02d8e969c607611c30a6acbe191.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/5941df5e4315c5ab63b7b2ac791fb0bf0f209744a055c06b43b5274849137cdd.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/c99468017f7cb1b243c80a5640fd483688c5ec58bcd18b64efa5b82d8df7bc24.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c02f13bddd4b7caf40929129210d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a5556763464ff29aa391538f904571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, PLBartTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "example =dataset['train']['uncommented_content']\n",
    "#label = tokenizer(example, truncation=True)\n",
    "#print (len(label['input_ids']))\n",
    "def tokenization(example):\n",
    "    return_dict = tokenizer(example['uncommented_content'], padding='max_length', truncation=True)\n",
    "    #print ((example['content'][10]))\n",
    "    labels = tokenizer(example['content'], padding='max_length', truncation=True).input_ids\n",
    "    return_dict['labels'] = labels\n",
    "    #print (return_dict.keys())\n",
    "    \n",
    "    return return_dict\n",
    "train_dataset = dataset[\"train\"].map(tokenization, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "train_dataset.format['type']\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(tokenization, batched=True)\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.format['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([    1,  5666,  1140,   203,  2080,  2527,  1930, 20650,   203,   203,\n",
      "         2080,  4204,    18,  6283,  1930,  1729,    22,  1631,    16,  8275,\n",
      "           22,  2620,    16,  1842,    67,  6283,   203,   203,   203,  1106,\n",
      "         7766,  4870,    22,  2419,    30,   203,   565,   632,  3845,  2039,\n",
      "          203,   565,  1652,  1729,    22,  1631,    12,   203,  3639,  9813,\n",
      "           16,   203,  3639,  4977,   270, 19706,  1546,  3576, 20364,  3113,\n",
      "          203,  3639,  3455,  9231,    33,  8381,    16,   203,   565,   262,\n",
      "           30,   203,  3639,  3536,  2276,   358,  1765,  1729,   358,  8275,\n",
      "         2887,   279,   585, 12123,   203,  3639,   810,   768,   273, 20650,\n",
      "           12, 15056,    18,  3015,  1435,   309,  1549,    12, 15056,    16,\n",
      "          609,    13,   469,  9813,    13,   203,  3639,  1765,   280,   273,\n",
      "         1729,    22,  1631,    18,  2620,    22,  1631,  1435,   203,  3639,\n",
      "          327,  1765,   280,    18,  6283,   768,    12,  2630,   768,    16,\n",
      "          315,  3813,  3113,  4977,   270, 19706,    16,  3455,  9231,    13,\n",
      "          203,   203,   565,   632,  3845,  2039,   203,   565,  1652,  8275,\n",
      "           22,  2620,    12,   917,   552,    16,  1729,  3202,  4672,   203,\n",
      "         3639,  3536,  2276,   358,  1765,  8275,   358,  1729,  2887,   279,\n",
      "          585, 12123,   203,  3639,   468,  4037,  8275,   768,   733,   358,\n",
      "         1731,   203,  3639,   810,   768,   273, 20650,    12,  3890,    12,\n",
      "          917,   552,  3719,   203,  3639,   876,   768,   273, 20650,  1435,\n",
      "          203,  3639,  1542,   768,   273, 20650,    12,  2620,  3202,    18,\n",
      "         3015, 10756,   203,  3639,  1815,  8275,    22,  2620,    18,   591,\n",
      "          502,   451,  1419,    12,  2630,   768,    16,   876,   768,    16,\n",
      "         1542,   768,    13,   203,  3639,   327,   876,   768,    18,   588,\n",
      "         1132,  7675,  3922,  2932,  3158,    17,    28,  7923,   203,   203,\n",
      "          565,   632,  3845,  2039,   203,   565,  1652,  1056,  7705,    12,\n",
      "         1631,   768,    16,  2665,  4672,   203,  3639,  3536,  4759,   358,\n",
      "          866,   716,   732,  2363,   326,  2665,  1300,   434,  2743,  8395,\n",
      "          203,  3639,  3214,   273,   562,    12,  1631,   768,    18,  7705,\n",
      "           13,   203,  3639,   309,  3214,   405,   374,    30,   203,  5411,\n",
      "          309,  8275,   768,    18,  7705,    63,    20,  8009,   291,  3374,\n",
      "        13332,   203,  7734,  3214,   273,  3214,   300,   404,   203,  3639,\n",
      "         1172,    12,  1631,   768,    13,   203,  3639,  1815,  3214,   422,\n",
      "         2665,   203,   203,   565,   632,  3845,  2039,   203,   565,  1652,\n",
      "         3400,  4873,    12,  1631,   768,    16,  2836,  2696,    16,  2665,\n",
      "         4672,   203,  3639,  3536,  4759,   358,  1954,   279, 13803,   883,\n",
      "         8395,   203,  3639,   309,   486,  8275,   768,    18,  7705,    63,\n",
      "           20,  8009,   291,  3374, 13332,   203,  5411,  2836,  2696,   273,\n",
      "         2836,  2696,   300,   404,   203,  3639,  1172,  2932,  4873,  1084,\n",
      "           30,   315,   397,  8275,   768,    18,  7705,    63,  4873,  2696,\n",
      "         8009,  3168,   397, 11747,  7923,   203,  3639,  1172,  2932,  3825,\n",
      "           30,   315,   397,  2665,   397, 11747,  7923,   203,  3639,  1815,\n",
      "          609,    12,  1631,   768,    18,  7705,    63,  4873,  2696,  8009,\n",
      "         3168,    13,   422,   609,    12,  3825,    13,   203,   203,   565,\n",
      "         1652,   866,    67,  7526,    12,  2890,    16,  9813,    16,   761,\n",
      "          955,  4672,   203,  3639,  3536, 12366,   716, 14540,   333,  9813,\n",
      "        15505,   279,  2202,   930,   598,   460,   761,   955,  8395,   203,\n",
      "         3639,  8275,   768,   273,   365,    18,  2620,    22,  1631,    12,\n",
      "        15056,    13,   203,  3639,   365,    18,  1883,  7705,    12,  1631,\n",
      "          768,    16,   404,    13,   203,  3639,   365,    18,  9877,  4873,\n",
      "           12,  1631,   768,    16,   404,    16,   761,   955,    13,   203,\n",
      "          203,     2]), 'input_ids': tensor([    1,  5666,  1140,   203,  2080,  2527,  1930, 20650,   203,  2080,\n",
      "         4204,    18,  6283,  1930,  1729,    22,  1631,    16,  8275,    22,\n",
      "         2620,    16,  1842,    67,  6283,   203,   203,  1106,  7766,  4870,\n",
      "           22,  2419,    30,   203,   203,   565,   632,  3845,  2039,   203,\n",
      "          565,  1652,  1729,    22,  1631,    12, 15056,    16,  4977,   270,\n",
      "        19706,  2218,  3576, 20364,  2187,  3455,  9231,    33,  8381,  4672,\n",
      "          203,  3639,  3536,  2276,   358,  1765,  1729,   358,  8275,  2887,\n",
      "          279,   585, 12123,   203,  3639,   810,   768,   273, 20650,    12,\n",
      "        15056,    18,  3015,  1435,   309,  1549,    12, 15056,    16,   609,\n",
      "           13,   469,  9813,    13,   203,  3639,  1765,   280,   273,  1729,\n",
      "           22,  1631,    18,  2620,    22,  1631,  1435,   203,  3639,   327,\n",
      "         1765,   280,    18,  6283,   768,    12,  2630,   768,    16,   296,\n",
      "         3813,  2187,  4977,   270, 19706,    16,  3455,  9231,    13,   203,\n",
      "          203,   565,   632,  3845,  2039,   203,   565,  1652,  8275,    22,\n",
      "         2620,    12,   917,   552,    16,  1729,  3202,  4672,   203,  3639,\n",
      "         3536,  2276,   358,  1765,  8275,   358,  1729,  2887,   279,   585,\n",
      "        12123,   203,  3639,   810,   768,   273, 20650,    12,  3890,    12,\n",
      "          917,   552,  3719,   203,  3639,   876,   768,   273, 20650,  1435,\n",
      "          203,  3639,  1542,   768,   273, 20650,    12,  2620,  3202,    18,\n",
      "         3015, 10756,   203,  3639,  1815,  8275,    22,  2620,    18,   591,\n",
      "          502,   451,  1419,    12,  2630,   768,    16,   876,   768,    16,\n",
      "         1542,   768,    13,   203,  3639,   327,   876,   768,    18,   588,\n",
      "         1132,  7675,  3922,  2668,  3158,    17,    28,  6134,   203,   203,\n",
      "          565,   632,  3845,  2039,   203,   565,  1652,  1056,  7705,    12,\n",
      "         1631,   768,    16,  2665,  4672,   203,  3639,  3536,  4759,   358,\n",
      "          866,   716,   732,  2363,   326,  2665,  1300,   434,  2743,  8395,\n",
      "          203,  3639,  3214,   273,   562,    12,  1631,   768,    18,  7705,\n",
      "           13,   203,  3639,   309,  3214,   405,   374,    30,   203,  5411,\n",
      "          309,  8275,   768,    18,  7705,    63,    20,  8009,   291,  3374,\n",
      "        13332,   203,  7734,  3214,   273,  3214,   300,   404,   203,  3639,\n",
      "         1172,    12,  1631,   768,    13,   203,  3639,  1815,  3214,   422,\n",
      "         2665,   203,   203,   565,   632,  3845,  2039,   203,   565,  1652,\n",
      "         3400,  4873,    12,  1631,   768,    16,  2836,  2696,    16,  2665,\n",
      "         4672,   203,  3639,  3536,  4759,   358,  1954,   279, 13803,   883,\n",
      "         8395,   203,  3639,   309,   486,  8275,   768,    18,  7705,    63,\n",
      "           20,  8009,   291,  3374, 13332,   203,  5411,  2836,  2696,   273,\n",
      "         2836,  2696,   300,   404,   203,  3639,  1172,  2668,  4873,  1084,\n",
      "           30,   296,   397,  8275,   768,    18,  7705,    63,  4873,  2696,\n",
      "         8009,  3168,   397,  6699,  6134,   203,  3639,  1172,  2668,  3825,\n",
      "           30,   296,   397,  2665,   397,  6699,  6134,   203,  3639,  1815,\n",
      "          609,    12,  1631,   768,    18,  7705,    63,  4873,  2696,  8009,\n",
      "         3168,    13,   422,   609,    12,  3825,    13,   203,   203,   565,\n",
      "         1652,   866,    67,  7526,    12,  2890,    16,  9813,    16,   761,\n",
      "          955,  4672,   203,  3639,  3536, 12366,   716, 14540,   333,  9813,\n",
      "        15505,   279,  2202,   930,   598,   460,   761,   955,  8395,   203,\n",
      "         3639,  8275,   768,   273,   365,    18,  2620,    22,  1631,    12,\n",
      "        15056,    13,   203,  3639,   365,    18,  1883,  7705,    12,  1631,\n",
      "          768,    16,   404,    13,   203,  3639,   365,    18,  9877,  4873,\n",
      "           12,  1631,   768,    16,   404,    16,   761,   955,    13,   203,\n",
      "          203,   565,  1652,   866,    67,  2011,    12,  2890,    16,  9813,\n",
      "         4672,   203,  3639,  3536, 12366,   716, 14540,   333,  9813, 15505,\n",
      "         1158,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "print ((train_dataset[0]))\n",
    "train_dataset.save_to_disk(fname_prefix + \"datasets/codet5_train_uncommented_bq_padded.hf\")\n",
    "test_dataset.save_to_disk(fname_prefix + \"datasets/codet5_test_uncommented_bq_padded.hf\")\n",
    "#print (combined_df[combined_df['content'] ==  \"File Error\"])\n",
    "#combined_df.to_csv(fname_prefix + 'data/labeled_code/full_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "988cc1e00d3b5bb0a2e9024406047781d3e298e90a30d1fcc633613d0d680479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
