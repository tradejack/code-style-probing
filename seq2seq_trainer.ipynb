{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "fname_prefix = \"/data/users/team2_capstone/code-style-probing/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4'\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_from_disk, load_metric\n",
    "#import datasets\n",
    "import pickle\n",
    "#from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/12dd1d7e87ade1728f8382f3b875a47cdddb88bc50797ecc506957411661a39a.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/c2ada6c76bb6a90c2330323775cb4853dd2b0cfee29d6b2c5ecb419c5874b488.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/354ae288bdee65437fa8eedecf9a2770001b97bac23d7fc5a04badae8da42346.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/f420b33feb234cfc688fa17febbada1c21692d80c819c5fa8147ccdca57071ac.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/467e224188b39d74622382aee9b73c080650b67706599bb5592d1dcf40149f9d.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"def replaceNegative(label):\\n    #print (label['labels'])\\n\\n    label['labels'] = [label['labels']]\\n    return label\\n\\ntrain_codet5_dataset = train_codet5_dataset.map(replaceNegative, batched = False)\\ntest_codet5_dataset = test_codet5_dataset.map(replaceNegative, batched = False)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base')\n",
    "train_codet5_dataset = load_from_disk(fname_prefix + 'datasets/codet5_train_uncommented_combined_padded.hf')\n",
    "test_codet5_dataset = load_from_disk(fname_prefix + 'datasets/codet5_test_uncommented_combined_padded.hf')\n",
    "\n",
    "\"\"\"def replaceNegative(label):\n",
    "    #print (label['labels'])\n",
    "\n",
    "    label['labels'] = [label['labels']]\n",
    "    return label\n",
    "\n",
    "train_codet5_dataset = train_codet5_dataset.map(replaceNegative, batched = False)\n",
    "test_codet5_dataset = test_codet5_dataset.map(replaceNegative, batched = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Salesforce/codet5-small/resolve/main/config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/ef13e715cbf36adda46c74774e8032ab573cfbb2ebe59748c9fc72b7cf67e418.96d28e790b8c3d3e3be663606a66e0793a173c78e745e3603be4c0f878319099\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Salesforce/codet5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Salesforce/codet5-small/resolve/main/pytorch_model.bin from cache at /soe/ksmunson/.cache/huggingface/transformers/72f18276a84809c5d2071dd664611f32bf6732788714ff4669de3b2d7becf4e8.f77f3daae184f7661a8837b1e043ddb86c279a9a71f866e7d286f68244bca50e\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Salesforce/codet5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/12dd1d7e87ade1728f8382f3b875a47cdddb88bc50797ecc506957411661a39a.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/c2ada6c76bb6a90c2330323775cb4853dd2b0cfee29d6b2c5ecb419c5874b488.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/354ae288bdee65437fa8eedecf9a2770001b97bac23d7fc5a04badae8da42346.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/f420b33feb234cfc688fa17febbada1c21692d80c819c5fa8147ccdca57071ac.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/467e224188b39d74622382aee9b73c080650b67706599bb5592d1dcf40149f9d.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'line_count', 'comment_count', 'comment_total_len', 'comment_avg_len', 'comment_density', 'id_total', 'lower_case', 'id_total_var', 'lower_case_var', 'snake_case_ratio', 'snake_case_var_ratio', 'snake_case_class_ratio', 'snake_case_method_ratio', 'lower_camel_case_ratio', 'lower_camel_case_var_ratio', 'lower_camel_case_class_ratio', 'lower_camel_case_method_ratio', 'upper_camel_case_ratio', 'upper_camel_case_var_ratio', 'upper_camel_case_class_ratio', 'upper_camel_case_method_ratio', 'lower_case_ratio', 'lower_case_var_ratio', 'lower_case_class_ratio', 'lower_case_method_ratio', 'upper_case_ratio', 'upper_case_var_ratio', 'upper_case_class_ratio', 'upper_case_method_ratio', 'other_case_ratio', 'other_case_var_ratio', 'other_case_class_ratio', 'other_case_method_ratio', 'func_decorators_avg', 'func_async_ratio', 'class_parents_avg', 'class_decorators_avg', 'ds_density', 'ds_char_len_avg', 'ds_word_len_avg', 'comprehensions_avg', 'generators_avg', 'lambda_avg', 'snake_case', 'snake_case_var', 'id_total_method', 'snake_case_method', 'func_count', 'func_decorators_count', 'lower_camel_case', 'lower_camel_case_var', 'upper_camel_case', 'id_total_class', 'upper_camel_case_class', 'class_count', 'class_parents_count', 'class_decorators_count', 'internal_method', 'overridden_method', 'upper_case', 'upper_case_var', 'upper_camel_case_var', 'lower_case_method', 'generators', 'ds_count', 'ds_char_len_total', 'ds_word_len_total', 'ds_line_count', 'ds_of_method', 'lambda', 'other_case', 'other_case_class', 'other_case_var', 'comprehensions', 'lower_camel_case_method', 'lower_case_class', 'snake_case_class', 'upper_camel_case_method', 'other_case_method', 'upper_case_method', 'lower_camel_case_class', 'upper_case_class', 'path', 'id', 'repository', 'filepath', 'forks', 'issue_events', 'stars', 'parse_error', 'func_async_count', 'file', 'labels', 'content', 'uncommented_content', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 37257\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'line_count', 'comment_count', 'comment_total_len', 'comment_avg_len', 'comment_density', 'id_total', 'lower_case', 'id_total_var', 'lower_case_var', 'snake_case_ratio', 'snake_case_var_ratio', 'snake_case_class_ratio', 'snake_case_method_ratio', 'lower_camel_case_ratio', 'lower_camel_case_var_ratio', 'lower_camel_case_class_ratio', 'lower_camel_case_method_ratio', 'upper_camel_case_ratio', 'upper_camel_case_var_ratio', 'upper_camel_case_class_ratio', 'upper_camel_case_method_ratio', 'lower_case_ratio', 'lower_case_var_ratio', 'lower_case_class_ratio', 'lower_case_method_ratio', 'upper_case_ratio', 'upper_case_var_ratio', 'upper_case_class_ratio', 'upper_case_method_ratio', 'other_case_ratio', 'other_case_var_ratio', 'other_case_class_ratio', 'other_case_method_ratio', 'func_decorators_avg', 'func_async_ratio', 'class_parents_avg', 'class_decorators_avg', 'ds_density', 'ds_char_len_avg', 'ds_word_len_avg', 'comprehensions_avg', 'generators_avg', 'lambda_avg', 'snake_case', 'snake_case_var', 'id_total_method', 'snake_case_method', 'func_count', 'func_decorators_count', 'lower_camel_case', 'lower_camel_case_var', 'upper_camel_case', 'id_total_class', 'upper_camel_case_class', 'class_count', 'class_parents_count', 'class_decorators_count', 'internal_method', 'overridden_method', 'upper_case', 'upper_case_var', 'upper_camel_case_var', 'lower_case_method', 'generators', 'ds_count', 'ds_char_len_total', 'ds_word_len_total', 'ds_line_count', 'ds_of_method', 'lambda', 'other_case', 'other_case_class', 'other_case_var', 'comprehensions', 'lower_camel_case_method', 'lower_case_class', 'snake_case_class', 'upper_camel_case_method', 'other_case_method', 'upper_case_method', 'lower_camel_case_class', 'upper_case_class', 'path', 'id', 'repository', 'filepath', 'forks', 'issue_events', 'stars', 'parse_error', 'func_async_count', 'file', 'labels', 'content', 'uncommented_content', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3240\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"Salesforce/codet5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "eval_dataset = test_codet5_dataset\n",
    "eval_dataset = eval_dataset.train_test_split(test_size = 0.08)\n",
    "print (eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /data/users/team2_capstone/code-style-probing//seq2seq_results/no_outlier_codet5small/checkpoint-51000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/data/users/team2_capstone/code-style-probing//seq2seq_results/no_outlier_codet5small/checkpoint-51000\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file /data/users/team2_capstone/code-style-probing//seq2seq_results/no_outlier_codet5small/checkpoint-51000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /data/users/team2_capstone/code-style-probing//seq2seq_results/no_outlier_codet5small/checkpoint-51000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "from transformers import AutoConfig\n",
    "\n",
    "#config = AutoConfig.from_pretrained(fname_prefix + \"/seq2seq_results/no_outlier_codet5small/checkpoint-51000\",    min_length = 20, max_length = 512, )\n",
    "model =AutoModelForSeq2SeqLM.from_pretrained(fname_prefix + \"/seq2seq_results/no_outlier_codet5small/checkpoint-51000\")\n",
    "model.config.max_length = 512\n",
    "#fname_prefix + /seq2seq_results/no_outlier_codet5small/checkpoint-50500\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    #f\"{model_name}-finetuned-xsum\",\n",
    "    output_dir= fname_prefix + \"/seq2seq_results/no_outlier_codet5small\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20000,\n",
    "    eval_accumulation_steps=200,\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=30,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    "\n",
    ")\n",
    "\n",
    "#data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     7,     5,    19, 13640,    19,  4757,    19,  3074,\n",
       "          5790,   203,     7,   300,    14,    17, 14848,    30,  7718,    17,\n",
       "            28,   300,    14,    17,   203,   203,     7, 25417,   261,    71,\n",
       "            13, 12461,    16,   478,  1074, 19861, 11473,    18,  8660, 20317,\n",
       "           348, 18739, 18465,   203,     7,  4826, 14989,  8735,    18,   203,\n",
       "           203,     7,  8505,  4027,   471,   999,   316,  1084,   471,  3112,\n",
       "         10138,    16,   598,   578,  2887,   203,     7, 11544,    16,   854,\n",
       "         15498,  2112,   716,   326,  3751,  4636,   854,  5100,    30,   203,\n",
       "           203,     7,   404,    18,  8505, 15326,   434,  1084,   981,  1297,\n",
       "         15096,   326,  5721, 22245, 11690,    16,   333,   203,     7,   666,\n",
       "           434,  4636,   471,   326,  3751,  1015,   830,    69,  4417,    18,\n",
       "           203,   203,     7,   576,    18,  8505, 15326,   316,  3112,   646,\n",
       "          1297,   283, 11776,   311,   326,  5721, 22245, 11690,    16,   203,\n",
       "             7,   333,   666,   434,  4636,   471,   326,  3751,  1015,   830,\n",
       "            69,  4417,   316,   326,  7323,   203,     7,   471,    19,   280,\n",
       "          1308, 31824,  2112,   598,   326,  7006,    18,   203,   203,     7,\n",
       "         20676,   348,  3932, 18869,  9332,  4437,  4629, 15472,  2056,  6953,\n",
       "         12786, 27776, 11847,   670, 11753,    55,  4116,  3492,  6566,    38,\n",
       "          1693, 14006,   315,  3033,  4437,     6,  4116,   203,     7, 16743,\n",
       "          5675, 22526,  4869, 15694,  2053,  2056,   678,   985,    54,  6856,\n",
       "          8805,    16,  2120, 11686,    40,  1360,    16,   605,  1693,  4269,\n",
       "         13319,  2056,  8493,    16, 12786, 15694,  2053,  2056,   203,     7,\n",
       "           678,   985,    54,  6856,  8805, 15932,   490,   654,  1792,  6856,\n",
       "         22879,  4116,   478,  1285,  5407,  1260, 12108,   432, 20814,  2871,\n",
       "         19545, 30817,   432,   862,  3690,  2312,  2534,  3114,    40,    18,\n",
       "          2120,  3741,   203,     7,  9964,  6122,  4685, 12786, 27776, 11847,\n",
       "           670, 11753,  4869,  3492,  6566,    38,  1693, 14006,  9722,  8961,\n",
       "          2782, 12108, 16743, 29100,    16,  2120, 17541,    16,  2120,    39,\n",
       "         13355,  1013,    16,   203,     7, 22872,  6365,    16,  5675,  3375,\n",
       "          6253,  6043,    16,  4869,  3492,  1090,  3500,  2222,  6365,   463,\n",
       "          2192,  2833,    55,   261,   706, 11686,    40,  1360,    16,   605,\n",
       "          1693,  4269, 13319,  2056,  8493,    16,  4629,    39,  4830,  3212,\n",
       "         15932, 10025,   882,  1285,  9099, 12389,  1212,    55,  4869,   203,\n",
       "             7, 12828,    55,    31,  1806,  1260, 15932, 14988,    16,  8730,\n",
       "            16,  4869,  4629,    42, 10158,    31,  4869,   605,  3378,  3740,\n",
       "          1260,  6137,  9712,    57,  3725,    13, 11705,  6950,  2204,  6425,\n",
       "         20093,  4116,  6229,   203,     7, 16743, 12786,  3964, 15932,  8961,\n",
       "         22879,    16, 14735,  1584,  3891,  2120,  8020,  2849,  1268,    16,\n",
       "          2347,  2259,  1268,  8961, 22879,    16,  4869,   399,  3871,   261,\n",
       "           706, 11686,    40,  1360,   203,     7, 12901,    43,  2053,    43,\n",
       "          7535,  4869, 22478, 23109,  1090,    13,   432,  2259, 23708,  2120,\n",
       "         16743,   678,  5255,  8210, 15932, 12786, 14988, 15932, 20676,   348,\n",
       "          3932, 18869,  9332,    16, 14839,  1157, 11083, 11738,  4136, 18204,\n",
       "         15932, 12786,   203,     7, 13803,  1260, 13450, 14674, 15932, 11726,\n",
       "          1792,   463,  2192,  2833,    18,   203,   203,   203,  2080,  2395,\n",
       "            18, 16239,   203,   203,   203,     7,  1220,   353,   279,  4143,\n",
       "          3454,   434,   326,   981,   316,  2395,    18,  3813,    18,  3813,\n",
       "            67,   915,   203,     7,  2597,   353,   279,  4143,  3454,   434,\n",
       "          2395,    18,  3813,    18,  3813,    67,   915,   203,     7,  2597,\n",
       "           353,   279,  4143,  3454,   434,  2395,    18,  3813,    18,  3813,\n",
       "            67,   915,   203,     7,  2597,   353,   279,  4143,  3454,   434,\n",
       "          2395,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_codet5_dataset ,\n",
    "    eval_dataset=test_codet5_dataset,\n",
    "    #data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")\n",
    "model.generate()\n",
    "#\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: lower_case_method_ratio, other_case_var, lower_case_var, comprehensions_avg, other_case_ratio, lower_camel_case_class, ds_char_len_avg, forks, lower_camel_case_ratio, ds_count, lower_camel_case_class_ratio, func_async_ratio, lower_case, upper_camel_case_method_ratio, other_case_method_ratio, upper_case_method_ratio, func_async_count, class_decorators_count, file, func_count, comment_count, lower_case_ratio, content, func_decorators_count, upper_camel_case_class_ratio, generators, upper_camel_case_ratio, lambda, internal_method, upper_case_class, ds_word_len_total, lower_case_var_ratio, lower_case_class_ratio, lower_case_method, upper_camel_case_var, Unnamed: 0.1, comment_total_len, id_total, parse_error, other_case_method, upper_case_var_ratio, comprehensions, id_total_method, ds_word_len_avg, upper_case_ratio, overridden_method, snake_case_class_ratio, snake_case_var, id_total_var, snake_case_class, other_case_class, upper_case, lower_camel_case_var_ratio, class_decorators_avg, snake_case_ratio, id_total_class, lower_case_class, path, ds_char_len_total, upper_camel_case_class, upper_case_class_ratio, snake_case_method, lambda_avg, repository, other_case_class_ratio, lower_camel_case_method, other_case_var_ratio, snake_case_method_ratio, id, upper_camel_case, comment_density, snake_case_var_ratio, upper_case_method, class_parents_avg, Unnamed: 0, lower_camel_case_method_ratio, ds_density, filepath, func_decorators_avg, snake_case, __index_level_0__, stars, ds_of_method, class_parents_count, line_count, lower_camel_case, ds_line_count, generators_avg, upper_camel_case_method, comment_avg_len, uncommented_content, lower_camel_case_var, class_count, other_case, upper_case_var, issue_events, upper_camel_case_var_ratio. If lower_case_method_ratio, other_case_var, lower_case_var, comprehensions_avg, other_case_ratio, lower_camel_case_class, ds_char_len_avg, forks, lower_camel_case_ratio, ds_count, lower_camel_case_class_ratio, func_async_ratio, lower_case, upper_camel_case_method_ratio, other_case_method_ratio, upper_case_method_ratio, func_async_count, class_decorators_count, file, func_count, comment_count, lower_case_ratio, content, func_decorators_count, upper_camel_case_class_ratio, generators, upper_camel_case_ratio, lambda, internal_method, upper_case_class, ds_word_len_total, lower_case_var_ratio, lower_case_class_ratio, lower_case_method, upper_camel_case_var, Unnamed: 0.1, comment_total_len, id_total, parse_error, other_case_method, upper_case_var_ratio, comprehensions, id_total_method, ds_word_len_avg, upper_case_ratio, overridden_method, snake_case_class_ratio, snake_case_var, id_total_var, snake_case_class, other_case_class, upper_case, lower_camel_case_var_ratio, class_decorators_avg, snake_case_ratio, id_total_class, lower_case_class, path, ds_char_len_total, upper_camel_case_class, upper_case_class_ratio, snake_case_method, lambda_avg, repository, other_case_class_ratio, lower_camel_case_method, other_case_var_ratio, snake_case_method_ratio, id, upper_camel_case, comment_density, snake_case_var_ratio, upper_case_method, class_parents_avg, Unnamed: 0, lower_camel_case_method_ratio, ds_density, filepath, func_decorators_avg, snake_case, __index_level_0__, stars, ds_of_method, class_parents_count, line_count, lower_camel_case, ds_line_count, generators_avg, upper_camel_case_method, comment_avg_len, uncommented_content, lower_camel_case_var, class_count, other_case, upper_case_var, issue_events, upper_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3240\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='203' max='203' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [203/203 12:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_preds = trainer.predict(eval_dataset['test']) #, min_length=40, max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 512)\n",
      "pred: import datetime\n",
      "try:\n",
      "    from urlparse import urlparse\n",
      "except ImportError:\n",
      "    from urllib.parse import urlparse\n",
      "from xml.dom import minidom\n",
      "\n",
      "from django.conf import settings\n",
      "from django.test.client import RequestFactory\n",
      "from django.template import Template, Context\n",
      "from django.core.urlresolvers import reverse\n",
      "from django.test import TestCase\n",
      "from django.utils.unittest import skipIf\n",
      "\n",
      "from paypal.pro.models import PayPalNVP\n",
      "\n",
      "from billing import get_gateway, get_integration, CreditCard\n",
      "from billing.signals import *\n",
      "from billing.gateway import CardNotSupported\n",
      "from billing.utils.credit_card import Visa\n",
      "\n",
      "RF = RequestFactory()\n",
      "\n",
      "request = RF.get('/', REMOTE_ADDR='192.168.1.1')\n",
      "\n",
      "fake_options = {\n",
      "   'request': request,\n",
      "    'email': 'testuser@fakedomain.com',\n",
      "    'billing_address': {\n",
      "        'name': 'PayPal User',\n",
      "        'address1': 'Street 1',\n",
      "        'city': 'Mountain View',\n",
      "       'state': 'CA',\n",
      "        'country': 'US',\n",
      "        'zip': '94043',\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "@skipIf(not settings.MERCHANT_SETTINGS.get('pay_pal', None), 'gateway not configured')\n",
      "class PayPalGatewayTestCase(TestCase):\n",
      "    def setUp(self):\n",
      "        self.merchant = get_gateway('pay_pal')\n",
      "        self.merchant.test_mode = True\n",
      "        self.credit_card = CreditCard(\n",
      "            first_name='Test',\n",
      "            last_name='User',\n",
      "            month=10,\n",
      "            year=2017,\n",
      "            number='4500775008976759',\n",
      "            verification_value='000',\n",
      "        )\n",
      "\n",
      "    def testCardSupported(self):\n",
      "        self.credit_card.number = '501922222222222222'\n",
      "        self.assertRaises(CardNotSupported, lambda: self.merchant.purchase(1000, self.credit_card))\n",
      "\n",
      "    def testCardValidated(self):\n",
      "        self.merchant.test_mode = False\n",
      "        self.credit_card.number = '4222222222222123'\n",
      "        self.\n",
      "label: import datetime\n",
      "try:\n",
      "    from urlparse import urlparse\n",
      "except ImportError:\n",
      "    # Python3\n",
      "    from urllib.parse import urlparse\n",
      "from xml.dom import minidom\n",
      "\n",
      "from django.conf import settings\n",
      "from django.test.client import RequestFactory\n",
      "from django.template import Template, Context\n",
      "from django.core.urlresolvers import reverse\n",
      "from django.test import TestCase\n",
      "from django.utils.unittest import skipIf\n",
      "\n",
      "from paypal.pro.models import PayPalNVP\n",
      "\n",
      "from billing import get_gateway, get_integration, CreditCard\n",
      "from billing.signals import *\n",
      "from billing.gateway import CardNotSupported\n",
      "from billing.utils.credit_card import Visa\n",
      "\n",
      "RF = RequestFactory()\n",
      "request = RF.get(\"/\", REMOTE_ADDR=\"192.168.1.1\")\n",
      "fake_options = {\n",
      "    \"request\": request,\n",
      "    \"email\": \"testuser@fakedomain.com\",\n",
      "    \"billing_address\": {\n",
      "        \"name\": \"PayPal User\",\n",
      "        \"address1\": \"Street 1\",\n",
      "        \"city\": \"Mountain View\",\n",
      "        \"state\": \"CA\",\n",
      "        \"country\": \"US\",\n",
      "        \"zip\": \"94043\"\n",
      "    },\n",
      "}\n",
      "\n",
      "@skipIf(not settings.MERCHANT_SETTINGS.get(\"pay_pal\", None), \"gateway not configured\")\n",
      "class PayPalGatewayTestCase(TestCase):\n",
      "    def setUp(self):\n",
      "        self.merchant = get_gateway(\"pay_pal\")\n",
      "        self.merchant.test_mode = True\n",
      "        self.credit_card = CreditCard(first_name=\"Test\", last_name=\"User\",\n",
      "                                      month=10, year=2017,\n",
      "                                      number=\"4500775008976759\",\n",
      "                                      verification_value=\"000\")\n",
      "\n",
      "    def testCardSupported(self):\n",
      "        self.credit_card.number = \"5019222222222222\"\n",
      "        self.assertRaises(CardNotSupported,\n",
      "                          lambda: self.merchant.purchase(1000,\n",
      "                                                         self.credit_card))\n",
      "\n",
      "    def testCardValidated(self):\n",
      "        self.merchant.test_mode = False\n",
      "        self.credit_card.number = \"4222222222222123\"\n",
      "        self.\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, report  = eval_preds\n",
    "print (predictions.shape)\n",
    "idx = 30\n",
    "decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "print (\"pred:\", decoded_preds[idx]) \n",
    "print (\"label:\", decode_labels[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "988cc1e00d3b5bb0a2e9024406047781d3e298e90a30d1fcc633613d0d680479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
