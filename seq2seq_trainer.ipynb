{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "fname_prefix = \"/data/users/team2_capstone/code-style-probing/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_from_disk, load_metric\n",
    "#import datasets\n",
    "import pickle\n",
    "#from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/12dd1d7e87ade1728f8382f3b875a47cdddb88bc50797ecc506957411661a39a.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/c2ada6c76bb6a90c2330323775cb4853dd2b0cfee29d6b2c5ecb419c5874b488.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/354ae288bdee65437fa8eedecf9a2770001b97bac23d7fc5a04badae8da42346.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/f420b33feb234cfc688fa17febbada1c21692d80c819c5fa8147ccdca57071ac.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/467e224188b39d74622382aee9b73c080650b67706599bb5592d1dcf40149f9d.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'train_codet5_dataset = load_from_disk(fname_prefix + \"datasets/codet5_train_docstring_bq_padded.hf\")\\nid = 70000\\ndups = 0\\nprint (len(train_codet5_dataset))\\nfor id in range(0,1000):\\n    #input = (tokenizer.decode(train_codet5_dataset[id* 100][\\'input_ids\\'], skip_special_tokens=True))\\n    #label = (tokenizer.decode(train_codet5_dataset[id* 100][\\'labels\\'], skip_special_tokens=True))\\n    input = (train_codet5_dataset[id* 100][\\'input_ids\\'])\\n    label = (train_codet5_dataset[id* 100][\\'labels\\'])\\n       if \"\"\"\"\" in input:\\n        print (\"============================\")\\n        print (input)\\n        print(\"++++++++++++++\")\\n        print (label)\\n    if input == label:\\n        dups +=1\\nprint (dups)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "\"\"\"train_codet5_dataset = load_from_disk(fname_prefix + \"datasets/codet5_train_docstring_bq_padded.hf\")\n",
    "id = 70000\n",
    "dups = 0\n",
    "print (len(train_codet5_dataset))\n",
    "for id in range(0,1000):\n",
    "    #input = (tokenizer.decode(train_codet5_dataset[id* 100]['input_ids'], skip_special_tokens=True))\n",
    "    #label = (tokenizer.decode(train_codet5_dataset[id* 100]['labels'], skip_special_tokens=True))\n",
    "    input = (train_codet5_dataset[id* 100]['input_ids'])\n",
    "    label = (train_codet5_dataset[id* 100]['labels'])\n",
    "       if \"\\\"\\\"\\\"\" in input:\n",
    "        print (\"============================\")\n",
    "        print (input)\n",
    "        print(\"++++++++++++++\")\n",
    "        print (label)\n",
    "    if input == label:\n",
    "        dups +=1\n",
    "print (dups)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def replaceNegative(label):\\n    #print (label['labels'])\\n\\n    label['labels'] = [label['labels']]\\n    return label\\n\\ntrain_codet5_dataset = train_codet5_dataset.map(replaceNegative, batched = False)\\ntest_codet5_dataset = test_codet5_dataset.map(replaceNegative, batched = False)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base')\n",
    "train_codet5_dataset = load_from_disk(fname_prefix + 'datasets/codet5_train_docstring_bq_padded.hf')\n",
    "test_codet5_dataset = load_from_disk(fname_prefix + 'datasets/codet5_test_docstring_bq_padded.hf') #codet5_train_class_bq_padded.hf\n",
    "\n",
    "\"\"\"def replaceNegative(label):\n",
    "    #print (label['labels'])\n",
    "\n",
    "    label['labels'] = [label['labels']]\n",
    "    return label\n",
    "\n",
    "train_codet5_dataset = train_codet5_dataset.map(replaceNegative, batched = False)\n",
    "test_codet5_dataset = test_codet5_dataset.map(replaceNegative, batched = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Salesforce/codet5-small/resolve/main/config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/ef13e715cbf36adda46c74774e8032ab573cfbb2ebe59748c9fc72b7cf67e418.96d28e790b8c3d3e3be663606a66e0793a173c78e745e3603be4c0f878319099\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Salesforce/codet5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Salesforce/codet5-small/resolve/main/pytorch_model.bin from cache at /soe/ksmunson/.cache/huggingface/transformers/72f18276a84809c5d2071dd664611f32bf6732788714ff4669de3b2d7becf4e8.f77f3daae184f7661a8837b1e043ddb86c279a9a71f866e7d286f68244bca50e\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Salesforce/codet5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/12dd1d7e87ade1728f8382f3b875a47cdddb88bc50797ecc506957411661a39a.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/c2ada6c76bb6a90c2330323775cb4853dd2b0cfee29d6b2c5ecb419c5874b488.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/354ae288bdee65437fa8eedecf9a2770001b97bac23d7fc5a04badae8da42346.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/f420b33feb234cfc688fa17febbada1c21692d80c819c5fa8147ccdca57071ac.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-small/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/467e224188b39d74622382aee9b73c080650b67706599bb5592d1dcf40149f9d.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'repository', 'filepath', 'forks', 'issue_events', 'stars', 'parse_error', 'line_count', 'comment_count', 'comment_avg_len', 'comment_density', 'id_total', 'lower_case', 'id_total_var', 'lower_case_var', 'snake_case', 'snake_case_var', 'lower_camel_case', 'lower_camel_case_var', 'snake_case_ratio', 'snake_case_var_ratio', 'snake_case_class_ratio', 'snake_case_method_ratio', 'lower_camel_case_ratio', 'lower_camel_case_var_ratio', 'lower_camel_case_class_ratio', 'lower_camel_case_method_ratio', 'upper_camel_case_ratio', 'upper_camel_case_var_ratio', 'upper_camel_case_class_ratio', 'upper_camel_case_method_ratio', 'lower_case_ratio', 'lower_case_var_ratio', 'lower_case_class_ratio', 'lower_case_method_ratio', 'upper_case_ratio', 'upper_case_var_ratio', 'upper_case_class_ratio', 'upper_case_method_ratio', 'other_case_ratio', 'other_case_var_ratio', 'other_case_class_ratio', 'other_case_method_ratio', 'func_decorators_avg', 'func_async_ratio', 'class_parents_avg', 'class_decorators_avg', 'ds_density', 'ds_char_len_avg', 'ds_word_len_avg', 'comprehensions_avg', 'generators_avg', 'lambda_avg', 'comment_total_len', 'upper_camel_case', 'id_total_class', 'upper_camel_case_class', 'ds_count', 'ds_char_len_total', 'ds_word_len_total', 'ds_line_count', 'class_count', 'class_parents_count', 'class_decorators_count', 'upper_camel_case_var', 'id_total_method', 'snake_case_method', 'internal_method', 'overridden_method', 'ds_of_method', 'func_count', 'func_decorators_count', 'comprehensions', 'lambda', 'other_case', 'other_case_var', 'upper_case', 'upper_case_var', 'lower_camel_case_method', 'lower_case_method', 'other_case_class', 'func_async_count', 'generators', 'lower_case_class', 'snake_case_class', 'upper_camel_case_method', 'other_case_method', 'upper_case_class', 'lower_camel_case_class', 'upper_case_method', 'file', 'labels', 'content', 'no_docstring_content', 'uncommented_content', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 64481\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'repository', 'filepath', 'forks', 'issue_events', 'stars', 'parse_error', 'line_count', 'comment_count', 'comment_avg_len', 'comment_density', 'id_total', 'lower_case', 'id_total_var', 'lower_case_var', 'snake_case', 'snake_case_var', 'lower_camel_case', 'lower_camel_case_var', 'snake_case_ratio', 'snake_case_var_ratio', 'snake_case_class_ratio', 'snake_case_method_ratio', 'lower_camel_case_ratio', 'lower_camel_case_var_ratio', 'lower_camel_case_class_ratio', 'lower_camel_case_method_ratio', 'upper_camel_case_ratio', 'upper_camel_case_var_ratio', 'upper_camel_case_class_ratio', 'upper_camel_case_method_ratio', 'lower_case_ratio', 'lower_case_var_ratio', 'lower_case_class_ratio', 'lower_case_method_ratio', 'upper_case_ratio', 'upper_case_var_ratio', 'upper_case_class_ratio', 'upper_case_method_ratio', 'other_case_ratio', 'other_case_var_ratio', 'other_case_class_ratio', 'other_case_method_ratio', 'func_decorators_avg', 'func_async_ratio', 'class_parents_avg', 'class_decorators_avg', 'ds_density', 'ds_char_len_avg', 'ds_word_len_avg', 'comprehensions_avg', 'generators_avg', 'lambda_avg', 'comment_total_len', 'upper_camel_case', 'id_total_class', 'upper_camel_case_class', 'ds_count', 'ds_char_len_total', 'ds_word_len_total', 'ds_line_count', 'class_count', 'class_parents_count', 'class_decorators_count', 'upper_camel_case_var', 'id_total_method', 'snake_case_method', 'internal_method', 'overridden_method', 'ds_of_method', 'func_count', 'func_decorators_count', 'comprehensions', 'lambda', 'other_case', 'other_case_var', 'upper_case', 'upper_case_var', 'lower_camel_case_method', 'lower_case_method', 'other_case_class', 'func_async_count', 'generators', 'lower_case_class', 'snake_case_class', 'upper_camel_case_method', 'other_case_method', 'upper_case_class', 'lower_camel_case_class', 'upper_case_method', 'file', 'labels', 'content', 'no_docstring_content', 'uncommented_content', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 5608\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"Salesforce/codet5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "eval_dataset = test_codet5_dataset\n",
    "eval_dataset = eval_dataset.train_test_split(test_size = 0.08)\n",
    "print (eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_length\": 512,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 24\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "from transformers import AutoConfig\n",
    "\n",
    "#config = AutoConfig.from_pretrained(fname_prefix + \"/seq2seq_results/no_outlier_codet5small/checkpoint-51000\",    min_length = 20, max_length = 512, )\n",
    "#model =AutoModelForSeq2SeqLM.from_pretrained(fname_prefix + \"/seq2seq_results/outlier_codet5small/checkpoint-40500\")\n",
    "#model =AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-small\")\n",
    "model =AutoModelForSeq2SeqLM.from_pretrained(fname_prefix + \"/seq2seq_results/outlier_docstring_codet5small/checkpoint-46000\")\n",
    "model.config.max_length = 512\n",
    "#fname_prefix + /seq2seq_results/no_outlier_codet5small/checkpoint-50500\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    #f\"{model_name}-finetuned-xsum\",\n",
    "    output_dir= fname_prefix + \"/seq2seq_results/outlier_docstring_codet5small\",\n",
    "    evaluation_strategy='epoch',\n",
    "    #eval_steps=20000,\n",
    "    eval_accumulation_steps=200,\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=30,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    "\n",
    ")\n",
    "\n",
    "#data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio. If upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 280354\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 24\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46728' max='46728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46728/46728 7:36:46, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.484005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.462938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>0.433287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-42500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio. If upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 70089\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio. If upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 70089\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-20000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio. If upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 70089\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46500\n",
      "Configuration saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46500/config.json\n",
      "Model weights saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in /data/users/team2_capstone/code-style-probing//seq2seq_results/outlier_docstring_codet5small/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [/data/users/team2_capstone/code-style-probing/seq2seq_results/outlier_docstring_codet5small/checkpoint-31500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio. If upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 70089\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=46728, training_loss=0.4758622658169039, metrics={'train_runtime': 27408.2378, 'train_samples_per_second': 40.915, 'train_steps_per_second': 1.705, 'total_flos': 1.5177446163952435e+17, 'train_loss': 0.4758622658169039, 'epoch': 4.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_codet5_dataset ,\n",
    "    eval_dataset=test_codet5_dataset,\n",
    "    #data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    ")\n",
    "#model.generate()\n",
    "#\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio. If upper_camel_case_var, __index_level_0__, id_total_method, snake_case_method, Unnamed: 0.1, other_case, id_total_class, comment_density, func_decorators_avg, ds_word_len_avg, other_case_var, lower_case_class_ratio, uncommented_content, lower_camel_case_ratio, ds_line_count, class_decorators_count, content, func_async_ratio, lower_case_class, lower_camel_case_method, snake_case, issue_events, snake_case_var_ratio, upper_camel_case_class, upper_case_var, func_count, ds_char_len_avg, upper_case_class, overridden_method, file, other_case_var_ratio, upper_case, lower_camel_case_class_ratio, other_case_class, other_case_method, comment_avg_len, lower_case_ratio, comment_total_len, filepath, upper_camel_case_method, class_decorators_avg, upper_case_var_ratio, lambda_avg, upper_case_method_ratio, generators, other_case_method_ratio, comment_count, id_total_var, no_docstring_content, generators_avg, id_total, other_case_class_ratio, lambda, repository, upper_camel_case_ratio, forks, comprehensions, parse_error, lower_case_var_ratio, class_count, upper_camel_case_var_ratio, ds_count, lower_camel_case_method_ratio, internal_method, comprehensions_avg, lower_camel_case_var, other_case_ratio, lower_camel_case, upper_case_ratio, ds_density, lower_case_method, stars, snake_case_var, lower_case_var, lower_case, snake_case_class, func_decorators_count, upper_case_method, ds_char_len_total, ds_word_len_total, Unnamed: 0, lower_camel_case_class, snake_case_ratio, upper_camel_case_method_ratio, snake_case_class_ratio, class_parents_avg, line_count, class_parents_count, lower_case_method_ratio, func_async_count, upper_camel_case, snake_case_method_ratio, ds_of_method, upper_camel_case_class_ratio, upper_case_class_ratio, lower_camel_case_var_ratio are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5608\n",
      "  Batch size = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 13:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_preds = trainer.predict(eval_dataset['test']) #, min_length=40, max_length = 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, report  = eval_preds\n",
    "decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "df = pd.DataFrame(decoded_preds,  columns = [\"preds\"])\n",
    "df['labels'] = decoded_labels\n",
    "#print (decoded_labels[0])\n",
    "df.to_csv(fname_prefix + 'seq2seq_results/outlier_docstring_codet5small/codet5_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idx = 30\\nmetric = load_metric(\"bleu\") #this doesnt work for some reason\\n#metric = load_metric()\\ndef compute_metrics(eval_preds):\\n    predictions, labels, report  = eval_preds\\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\\n    df = pd.DataFrame(decoded_preds,  columns = [\"preds\"])\\n    df[\\'labels\\'] = decoded_labels\\n    #print (decoded_labels[0])\\n    df.to_csv(fname_prefix + \\'seq2seq_results/no_outlier_codet5small/codet5_preds.csv\\')\\n    return metric.compute(predictions=decoded_preds, references=decoded_labels)\\n\\ncompute_metrics(eval_preds)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"\"\"idx = 30\n",
    "metric = load_metric(\"bleu\") #this doesnt work for some reason\n",
    "#metric = load_metric()\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels, report  = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    df = pd.DataFrame(decoded_preds,  columns = [\"preds\"])\n",
    "    df['labels'] = decoded_labels\n",
    "    #print (decoded_labels[0])\n",
    "    df.to_csv(fname_prefix + 'seq2seq_results/no_outlier_codet5small/codet5_preds.csv')\n",
    "    return metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "compute_metrics(eval_preds)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "988cc1e00d3b5bb0a2e9024406047781d3e298e90a30d1fcc633613d0d680479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
