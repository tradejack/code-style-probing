{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for training pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_prefix = \"/data/users/team2_capstone/code-style-probing/\"\n",
    "\n",
    "target_features = [\n",
    "     'snake_case_var_ratio',\n",
    "     'snake_case_class_ratio',\n",
    "     'snake_case_method_ratio',\n",
    "     'upper_camel_case_var_ratio',\n",
    "     'upper_camel_case_class_ratio',\n",
    "     'upper_camel_case_method_ratio',\n",
    "     'lower_camel_case_var_ratio',\n",
    "     'lower_camel_case_class_ratio',\n",
    "     'lower_camel_case_method_ratio',\n",
    "     'func_decorators_avg',\n",
    "     'class_decorators_avg',\n",
    "     'class_parents_avg',\n",
    "     'comprehensions_avg',\n",
    "     'generators_avg',\n",
    "     'lambda_avg',\n",
    "     'comment_density',\n",
    "     'ds_density',\n",
    "]\n",
    "PY150K_DIR = fname_prefix + \"data/py150\"\n",
    "PY150K_CODE_DIR = fname_prefix + \"data/py150/py150_files\"\n",
    "PY150K_TRAIN_AST = fname_prefix + \"data/py150/python100k_train.json\"\n",
    "PY150K_EVAL_AST = fname_prefix + \"data/py150/python50k_eval.json\"\n",
    "PY150K_TRAIN_CODE = fname_prefix + \"data/py150/py150_files/python100k_train.txt\"\n",
    "PY150K_EVAL_CODE = fname_prefix + \"data/py150/py150_files/python50k_eval.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository</th>\n",
       "      <th>filepath</th>\n",
       "      <th>forks</th>\n",
       "      <th>issue_events</th>\n",
       "      <th>stars</th>\n",
       "      <th>parse_error</th>\n",
       "      <th>line_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comment_avg_len</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>...</th>\n",
       "      <th>other_case_class</th>\n",
       "      <th>func_async_count</th>\n",
       "      <th>generators</th>\n",
       "      <th>lower_case_class</th>\n",
       "      <th>snake_case_class</th>\n",
       "      <th>upper_camel_case_method</th>\n",
       "      <th>other_case_method</th>\n",
       "      <th>upper_case_class</th>\n",
       "      <th>lower_camel_case_class</th>\n",
       "      <th>upper_case_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jbkalmbach/kbmod</td>\n",
       "      <td>analysis/rawGenerated/batchGenerate.py</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pymedusa/SickRage</td>\n",
       "      <td>medusa/providers/torrent/rss/rsstorrent.py</td>\n",
       "      <td>22</td>\n",
       "      <td>763</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>170.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.625000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ipdata/python</td>\n",
       "      <td>ipdata/test_cli.py</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.352941</td>\n",
       "      <td>0.251852</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>demisto/content</td>\n",
       "      <td>Packs/AnsibleLinux/Integrations/AnsibleACME/An...</td>\n",
       "      <td>1328</td>\n",
       "      <td>52</td>\n",
       "      <td>797</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.818182</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hidat/audio_pipeline</td>\n",
       "      <td>review_parser/mb_release.py</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.166667</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87927</th>\n",
       "      <td>operepo/ope</td>\n",
       "      <td>libs/gluon/packages/dal/pydal/adapters/sqlite.py</td>\n",
       "      <td>8</td>\n",
       "      <td>138</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>279.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.857143</td>\n",
       "      <td>0.050179</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87928</th>\n",
       "      <td>DOV-Vlaanderen/pydov</td>\n",
       "      <td>setup.py</td>\n",
       "      <td>17</td>\n",
       "      <td>287</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87929</th>\n",
       "      <td>slogan621/tscharts</td>\n",
       "      <td>apps/xrayuploader/xrayuploader.py</td>\n",
       "      <td>8</td>\n",
       "      <td>97</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>502.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>49.300000</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87930</th>\n",
       "      <td>seasonstar/bibi</td>\n",
       "      <td>application/models/order/logistic.py</td>\n",
       "      <td>365</td>\n",
       "      <td>12</td>\n",
       "      <td>1016</td>\n",
       "      <td>1</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87931</th>\n",
       "      <td>lablup/sorna-repl</td>\n",
       "      <td>python-theano/run.py</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.833333</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875096 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 repository  \\\n",
       "0          jbkalmbach/kbmod   \n",
       "1         pymedusa/SickRage   \n",
       "2             ipdata/python   \n",
       "3           demisto/content   \n",
       "4      hidat/audio_pipeline   \n",
       "...                     ...   \n",
       "87927           operepo/ope   \n",
       "87928  DOV-Vlaanderen/pydov   \n",
       "87929    slogan621/tscharts   \n",
       "87930       seasonstar/bibi   \n",
       "87931     lablup/sorna-repl   \n",
       "\n",
       "                                                filepath  forks  issue_events  \\\n",
       "0                 analysis/rawGenerated/batchGenerate.py      1            32   \n",
       "1             medusa/providers/torrent/rss/rsstorrent.py     22           763   \n",
       "2                                     ipdata/test_cli.py      6            15   \n",
       "3      Packs/AnsibleLinux/Integrations/AnsibleACME/An...   1328            52   \n",
       "4                            review_parser/mb_release.py      1            26   \n",
       "...                                                  ...    ...           ...   \n",
       "87927   libs/gluon/packages/dal/pydal/adapters/sqlite.py      8           138   \n",
       "87928                                           setup.py     17           287   \n",
       "87929                  apps/xrayuploader/xrayuploader.py      8            97   \n",
       "87930               application/models/order/logistic.py    365            12   \n",
       "87931                               python-theano/run.py      2            56   \n",
       "\n",
       "       stars  parse_error  line_count  comment_count  comment_avg_len  \\\n",
       "0          1            1        51.0            0.0         0.000000   \n",
       "1         27            1       170.0            8.0        17.625000   \n",
       "2         16            1       135.0           34.0        37.352941   \n",
       "3        797            1        59.0           11.0        26.818182   \n",
       "4          4            1        76.0           12.0        37.166667   \n",
       "...      ...          ...         ...            ...              ...   \n",
       "87927      9            1       279.0           14.0        43.857143   \n",
       "87928     31            1        66.0            3.0        25.666667   \n",
       "87929     16            1       502.0           20.0        49.300000   \n",
       "87930   1016            1       434.0            1.0        23.000000   \n",
       "87931     14            1       179.0            6.0        35.833333   \n",
       "\n",
       "       comment_density  ...  other_case_class  func_async_count  generators  \\\n",
       "0             0.000000  ...               NaN               NaN         NaN   \n",
       "1             0.047059  ...               NaN               NaN         NaN   \n",
       "2             0.251852  ...               NaN               NaN         NaN   \n",
       "3             0.186441  ...               NaN               NaN         NaN   \n",
       "4             0.157895  ...               2.0               NaN         NaN   \n",
       "...                ...  ...               ...               ...         ...   \n",
       "87927         0.050179  ...               2.0               NaN         NaN   \n",
       "87928         0.045455  ...               NaN               NaN         NaN   \n",
       "87929         0.039841  ...               2.0               NaN         NaN   \n",
       "87930         0.002304  ...               NaN               NaN         3.0   \n",
       "87931         0.033520  ...               NaN               NaN         NaN   \n",
       "\n",
       "       lower_case_class  snake_case_class  upper_camel_case_method  \\\n",
       "0                   NaN               NaN                      NaN   \n",
       "1                   NaN               NaN                      NaN   \n",
       "2                   NaN               NaN                      NaN   \n",
       "3                   NaN               NaN                      NaN   \n",
       "4                   NaN               NaN                      NaN   \n",
       "...                 ...               ...                      ...   \n",
       "87927               NaN               NaN                      NaN   \n",
       "87928               NaN               NaN                      NaN   \n",
       "87929               NaN               NaN                      NaN   \n",
       "87930               NaN               NaN                      NaN   \n",
       "87931               NaN               NaN                      NaN   \n",
       "\n",
       "       other_case_method  upper_case_class  lower_camel_case_class  \\\n",
       "0                    NaN               NaN                     NaN   \n",
       "1                    NaN               NaN                     NaN   \n",
       "2                    NaN               NaN                     NaN   \n",
       "3                    NaN               NaN                     NaN   \n",
       "4                    NaN               NaN                     NaN   \n",
       "...                  ...               ...                     ...   \n",
       "87927               10.0               NaN                     NaN   \n",
       "87928                NaN               NaN                     NaN   \n",
       "87929                3.0               NaN                     NaN   \n",
       "87930                NaN               NaN                     NaN   \n",
       "87931                NaN               NaN                     NaN   \n",
       "\n",
       "       upper_case_method  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "87927                2.0  \n",
       "87928                NaN  \n",
       "87929                NaN  \n",
       "87930                NaN  \n",
       "87931                NaN  \n",
       "\n",
       "[875096 rows x 89 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269088\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.read_csv(fname_prefix+\"data/bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file0_20220530.csv\")\n",
    "#os.listdir(\"data\")\n",
    "bq_metric_files = [\n",
    "    #'bigquery_metric_dedup_file0_20220530.csv',\n",
    "    #'py150k_metric_20220527.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file1_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file2_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file3_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file4_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file5_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file6_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file7_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file8_20220530.csv',\n",
    "    'bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file9_20220530.csv' \n",
    " ]\n",
    "\n",
    "for file in bq_metric_files:\n",
    "    temp_df = pd.read_csv(f'{fname_prefix}data/{file}')\n",
    "    combined_df = pd.concat((combined_df, temp_df))\n",
    "#os.listdir(f'{fname_prefix}data/BigQuery/files/')\n",
    "\n",
    "#need to load all of the data\n",
    "\n",
    "bq_content_df = pd.read_csv(f'{fname_prefix}data/BigQuery/files/cubert_metadata000000000000') \n",
    "bq_content_files = [\n",
    "    f'data/BigQuery/files/cubert_metadata000000000001',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000002',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000003',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000004',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000005',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000006',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000007',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000008',\n",
    "    f'data/BigQuery/files/cubert_metadata000000000009'\n",
    "]\n",
    "for file in bq_content_files:\n",
    "    temp_df = pd.read_csv(f'{fname_prefix}{file}')\n",
    "    bq_content_df = pd.concat((bq_content_df, temp_df))\n",
    "display(combined_df)\n",
    "#combined_df = pd.concat([py150k_df, bigquery_df], axis = 0) \n",
    "combined_df['file'] = [ x + y  for x, y in zip(combined_df['repository'], combined_df['filepath'])]\n",
    "bq_content_df['file'] = [ x + y  for x, y in zip(bq_content_df['repository'], bq_content_df['filepath'])]\n",
    "print (len (bq_content_df['file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_feature_clusterer_preds.pickle', 'feature_list_params.txt']\n"
     ]
    }
   ],
   "source": [
    "#!pip install hdbscan\n",
    "import hdbscan\n",
    "print (os.listdir(fname_prefix + \"data/combined_dataset/clusters/all_data\"))\n",
    "with open(fname_prefix + \"data/combined_dataset/clusters/all_data/full_feature_clusterer_preds.pickle\", \"rb\") as file:\n",
    "    cluster_pred = pickle.load(file)\n",
    "    labels = cluster_pred.labels_\n",
    "    cluster_num = len(np.unique(labels))\n",
    "combined_df['labels'] = labels.tolist()[ : 87273] + labels.tolist()[187273: ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get code\n",
    "\n",
    "\n",
    "code_filenames = read_py150k_code(PY150K_TRAIN_CODE)\n",
    "#print ((code_filenames[1]))\n",
    "py150_code = []\n",
    "\"\"\"for i in range(0, len(code_filenames)):\n",
    "    #print (i)\n",
    "    try:\n",
    "        py150_code.append( read_file_to_string( #regex codefilenames drop data/py150/py150_files/data/ \n",
    "            f\"{PY150K_CODE_DIR}/{code_filenames[i]}\"\n",
    "        ))\n",
    "    except: # currently appending empty string for empy files\n",
    "        print (f\"{PY150K_CODE_DIR}/{code_filenames[i]}\")\n",
    "        py150_code.append( \"File Error\"\n",
    "        )\"\"\" # getting py 150 code\n",
    "ex_files = list(combined_df['file'])\n",
    "filtered_bq = bq_content_df[bq_content_df['file'].isin(ex_files)]\n",
    "bigquery_code = list(filtered_bq['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875096\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (875096) does not match length of index (208311)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000005vscode-remote?line=6'>7</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(fname_prefix\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file0_20220530.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000005vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m#display (test_df)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000005vscode-remote?line=8'>9</a>\u001b[0m combined_df[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m combined_code\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000005vscode-remote?line=9'>10</a>\u001b[0m display(combined_df)\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/pandas/core/frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4532\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4534\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4535\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4536\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (875096) does not match length of index (208311)"
     ]
    }
   ],
   "source": [
    "#hugging face dataset\n",
    "\n",
    "print (len(filtered_bq))\n",
    "\n",
    "combined_code =bigquery_code[ : 87273] + py150_code + bigquery_code[87273 : ] # changing to fit format of bq manifest 1 py150 then rest of bq, done to match cluster\n",
    "#87273\n",
    "test_df = pd.read_csv(fname_prefix+\"data/bigquery_metric_dedup_file_20220530/bigquery_metric_dedup_file0_20220530.csv\")\n",
    "#display (test_df)\n",
    "combined_df['content'] = combined_code\n",
    "display(combined_df)\n",
    "combined_df.to_csv(fname_prefix + 'data/labeled_code/bq_data_outliers.csv')\n",
    "#print (combined_df.iloc[87273])\n",
    "#print (test_df.iloc[87273])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository</th>\n",
       "      <th>filepath</th>\n",
       "      <th>forks</th>\n",
       "      <th>issue_events</th>\n",
       "      <th>stars</th>\n",
       "      <th>parse_error</th>\n",
       "      <th>line_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comment_avg_len</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>...</th>\n",
       "      <th>lower_case_class</th>\n",
       "      <th>snake_case_class</th>\n",
       "      <th>upper_camel_case_method</th>\n",
       "      <th>other_case_method</th>\n",
       "      <th>upper_case_class</th>\n",
       "      <th>lower_camel_case_class</th>\n",
       "      <th>upper_case_method</th>\n",
       "      <th>file</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>osrg/gobgp</td>\n",
       "      <td>test/scenario_test/bgp_zebra_test.py</td>\n",
       "      <td>687</td>\n",
       "      <td>1066</td>\n",
       "      <td>2972</td>\n",
       "      <td>1</td>\n",
       "      <td>312.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.925000</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>osrg/gobgptest/scenario_test/bgp_zebra_test.py</td>\n",
       "      <td>7</td>\n",
       "      <td># Copyright (C) 2015 Nippon Telegraph and Tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CivicKnowledge/ambry</td>\n",
       "      <td>test/bundle_tests/ingest.example.com/headersty...</td>\n",
       "      <td>8</td>\n",
       "      <td>303</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CivicKnowledge/ambrytest/bundle_tests/ingest.e...</td>\n",
       "      <td>20</td>\n",
       "      <td>import ambry.bundle \\n\\n\\nclass Bundle(ambry.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sistemas-Multimedia/Icecast-tracker</td>\n",
       "      <td>Django/rocio333/holamundo333/manage.py</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sistemas-Multimedia/Icecast-trackerDjango/roci...</td>\n",
       "      <td>13</td>\n",
       "      <td>#!/usr/bin/env python\\nimport os\\nimport sys\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>neutrons/FastGR</td>\n",
       "      <td>addie/processing/mantid/master_table/table_row...</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>27.811594</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutrons/FastGRaddie/processing/mantid/master_...</td>\n",
       "      <td>6</td>\n",
       "      <td>from __future__ import (absolute_import, divis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JuBra/GEMEditor</td>\n",
       "      <td>GEMEditor/map/ui/__init__.py</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JuBra/GEMEditorGEMEditor/map/ui/__init__.py</td>\n",
       "      <td>17</td>\n",
       "      <td>from .MapListDialog import Ui_MapListDialog\\nf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87912</th>\n",
       "      <td>limafabio/lazycf</td>\n",
       "      <td>tests/Test_LazyCF.py</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>limafabio/lazycftests/Test_LazyCF.py</td>\n",
       "      <td>7</td>\n",
       "      <td>#!/usr/bin/py\\n\\nimport os\\nimport sys\\nimport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87917</th>\n",
       "      <td>QQuick/Transcrypt</td>\n",
       "      <td>transcrypt/docs/sphinx/conf.py</td>\n",
       "      <td>231</td>\n",
       "      <td>922</td>\n",
       "      <td>2175</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>46.972973</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QQuick/Transcrypttranscrypt/docs/sphinx/conf.py</td>\n",
       "      <td>10</td>\n",
       "      <td>import sys\\r\\n\\r\\nsys.path.append ('../../modu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87920</th>\n",
       "      <td>kytulendu/Gw2Browser</td>\n",
       "      <td>extern/glew/build/conan/test_package/conanfile.py</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kytulendu/Gw2Browserextern/glew/build/conan/te...</td>\n",
       "      <td>20</td>\n",
       "      <td>from conans import ConanFile, CMake\\nimport os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87923</th>\n",
       "      <td>martinstastny/django-simplestore</td>\n",
       "      <td>simplestore/products/migrations/0003_auto_2017...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>martinstastny/django-simplestoresimplestore/pr...</td>\n",
       "      <td>20</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Generated by Django...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87931</th>\n",
       "      <td>lablup/sorna-repl</td>\n",
       "      <td>python-theano/run.py</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.833333</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lablup/sorna-replpython-theano/run.py</td>\n",
       "      <td>6</td>\n",
       "      <td>#! /usr/bin/env python\\n\\nimport builtins as b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208311 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repository  \\\n",
       "8                               osrg/gobgp   \n",
       "12                    CivicKnowledge/ambry   \n",
       "16     Sistemas-Multimedia/Icecast-tracker   \n",
       "18                         neutrons/FastGR   \n",
       "25                         JuBra/GEMEditor   \n",
       "...                                    ...   \n",
       "87912                     limafabio/lazycf   \n",
       "87917                    QQuick/Transcrypt   \n",
       "87920                 kytulendu/Gw2Browser   \n",
       "87923     martinstastny/django-simplestore   \n",
       "87931                    lablup/sorna-repl   \n",
       "\n",
       "                                                filepath  forks  issue_events  \\\n",
       "8                   test/scenario_test/bgp_zebra_test.py    687          1066   \n",
       "12     test/bundle_tests/ingest.example.com/headersty...      8           303   \n",
       "16                Django/rocio333/holamundo333/manage.py      6             3   \n",
       "18     addie/processing/mantid/master_table/table_row...      3           136   \n",
       "25                          GEMEditor/map/ui/__init__.py      2            39   \n",
       "...                                                  ...    ...           ...   \n",
       "87912                               tests/Test_LazyCF.py      1             4   \n",
       "87917                     transcrypt/docs/sphinx/conf.py    231           922   \n",
       "87920  extern/glew/build/conan/test_package/conanfile.py     16             5   \n",
       "87923  simplestore/products/migrations/0003_auto_2017...     11             1   \n",
       "87931                               python-theano/run.py      2            56   \n",
       "\n",
       "       stars  parse_error  line_count  comment_count  comment_avg_len  \\\n",
       "8       2972            1       312.0           40.0        37.925000   \n",
       "12         4            1         6.0            0.0         0.000000   \n",
       "16         2            1        11.0            1.0        21.000000   \n",
       "18         1            1      1014.0           69.0        27.811594   \n",
       "25         1            1         3.0            0.0         0.000000   \n",
       "...      ...          ...         ...            ...              ...   \n",
       "87912      1            1        55.0            1.0        13.000000   \n",
       "87917   2175            1       251.0          148.0        46.972973   \n",
       "87920     43            1        22.0            0.0         0.000000   \n",
       "87923     36            1        25.0            2.0        35.500000   \n",
       "87931     14            1       179.0            6.0        35.833333   \n",
       "\n",
       "       comment_density  ...  lower_case_class  snake_case_class  \\\n",
       "8             0.128205  ...               NaN               NaN   \n",
       "12            0.000000  ...               NaN               NaN   \n",
       "16            0.090909  ...               NaN               NaN   \n",
       "18            0.068047  ...               NaN               NaN   \n",
       "25            0.000000  ...               NaN               NaN   \n",
       "...                ...  ...               ...               ...   \n",
       "87912         0.018182  ...               NaN               NaN   \n",
       "87917         0.589641  ...               NaN               NaN   \n",
       "87920         0.000000  ...               NaN               NaN   \n",
       "87923         0.080000  ...               NaN               NaN   \n",
       "87931         0.033520  ...               NaN               NaN   \n",
       "\n",
       "       upper_camel_case_method  other_case_method  upper_case_class  \\\n",
       "8                          NaN                NaN               NaN   \n",
       "12                         NaN                NaN               NaN   \n",
       "16                         NaN                NaN               NaN   \n",
       "18                         NaN                NaN               NaN   \n",
       "25                         NaN                NaN               NaN   \n",
       "...                        ...                ...               ...   \n",
       "87912                      NaN                NaN               NaN   \n",
       "87917                      NaN                NaN               NaN   \n",
       "87920                      NaN                NaN               NaN   \n",
       "87923                      NaN                NaN               NaN   \n",
       "87931                      NaN                NaN               NaN   \n",
       "\n",
       "       lower_camel_case_class  upper_case_method  \\\n",
       "8                         NaN                NaN   \n",
       "12                        NaN                NaN   \n",
       "16                        NaN                NaN   \n",
       "18                        NaN                NaN   \n",
       "25                        NaN                NaN   \n",
       "...                       ...                ...   \n",
       "87912                     NaN                NaN   \n",
       "87917                     NaN                NaN   \n",
       "87920                     NaN                NaN   \n",
       "87923                     NaN                NaN   \n",
       "87931                     NaN                NaN   \n",
       "\n",
       "                                                    file  labels  \\\n",
       "8         osrg/gobgptest/scenario_test/bgp_zebra_test.py       7   \n",
       "12     CivicKnowledge/ambrytest/bundle_tests/ingest.e...      20   \n",
       "16     Sistemas-Multimedia/Icecast-trackerDjango/roci...      13   \n",
       "18     neutrons/FastGRaddie/processing/mantid/master_...       6   \n",
       "25           JuBra/GEMEditorGEMEditor/map/ui/__init__.py      17   \n",
       "...                                                  ...     ...   \n",
       "87912               limafabio/lazycftests/Test_LazyCF.py       7   \n",
       "87917    QQuick/Transcrypttranscrypt/docs/sphinx/conf.py      10   \n",
       "87920  kytulendu/Gw2Browserextern/glew/build/conan/te...      20   \n",
       "87923  martinstastny/django-simplestoresimplestore/pr...      20   \n",
       "87931              lablup/sorna-replpython-theano/run.py       6   \n",
       "\n",
       "                                                 content  \n",
       "8      # Copyright (C) 2015 Nippon Telegraph and Tele...  \n",
       "12     import ambry.bundle \\n\\n\\nclass Bundle(ambry.b...  \n",
       "16     #!/usr/bin/env python\\nimport os\\nimport sys\\n...  \n",
       "18     from __future__ import (absolute_import, divis...  \n",
       "25     from .MapListDialog import Ui_MapListDialog\\nf...  \n",
       "...                                                  ...  \n",
       "87912  #!/usr/bin/py\\n\\nimport os\\nimport sys\\nimport...  \n",
       "87917  import sys\\r\\n\\r\\nsys.path.append ('../../modu...  \n",
       "87920  from conans import ConanFile, CMake\\nimport os...  \n",
       "87923  # -*- coding: utf-8 -*-\\n# Generated by Django...  \n",
       "87931  #! /usr/bin/env python\\n\\nimport builtins as b...  \n",
       "\n",
       "[208311 rows x 92 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'style_chars = []\\nfor i in range (-1, 25):\\n    style_chars.append(f\"<style{i}>\")\\nprint (style_chars)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df to dataset\n",
    "combined_df = combined_df[combined_df['labels'] != -1]\n",
    "display(combined_df)\n",
    "combined_df.to_csv(fname_prefix + 'data/labeled_code/bq_data_no_outliers.csv')\n",
    "dataset = Dataset.from_pandas(combined_df).train_test_split(test_size=0.2)\n",
    "\"\"\"style_chars = []\n",
    "for i in range (-1, 25):\n",
    "    style_chars.append(f\"<style{i}>\")\n",
    "print (style_chars)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/1e2aacf615bc83f25a9d748eccb762b335eee01a29ab7a8db9b8e86cc851d489.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/7eaa9b856402f05e8fdd452951872ecd3c2692ea9abb86b7ab62b07e3bc5f7de.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/a3e93db547e41cdd21f01826d07c5679e111b02d8e969c607611c30a6acbe191.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/5941df5e4315c5ab63b7b2ac791fb0bf0f209744a055c06b43b5274849137cdd.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/c99468017f7cb1b243c80a5640fd483688c5ec58bcd18b64efa5b82d8df7bc24.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, PLBartTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "\n",
    "#tokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-python-en_XX\", src_lang=\"python\", tgt_lang=\"python\" )\n",
    "#return_tensors ='pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/vocab.json from cache at /soe/ksmunson/.cache/huggingface/transformers/1e2aacf615bc83f25a9d748eccb762b335eee01a29ab7a8db9b8e86cc851d489.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/merges.txt from cache at /soe/ksmunson/.cache/huggingface/transformers/7eaa9b856402f05e8fdd452951872ecd3c2692ea9abb86b7ab62b07e3bc5f7de.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/added_tokens.json from cache at /soe/ksmunson/.cache/huggingface/transformers/a3e93db547e41cdd21f01826d07c5679e111b02d8e969c607611c30a6acbe191.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/special_tokens_map.json from cache at /soe/ksmunson/.cache/huggingface/transformers/5941df5e4315c5ab63b7b2ac791fb0bf0f209744a055c06b43b5274849137cdd.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer_config.json from cache at /soe/ksmunson/.cache/huggingface/transformers/c99468017f7cb1b243c80a5640fd483688c5ec58bcd18b64efa5b82d8df7bc24.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n",
      "Parameter 'function'=<function tokenization at 0x7f38594f14c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db54a12028cf4fb68ed0de22600c75c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenization\u001b[39m(example):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m#print (tokenizer(example[\"content\"], padding='max_length', truncation=True).keys())\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer(example[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m], padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(tokenization, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m train_dataset\u001b[39m.\u001b[39mset_format(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m train_dataset\u001b[39m.\u001b[39mformat[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/arrow_dataset.py:2376\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2373\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2375\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2376\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2377\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2378\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2379\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2380\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2381\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2382\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2383\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2384\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2385\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2386\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2387\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2388\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2389\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2390\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2391\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2392\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2393\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2394\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2395\u001b[0m     )\n\u001b[1;32m   2396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2398\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/arrow_dataset.py:551\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    550\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    552\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    553\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    554\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/arrow_dataset.py:518\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    512\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    513\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    514\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    515\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    516\u001b[0m }\n\u001b[1;32m    517\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    519\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    520\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/fingerprint.py:458\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             kwargs[fingerprint_name] \u001b[39m=\u001b[39m update_fingerprint(\n\u001b[1;32m    453\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[1;32m    454\u001b[0m             )\n\u001b[1;32m    456\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/arrow_dataset.py:2764\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2760\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2761\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(input_dataset\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   2762\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2764\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   2765\u001b[0m         batch,\n\u001b[1;32m   2766\u001b[0m         indices,\n\u001b[1;32m   2767\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(input_dataset\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2768\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   2769\u001b[0m     )\n\u001b[1;32m   2770\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   2771\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   2772\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2773\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/arrow_dataset.py:2644\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2642\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   2643\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 2644\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   2645\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2646\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/datasets/arrow_dataset.py:2336\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2332\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[1;32m   2333\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m   2334\u001b[0m )\n\u001b[1;32m   2335\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> 2336\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2337\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
      "\u001b[1;32m/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb Cell 9\u001b[0m in \u001b[0;36mtokenization\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenization\u001b[39m(example):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m#print (tokenizer(example[\"content\"], padding='max_length', truncation=True).keys())\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnlp-gpu-01.soe.ucsc.edu/data/users/ksmunson/code-style-probing/full_data_preprocess.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer(example[\u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m], padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2495\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2490\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2491\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2492\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2493\u001b[0m         )\n\u001b[1;32m   2494\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2495\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2496\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2497\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2498\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2499\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2500\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2501\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2502\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2503\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2504\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2505\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2506\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2507\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2508\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2509\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2510\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2511\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2512\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2513\u001b[0m     )\n\u001b[1;32m   2514\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2516\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2517\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2533\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2534\u001b[0m     )\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2686\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2676\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2677\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2678\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2679\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2684\u001b[0m )\n\u001b[0;32m-> 2686\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2687\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2688\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2689\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2690\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2691\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2692\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2693\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2694\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2695\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2696\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2697\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2698\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2699\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2700\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2701\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2702\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2703\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2704\u001b[0m )\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/tokenization_utils.py:733\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 733\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[1;32m    734\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    735\u001b[0m input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/tokenization_utils.py:700\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[1;32m    699\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 700\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    701\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    702\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/tokenization_utils.py:547\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         tokenized_text\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m    546\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         tokenized_text\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenize(token))\n\u001b[1;32m    548\u001b[0m \u001b[39m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/models/roberta/tokenization_roberta.py:298\u001b[0m, in \u001b[0;36mRobertaTokenizer._tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m re\u001b[39m.\u001b[39mfindall(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpat, text):\n\u001b[1;32m    295\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    296\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbyte_encoder[b] \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m token\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    297\u001b[0m     )  \u001b[39m# Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     bpe_tokens\u001b[39m.\u001b[39mextend(bpe_token \u001b[39mfor\u001b[39;00m bpe_token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbpe(token)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    299\u001b[0m \u001b[39mreturn\u001b[39;00m bpe_tokens\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/models/roberta/tokenization_roberta.py:259\u001b[0m, in \u001b[0;36mRobertaTokenizer.bpe\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[39mreturn\u001b[39;00m token\n\u001b[1;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     bigram \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39;49m(pairs, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m pair: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbpe_ranks\u001b[39m.\u001b[39;49mget(pair, \u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m\"\u001b[39;49m)))\n\u001b[1;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m bigram \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbpe_ranks:\n\u001b[1;32m    261\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/data/users/ksmunson/data/users/ksmunson/lib/python3.9/site-packages/transformers/models/roberta/tokenization_roberta.py:259\u001b[0m, in \u001b[0;36mRobertaTokenizer.bpe.<locals>.<lambda>\u001b[0;34m(pair)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[39mreturn\u001b[39;00m token\n\u001b[1;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     bigram \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(pairs, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m pair: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbpe_ranks\u001b[39m.\u001b[39mget(pair, \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m bigram \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbpe_ranks:\n\u001b[1;32m    261\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "def tokenization(example):\n",
    "    #print (tokenizer(example[\"content\"], padding='max_length', truncation=True).keys())\n",
    "    return tokenizer(example[\"content\"], padding='max_length', truncation=True)\n",
    "train_dataset = dataset[\"train\"].map(tokenization, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "train_dataset.format['type']\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(tokenization, batched=True)\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.format['type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(20), 'input_ids': tensor([    1,  8395,  6289,  1953,   364,   450, 22536,  8395,   203,   203,\n",
      "         2080,  2792,  1930,  6057,   203,   203,   203,  1106,  3877,   559,\n",
      "           12,  3572,  4672,   203,   565,  1983,  2881, 19064,   273,   296,\n",
      "         2854,  2881, 19064,    11,   203,   565,  1339,   273,   296,  3184,\n",
      "           11,   203,   565, 23720,   273,   296, 19064,    11,   203,   565,\n",
      "         1525, 19064,   273,   296,  5748, 19064,    11,   203,   565,  9549,\n",
      "         1385,   273,   296, 19525,  1385,    11,   203,   565,   498,  7652,\n",
      "          273,   296,   856,  7652,    11,   203,   203,   203,  3184,   723,\n",
      "           67, 30288,   273,   288,   203,   565,  3877,   559,    18,  2854,\n",
      "         2881, 19064,    30,   296,    37,  1983,  2548,    16,   675,    17,\n",
      "          591,  1134, 23720,  1093,    16,   203,   565,  3877,   559,    18,\n",
      "         3184,    30,   296,    37,  8566,  8044, 22525,  1339,   598, 13494,\n",
      "         1093,    16,   203,   565,  3877,   559,    18, 19064,    30,   296,\n",
      "           37,  8566,  8044, 23720,   598,  2695,  2403,  2345, 30891,   367,\n",
      "         1093,    16,   203,   565,  3877,   559,    18,  5748, 19064,    30,\n",
      "          296,    37,  9259,  8044, 23720,   598,  2695,  2403,  2345, 30891,\n",
      "          367,  1093,    16,   203,   565,  3877,   559,    18, 19525,  1385,\n",
      "           30,   296,    37,  4200,  8044, 22525,  1093,    16,   203,   565,\n",
      "         3877,   559,    18,   856,  7652,    30,   296,    37,  4752,  8044,\n",
      "          498,  7652, 22525,  1093,    16,   203,    97,   203,   203,   203,\n",
      "         1106, 19945,  1119,    12,  3572,  4672,   203,   565,  9638,   273,\n",
      "          296, 31575,    11,   203,   565,  8494,   273,   296, 23847,    11,\n",
      "          203,   565, 23262,  2423,   273,   296,   484, 10378,  2423,    11,\n",
      "          203,   565, 11876,   273,   296,   266,  6059,    11,   203,   565,\n",
      "         5114,   273,   296,  9572,    11,   203,   565,   598,  9446,    82,\n",
      "          273,   296,  1918,  9446,    82,    11,   203,   203,   203,  1106,\n",
      "         3877, 30418,    12,  3572,  4672,   203,   565,  2376,  1224,   273,\n",
      "          296, 10086,  1224,    11,   203,   565, 12110,   273,   296,  2761,\n",
      "         6785,    11,   203,   565,   431,   672,   273,   296,   338,   672,\n",
      "           11,   203,   565,   777,   273,   296,   454,    11,   203,     2,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
      "Empty DataFrame\n",
      "Columns: [repository, filepath, forks, issue_events, stars, parse_error, line_count, comment_count, comment_avg_len, comment_density, id_total, lower_case, id_total_var, lower_case_var, snake_case, snake_case_var, lower_camel_case, lower_camel_case_var, snake_case_ratio, snake_case_var_ratio, snake_case_class_ratio, snake_case_method_ratio, lower_camel_case_ratio, lower_camel_case_var_ratio, lower_camel_case_class_ratio, lower_camel_case_method_ratio, upper_camel_case_ratio, upper_camel_case_var_ratio, upper_camel_case_class_ratio, upper_camel_case_method_ratio, lower_case_ratio, lower_case_var_ratio, lower_case_class_ratio, lower_case_method_ratio, upper_case_ratio, upper_case_var_ratio, upper_case_class_ratio, upper_case_method_ratio, other_case_ratio, other_case_var_ratio, other_case_class_ratio, other_case_method_ratio, func_decorators_avg, func_async_ratio, class_parents_avg, class_decorators_avg, ds_density, ds_char_len_avg, ds_word_len_avg, comprehensions_avg, generators_avg, lambda_avg, comment_total_len, upper_camel_case, id_total_class, upper_camel_case_class, ds_count, ds_char_len_total, ds_word_len_total, ds_line_count, class_count, class_parents_count, class_decorators_count, upper_camel_case_var, id_total_method, snake_case_method, internal_method, overridden_method, ds_of_method, func_count, func_decorators_count, comprehensions, lambda, other_case, other_case_var, upper_case, upper_case_var, lower_camel_case_method, lower_case_method, other_case_class, func_async_count, generators, lower_case_class, snake_case_class, upper_camel_case_method, other_case_method, upper_case_class, lower_camel_case_class, upper_case_method, path, file, labels, content]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "print ((train_dataset[0]))\n",
    "train_dataset.save_to_disk(fname_prefix + \"datasets/codet5_train_full.hf\")\n",
    "test_dataset.save_to_disk(fname_prefix + \"datasets/codet5_test_full.hf\")\n",
    "#print (combined_df[combined_df['content'] ==  \"File Error\"])\n",
    "combined_df.to_csv(fname_prefix + 'data/labeled_code/full_data.csv')\n",
    "#\"/data/users/team2_capstone/code-style-probing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(17), 'input_ids': tensor([    1,  5666,  1062,    18,  2625,   203,   203,  4646,   273,  1062,\n",
      "           18,  2625,    18,  3693,  1952,  2932, 22851,  4757,    18,   832,\n",
      "         7923,   203,   203,  7648,   273,   315, 13465,  1611, 23899, 15168,\n",
      "         2499,  2787,  1611, 15168, 11664,    64,    86,    64,    82,  1350,\n",
      "           17, 15087,    30,   646,    17,   892,    31,   508,  5189, 11351,\n",
      "        31670,    86,    64,    82,    64,    86,    64,    82,  3215,    64,\n",
      "           86,    64,    82, 13465,  1611, 23899, 15168,  2499,  2787,  1611,\n",
      "        15168, 11664,   413,    64,    86,    64,    82,     6,   203,   203,\n",
      "         2485,   273,   288,   296,  1350,    17,   559,  4278,   315, 16404,\n",
      "           19,   687,    17,   892,    31,  7679,    33,  6062,  1611, 23899,\n",
      "        15168,  2499,  2787,  1611, 15168, 11664,     6,   289,   203,   203,\n",
      "         4646,    18,  2293,  2932,  3798,  3113,  2206, 30250,  3113,  2385,\n",
      "           16,  1607,    13,   203,   203,   455,   273,  1487,    18,   588,\n",
      "         2740,  1435,   203,   892,   273,   400,    18,   896,  1435,   203,\n",
      "          203,  1188,    12,   892,    18,  3922,  2932,  3158,    17,    28,\n",
      "            6,  3719,   203,     2,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "#example method for loading datset checkpoints\n",
    "test = load_from_disk(fname_prefix + 'datasets/codet5_test_full.hf')\n",
    "test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "print ((test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "988cc1e00d3b5bb0a2e9024406047781d3e298e90a30d1fcc633613d0d680479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
