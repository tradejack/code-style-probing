{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\km201\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchaudio\\backend\\utils.py:66: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "#preprocessing for training pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = [\n",
    "     'snake_case_var_ratio',\n",
    "     'snake_case_class_ratio',\n",
    "     'snake_case_method_ratio',\n",
    "     'upper_camel_case_var_ratio',\n",
    "     'upper_camel_case_class_ratio',\n",
    "     'upper_camel_case_method_ratio',\n",
    "     'lower_camel_case_var_ratio',\n",
    "     'lower_camel_case_class_ratio',\n",
    "     'lower_camel_case_method_ratio',\n",
    "     'func_decorators_avg',\n",
    "     'class_decorators_avg',\n",
    "     'class_parents_avg',\n",
    "     'comprehensions_avg',\n",
    "     'generators_avg',\n",
    "     'lambda_avg',\n",
    "     'comment_density',\n",
    "     'ds_density',\n",
    "]\n",
    "PY150K_DIR = \"data/py150\"\n",
    "PY150K_CODE_DIR = \"data/py150/py150_files\"\n",
    "PY150K_TRAIN_AST = \"data/py150/python100k_train.json\"\n",
    "PY150K_EVAL_AST = \"data/py150/python50k_eval.json\"\n",
    "PY150K_TRAIN_CODE = \"data/py150/py150_files/python100k_train.txt\"\n",
    "PY150K_EVAL_CODE = \"data/py150/py150_files/python50k_eval.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "py150k_df = pd.read_csv(\"data/py150k_metric_20220524.csv\")\n",
    "bigquery_df = pd.read_csv(\"data/bigquery_metric_20220526.csv\")\n",
    "bq_content_df = pd.read_csv(f'data/BigQuery/files/cubert_metadata000000000000') \n",
    "\n",
    "combined_df = pd.concat([py150k_df, bigquery_df], axis = 0) \n",
    "combined_df['file'] = [ x + y  for x, y in zip(combined_df['repository'], combined_df['filepath'])]\n",
    "bq_content_df['file'] = [ x + y  for x, y in zip(bq_content_df['repository'], bq_content_df['filepath'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/combined_dataset/clusters/feature_set_1/full_feature_clusterer.pickle\", \"rb\") as file:\n",
    "    cluster_pred = pickle.load(file)\n",
    "    labels = cluster_pred.labels_\n",
    "    cluster_num = len(np.unique(labels))\n",
    "combined_df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/py150/py150_files/data/PaulSec/twittor/implant.py\n",
      "data/py150/py150_files/data/alexandrebarachant/Grasp-and-lift-EEG-challenge/preprocessing/aux.py\n",
      "data/py150/py150_files/data/pimutils/khal/khal/khalendar/aux.py\n",
      "data/py150/py150_files/data/Akagi201/learning-python/socket/backdoor_fud/backdoor_fud.py\n",
      "data/py150/py150_files/data/ummahusla/Codecademy-Exercise-Answers/Language Skills/Python/Unit 6/Student Becomes the Teacher/Just Average/9-How is everything doing?.py\n",
      "data/py150/py150_files/data/ummahusla/Codecademy-Exercise-Answers/Language Skills/Python/Unit 7/2-Battleship!/Hit or Miss?/12-Bad Aim.py\n",
      "data/py150/py150_files/data/pimutils/khal/tests/aux.py\n",
      "data/py150/py150_files/data/ummahusla/Codecademy-Exercise-Answers/Language Skills/Python/Unit 7/2-Battleship!/Hit or Miss?/10-You Win!.py\n"
     ]
    }
   ],
   "source": [
    "#get code\n",
    "\n",
    "\n",
    "code_filenames = read_py150k_code(PY150K_TRAIN_CODE)\n",
    "#print ((code_filenames[1]))\n",
    "py150_code = []\n",
    "for i in range(0, len(code_filenames)):\n",
    "    #print (i)\n",
    "    try:\n",
    "        py150_code.append( read_file_to_string( #regex codefilenames drop data/py150/py150_files/data/ \n",
    "            f\"{PY150K_CODE_DIR}/{code_filenames[i]}\"\n",
    "        ))\n",
    "    except: # currently appending empty string for empy files\n",
    "        print (f\"{PY150K_CODE_DIR}/{code_filenames[i]}\")\n",
    "        py150_code.append( \"File Error\"\n",
    "        )\n",
    "ex_files = list(combined_df['file'])\n",
    "filtered_bq = bq_content_df[bq_content_df['file'].isin(ex_files)]\n",
    "bigquery_code = list(filtered_bq['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comment_total_len</th>\n",
       "      <th>comment_avg_len</th>\n",
       "      <th>comment_density</th>\n",
       "      <th>id_total</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>id_total_var</th>\n",
       "      <th>lower_case_var</th>\n",
       "      <th>snake_case_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>repository</th>\n",
       "      <th>filepath</th>\n",
       "      <th>forks</th>\n",
       "      <th>issue_events</th>\n",
       "      <th>stars</th>\n",
       "      <th>parse_error</th>\n",
       "      <th>func_async_count</th>\n",
       "      <th>file</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>51.833333</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>381.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.341207</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# Open Source Initiat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>#!/usr/bin/env python\\n\"\"\"Django's command lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>\"\"\"Installer for hippybot\\n\"\"\"\\n\\nimport os\\nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>#!/usr/bin/env python\\nimport os\\nimport sys\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115045</th>\n",
       "      <td>1292.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>7829.0</td>\n",
       "      <td>38.950249</td>\n",
       "      <td>0.155573</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>0.056695</td>\n",
       "      <td>...</td>\n",
       "      <td>oscarbranson/latools</td>\n",
       "      <td>latools/helpers/plot.py</td>\n",
       "      <td>11.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oscarbranson/latoolslatools/helpers/plot.py</td>\n",
       "      <td>-1</td>\n",
       "      <td>\"\"\"\\nPlotting functions.\\n\\n(c) Oscar Branson ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115046</th>\n",
       "      <td>194.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>37.235294</td>\n",
       "      <td>0.087629</td>\n",
       "      <td>63.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>...</td>\n",
       "      <td>erjac77/ansible-module-f5bigip</td>\n",
       "      <td>library/f5bigip_ltm_monitor_snmp_dca.py</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erjac77/ansible-module-f5bigiplibrary/f5bigip_...</td>\n",
       "      <td>-1</td>\n",
       "      <td>#!/usr/bin/python\\n# -*- coding: utf-8 -*-\\n#\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115047</th>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>111.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>...</td>\n",
       "      <td>python-hyper/hyper-h2</td>\n",
       "      <td>test/test_config.py</td>\n",
       "      <td>139.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>python-hyper/hyper-h2test/test_config.py</td>\n",
       "      <td>-1</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\"\"\"\\ntest_config\\n~~~...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115048</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>...</td>\n",
       "      <td>techbureau/zaifbot</td>\n",
       "      <td>tests/trade/test_trade.py</td>\n",
       "      <td>14.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>techbureau/zaifbottests/trade/test_trade.py</td>\n",
       "      <td>-1</td>\n",
       "      <td>import unittest\\nfrom zaifbot.trade.trade impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115049</th>\n",
       "      <td>2910.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4932.0</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>2995.0</td>\n",
       "      <td>3009.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>...</td>\n",
       "      <td>bingopodcast/bingos</td>\n",
       "      <td>bingo_emulator/singapore/game.py</td>\n",
       "      <td>1.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bingopodcast/bingosbingo_emulator/singapore/ga...</td>\n",
       "      <td>-1</td>\n",
       "      <td>#!/usr/bin/python\\n\\nimport logging\\nlogging.b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215050 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        line_count  comment_count  comment_total_len  comment_avg_len  \\\n",
       "0            116.0            2.0               44.0        22.000000   \n",
       "1            363.0           24.0             1244.0        51.833333   \n",
       "2             13.0            1.0               21.0        21.000000   \n",
       "3             34.0            0.0                0.0         0.000000   \n",
       "4             11.0            1.0               21.0        21.000000   \n",
       "...            ...            ...                ...              ...   \n",
       "115045      1292.0          201.0             7829.0        38.950249   \n",
       "115046       194.0           17.0              633.0        37.235294   \n",
       "115047       145.0            1.0               23.0        23.000000   \n",
       "115048        48.0            0.0                NaN         0.000000   \n",
       "115049      2910.0           72.0             4932.0        68.500000   \n",
       "\n",
       "        comment_density  id_total  lower_case  id_total_var  lower_case_var  \\\n",
       "0              0.017241       1.0         1.0           1.0             1.0   \n",
       "1              0.066116     381.0       214.0         333.0           195.0   \n",
       "2              0.076923       3.0         3.0           3.0             3.0   \n",
       "3              0.000000      26.0        18.0          26.0            18.0   \n",
       "4              0.090909       3.0         3.0           3.0             3.0   \n",
       "...                 ...       ...         ...           ...             ...   \n",
       "115045         0.155573    1658.0      1533.0        1646.0          1527.0   \n",
       "115046         0.087629      63.0        42.0          57.0            41.0   \n",
       "115047         0.006897     111.0        76.0          99.0            76.0   \n",
       "115048         0.000000      53.0        44.0          47.0            44.0   \n",
       "115049         0.024742    3084.0      2995.0        3009.0          2992.0   \n",
       "\n",
       "        snake_case_ratio  ...                      repository  \\\n",
       "0               0.000000  ...                             NaN   \n",
       "1               0.341207  ...                             NaN   \n",
       "2               0.000000  ...                             NaN   \n",
       "3               0.307692  ...                             NaN   \n",
       "4               0.000000  ...                             NaN   \n",
       "...                  ...  ...                             ...   \n",
       "115045          0.056695  ...            oscarbranson/latools   \n",
       "115046          0.126984  ...  erjac77/ansible-module-f5bigip   \n",
       "115047          0.270270  ...           python-hyper/hyper-h2   \n",
       "115048          0.094340  ...              techbureau/zaifbot   \n",
       "115049          0.026589  ...             bingopodcast/bingos   \n",
       "\n",
       "                                       filepath  forks  issue_events  stars  \\\n",
       "0                                           NaN    NaN           NaN    NaN   \n",
       "1                                           NaN    NaN           NaN    NaN   \n",
       "2                                           NaN    NaN           NaN    NaN   \n",
       "3                                           NaN    NaN           NaN    NaN   \n",
       "4                                           NaN    NaN           NaN    NaN   \n",
       "...                                         ...    ...           ...    ...   \n",
       "115045                  latools/helpers/plot.py   11.0          77.0    9.0   \n",
       "115046  library/f5bigip_ltm_monitor_snmp_dca.py    5.0          72.0    6.0   \n",
       "115047                      test/test_config.py  139.0         376.0  754.0   \n",
       "115048                tests/trade/test_trade.py   14.0         198.0   42.0   \n",
       "115049         bingo_emulator/singapore/game.py    1.0         511.0    3.0   \n",
       "\n",
       "        parse_error  func_async_count  \\\n",
       "0               NaN               NaN   \n",
       "1               NaN               NaN   \n",
       "2               NaN               NaN   \n",
       "3               NaN               NaN   \n",
       "4               NaN               NaN   \n",
       "...             ...               ...   \n",
       "115045          1.0               NaN   \n",
       "115046          1.0               NaN   \n",
       "115047          1.0               NaN   \n",
       "115048          1.0               NaN   \n",
       "115049          1.0               NaN   \n",
       "\n",
       "                                                     file  labels  \\\n",
       "0                                                     NaN      19   \n",
       "1                                                     NaN      -1   \n",
       "2                                                     NaN      19   \n",
       "3                                                     NaN      16   \n",
       "4                                                     NaN      19   \n",
       "...                                                   ...     ...   \n",
       "115045        oscarbranson/latoolslatools/helpers/plot.py      -1   \n",
       "115046  erjac77/ansible-module-f5bigiplibrary/f5bigip_...      -1   \n",
       "115047           python-hyper/hyper-h2test/test_config.py      -1   \n",
       "115048        techbureau/zaifbottests/trade/test_trade.py      -1   \n",
       "115049  bingopodcast/bingosbingo_emulator/singapore/ga...      -1   \n",
       "\n",
       "                                                  content  \n",
       "0       #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...  \n",
       "1       # -*- coding: utf-8 -*-\\n# Open Source Initiat...  \n",
       "2       #!/usr/bin/env python\\n\"\"\"Django's command lin...  \n",
       "3       \"\"\"Installer for hippybot\\n\"\"\"\\n\\nimport os\\nc...  \n",
       "4       #!/usr/bin/env python\\nimport os\\nimport sys\\n...  \n",
       "...                                                   ...  \n",
       "115045  \"\"\"\\nPlotting functions.\\n\\n(c) Oscar Branson ...  \n",
       "115046  #!/usr/bin/python\\n# -*- coding: utf-8 -*-\\n#\\...  \n",
       "115047  # -*- coding: utf-8 -*-\\n\"\"\"\\ntest_config\\n~~~...  \n",
       "115048  import unittest\\nfrom zaifbot.trade.trade impo...  \n",
       "115049  #!/usr/bin/python\\n\\nimport logging\\nlogging.b...  \n",
       "\n",
       "[215050 rows x 92 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hugging face dataset\n",
    "\n",
    "print (len(filtered_bq))\n",
    "combined_code = py150_code + bigquery_code\n",
    "\n",
    "combined_df['content'] = combined_code\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df to dataset\n",
    "dataset = Dataset.from_pandas(combined_df).train_test_split(test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/vocab.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\1e2aacf615bc83f25a9d748eccb762b335eee01a29ab7a8db9b8e86cc851d489.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/merges.txt from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\7eaa9b856402f05e8fdd452951872ecd3c2692ea9abb86b7ab62b07e3bc5f7de.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/added_tokens.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\a3e93db547e41cdd21f01826d07c5679e111b02d8e969c607611c30a6acbe191.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/special_tokens_map.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\5941df5e4315c5ab63b7b2ac791fb0bf0f209744a055c06b43b5274849137cdd.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer_config.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\c99468017f7cb1b243c80a5640fd483688c5ec58bcd18b64efa5b82d8df7bc24.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/sentencepiece.bpe.model from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\e57de2ba12d2b1d3cae7ce5921704890ac50789e8eb95100ff4c64dc98559729.c65001d1986897f4ae6d41d2c49f0e1621d3518cab63e0ffa3005e5deb5aae40\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/config.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\68f40642f8534e3482166065ce817305c07e1f4b8ea96013fe62ab865088bddb.8929a51af95d04be1b1d966435fd1ad4a48aca2f2953bc4e4a354b1f1dfd0b55\n",
      "Model config PLBartConfig {\n",
      "  \"_name_or_path\": \"uclanlp/plbart-python-en_XX\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"PLBartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"plbart\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50005\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, PLBartTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "\n",
    "tokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-python-en_XX\", src_lang=\"python\", tgt_lang=\"python\" )\n",
    "#return_tensors ='pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/vocab.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\1e2aacf615bc83f25a9d748eccb762b335eee01a29ab7a8db9b8e86cc851d489.9a48c5abf25554713c6513ab01066e53569b9a2da0d6189715951cf7c6288805\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/merges.txt from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\7eaa9b856402f05e8fdd452951872ecd3c2692ea9abb86b7ab62b07e3bc5f7de.7179059568f1a130b0a79e4bac71f38545207cab0ec45ce82ca09afadb2649a3\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/added_tokens.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\a3e93db547e41cdd21f01826d07c5679e111b02d8e969c607611c30a6acbe191.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/special_tokens_map.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\5941df5e4315c5ab63b7b2ac791fb0bf0f209744a055c06b43b5274849137cdd.b9905d0575bde443a20834122b6e2d48e853b2e36444ce98ddeb43c38097eb3f\n",
      "loading file https://huggingface.co/Salesforce/codet5-base/resolve/main/tokenizer_config.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\c99468017f7cb1b243c80a5640fd483688c5ec58bcd18b64efa5b82d8df7bc24.f1b0f4acf5601ca7b482b9f000524cffdc0c3950f7d8c45c32380bc213334af2\n",
      "100%|██████████| 173/173 [17:40<00:00,  6.13s/ba]\n",
      "100%|██████████| 44/44 [04:14<00:00,  5.78s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "def tokenization(example):\n",
    "    #print (tokenizer(example[\"content\"], padding='max_length', truncation=True).keys())\n",
    "    return tokenizer(example[\"content\"], padding='max_length', truncation=True)\n",
    "train_dataset = dataset[\"train\"].map(tokenization, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "train_dataset.format['type']\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(tokenization, batched=True)\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.format['type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(20), 'input_ids': tensor([    1,     7, 14848,    30,  7718,    17,    28,   203,   203,  8395,\n",
      "          203,   565, 24314, 10211,  8392,  1491,   203,   203,   565,   411,\n",
      "           84,    34,  1986, 24314, 10211,  8392,  1491, 19808,  1846,   358,\n",
      "        16592,   598, 24314, 10211,  7084,  1450,  4529,  8392,  1491,  8513,\n",
      "           18,  4554,   848,   999,   326,  8392,  1491,   358, 18472,   340,\n",
      "         2975,   715,  7120,  5295,  4123,   487,  6635,  1047,  1998,  5550,\n",
      "        17347,    84,  4438,    84,    34,  9434,  1846,  1221,  8392,  1491,\n",
      "         4097,  8220,   326, 24314, 10211,  8392,  1491,  7323,  1846,  1297,\n",
      "          527,   326,  1446,  1239,  6063,    30, 25892,   264,   473,  5618,\n",
      "        23480,  5618,    31,  2557,    17,  8412,    10,  4521, 23480,  4521,\n",
      "           31,  2412,   358,  3433,  2239,  3285, 17347,    84,    34,   225,\n",
      "          468,  8054,    30,   512,  9172,   203,   203,   565,  3502,  2557,\n",
      "          857,  1177,    30,   331,    22,   203,   565, 13329,    30,   462,\n",
      "          305,   381, 12124,    36, 17838, 10211,    18,   832,   203,   565,\n",
      "        11025,   635,    30,  2333,  2207,  6662,    18,   832,    19, 23258,\n",
      "           17,  2425,    19, 23258,    17,   710,  4507,    18,  6845,   203,\n",
      "         8395,   203,   203,   203,  2080,  1001, 14343,   972,  1930,  4967,\n",
      "           67,  5666,   203,   203,  5666,  2836,  3813,   203,   203,  5666,\n",
      "        10794, 10211,    67,  2425,    67,  2625,   203,  2080, 10794, 10211,\n",
      "           67,  2425,    67,  2625,    18,  7665,    18,  3278,    67,  4631,\n",
      "         1930, 24792,   225,   468,  8054,    30,   512,  9172,   203,  2080,\n",
      "        10794, 10211,    67,  2425,    67,  2625,    18,  8792,  1930, 10873,\n",
      "          203,   203,   203,  1106,  7766, 27441,    12,  4873,  3813,    18,\n",
      "         4709,  2449,  4672,   203,   565,  3536, 27441,  2836,  1842,  7168,\n",
      "           87,  8395,   203,   203,   565,  1652, 24292,    12,  2890,  4672,\n",
      "          203,  3639,  1342,   203,   203,   565,  1652,   268,  2091,  4164,\n",
      "           12,  2890,  4672,   203,  3639,  1342,   203,   203,   565,  1652,\n",
      "         1842, 27441,    12,  2890,  4672,   203,  3639,  3536,  4709, 24792,\n",
      "         8395,   203,  3639,   468,  9852,    30,  4872,   733,   598, 11791,\n",
      "         1677,   598,  3454,   924,   203,  3639,   468,   938,   273, 10794,\n",
      "        10211,    67,  2425,    67,  2625,    18,  7665,    18,  3278,    67,\n",
      "         4631,    18, 27441,  1435,   225,   468,  8054,    30,   512,  9172,\n",
      "          203,  3639,  1342,   203,   203,   203,   430,  1001,   529,   972,\n",
      "          422,  4940,  5254,   972,  4278,   203,   565,  2836,  3813,    18,\n",
      "         5254,  1435,   203,     2,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "print ((train_dataset[0]))\n",
    "train_dataset.save_to_disk(\"datasets/codet5_train.hf\")\n",
    "test_dataset.save_to_disk(\"datasets/codet5_test.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/sentencepiece.bpe.model from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\e57de2ba12d2b1d3cae7ce5921704890ac50789e8eb95100ff4c64dc98559729.c65001d1986897f4ae6d41d2c49f0e1621d3518cab63e0ffa3005e5deb5aae40\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/uclanlp/plbart-python-en_XX/resolve/main/config.json from cache at C:\\Users\\km201/.cache\\huggingface\\transformers\\68f40642f8534e3482166065ce817305c07e1f4b8ea96013fe62ab865088bddb.8929a51af95d04be1b1d966435fd1ad4a48aca2f2953bc4e4a354b1f1dfd0b55\n",
      "Model config PLBartConfig {\n",
      "  \"_name_or_path\": \"uclanlp/plbart-python-en_XX\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"PLBartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"plbart\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50005\n",
      "}\n",
      "\n",
      "100%|██████████| 173/173 [14:57<00:00,  5.19s/ba]\n",
      "100%|██████████| 44/44 [03:45<00:00,  5.13s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-python-en_XX\", src_lang=\"python\", tgt_lang=\"python\" )\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(tokenization, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "train_dataset.format['type']\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(tokenization, batched=True)\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.format['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(20), 'input_ids': tensor([  754,  6971, 33475,  ...,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "print ((train_dataset[0]))\n",
    "train_dataset.save_to_disk(\"datasets/plbart_train.hf\")\n",
    "test_dataset.save_to_disk(\"datasets/plbart_test.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(-1), 'input_ids': tensor([662, 763, 662,  ...,   1,   1,   1]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "#example method for loading datset checkpoints\n",
    "test = load_from_disk('datasets/plbart_test.hf')\n",
    "test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "print ((test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac9e7467ab50678fb25b34fbfebaa7dd0935f663e602be01974fdf6c9ce75ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
