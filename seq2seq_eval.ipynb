{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "682ffb7c-e655-40eb-ab2c-7f450c356091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval on predictions\n",
    "import re\n",
    "import difflib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from evaluator.CodeBLEU.calc_code_bleu import get_codebleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "from utils.regex_parse import comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f698ad7-471b-455a-a9ab-21b66d1dbd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_codebleu(pred_filename, weights=\"0.25,0.25,0.25,0.25\", replaced_df=None):\n",
    "    pred_df = None\n",
    "    if replaced_df is not None:\n",
    "        pred_df = replaced_df\n",
    "    else:\n",
    "        pred_df = pd.read_csv(pred_filename)\n",
    "    # a list of gold codes (which is just some variants of the same code, we can use every code of different styles)\n",
    "    refs = [\n",
    "        pred_df[\"labels\"]\n",
    "    ]\n",
    "    # the prediction code\n",
    "    hyp = pred_df[\"preds\"]\n",
    "    score = get_codebleu(refs, hyp, \"python\", weights)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3079d5-33de-418c-b3d3-7a68d010e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_split_line(s):\n",
    "    print(f\"\\n====================={s.upper()}=====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72e6e0-a680-41b4-8852-864b69f644a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return re.split('\\s+', s)\n",
    "\n",
    "def get_diff_list(str_1, str_2):\n",
    "    s1 = tokenize(str_1)\n",
    "    s2 = tokenize(str_2)\n",
    "\n",
    "    matcher = difflib.SequenceMatcher(a=s1, b=s2)\n",
    "\n",
    "    diff_blocks_a = []\n",
    "    diff_blocks_b = []\n",
    "\n",
    "    prev_match = None\n",
    "    for idx, match in enumerate(matcher.get_matching_blocks()):\n",
    "\n",
    "        if idx == 0: \n",
    "            prev_match = match\n",
    "            if match.a != 0:\n",
    "                start_idx_a = 0\n",
    "                end_idx_a = match.a\n",
    "                diff_blocks_a += s1[start_idx_a:end_idx_a]\n",
    "            if match.b != 0:\n",
    "                start_idx_b = 0\n",
    "                end_idx_b = match.b\n",
    "                diff_blocks_b += s2[start_idx_b:end_idx_b]\n",
    "            continue\n",
    "\n",
    "        start_idx_a = prev_match.a + prev_match.size\n",
    "        end_idx_a = match.a\n",
    "\n",
    "        start_idx_b = prev_match.b + prev_match.size\n",
    "        end_idx_b = match.b\n",
    "\n",
    "        diff_list_a = s1[start_idx_a:end_idx_a]\n",
    "        diff_list_b = s2[start_idx_b:end_idx_b]\n",
    "        if len(diff_list_a):\n",
    "            diff_blocks_a += diff_list_a\n",
    "        if len(diff_list_b):\n",
    "            diff_blocks_b += diff_list_b\n",
    "\n",
    "        prev_match = match\n",
    "    return diff_blocks_a, diff_blocks_b\n",
    "\n",
    "def get_diff_str(input_str, output_str):\n",
    "    return \" \".join(get_diff_list(input_str, output_str)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891133a5-3134-4dd8-9ead-c9a73ed5e2c3",
   "metadata": {},
   "source": [
    "# Uncomment Parallel Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb10efc-1e36-4e04-8d7c-1c442d6523b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.7020337009365258,\n",
       " 'weighted_ngram': 0.7158332483308997,\n",
       " 'syntax_match': 0.9308169419505175,\n",
       " 'dataflow_match': 0.8687742139204994,\n",
       " 'code_bleu': 0.8043645262846106}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no_outlier_codet5small\n",
    "evaluate_codebleu(\"seq2seq_results/no_outlier_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450c104-b0e1-41f8-a78d-f97a0740a146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0036e88-85d5-4de7-bb9d-68cc81de9aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.7020194689240385,\n",
       " 'weighted_ngram': 0.7148537062012494,\n",
       " 'syntax_match': 0.9295950989323382,\n",
       " 'dataflow_match': 0.8680684288664943,\n",
       " 'code_bleu': 0.8036341757310301}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier_codet5small\n",
    "evaluate_codebleu(\"seq2seq_results/outlier_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1cf91-ab95-48dd-a226-e8d345bed8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a357a66d-82b1-4a93-9138-3ba335083de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_pred_df = pd.read_csv(\"seq2seq_results/outlier_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0edefd98-31d1-467f-9f98-b28c08dd8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding those input exactly same as the output\n",
    "exact_match_bool = comment_pred_df[\"inputs\"] == comment_pred_df[\"labels\"]\n",
    "cleaned_comment_pred_df = comment_pred_df.drop(comment_pred_df[exact_match_bool].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a8ba3-0522-4ff9-b018-f6cbee27a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_codebleu(\"\", weights=\"0.25,0.25,0.25,0.25\", replaced_df=cleaned_comment_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e6c5403-4de8-4fcc-af78-a81ea8397373",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_pred_df = cleaned_comment_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a8b674c-a066-467d-b76b-eede739a46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_inputs = comment_pred_df[\"inputs\"].to_numpy()\n",
    "comment_labels = comment_pred_df[\"labels\"].to_numpy()\n",
    "comment_preds = comment_pred_df[\"preds\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4185e-912b-446f-bcd4-13c485a246fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting unit score\n",
    "comment_code_scores = []\n",
    "comment_text_scores = []\n",
    "comment_diff_bleu_scores = []\n",
    "\n",
    "gold_comments = []\n",
    "pred_comments = []\n",
    "gold_comment_texts = []\n",
    "pred_comment_texts = []\n",
    "gold_comments_count = []\n",
    "pred_comments_count = []\n",
    "gold_has_comments_list = []\n",
    "pred_has_comments_list = []\n",
    "\n",
    "for idx in tqdm(range(comment_preds.shape[0])):\n",
    "    input_code = comment_inputs[idx]\n",
    "    gold = comment_labels[idx]\n",
    "    pred = comment_preds[idx]\n",
    "    refs = [\n",
    "        [gold]\n",
    "    ]\n",
    "    hyp = [pred]\n",
    "    \n",
    "    comment_code_score = get_codebleu(refs, hyp, \"python\", '0.25,0.25,0.25,0.25')\n",
    "    \n",
    "    gold_comment = comment(gold)\n",
    "    pred_comment = comment(pred)\n",
    "    gold_comment_text = \"\\n\".join(gold_comment)\n",
    "    pred_comment_text = \"\\n\".join(pred_comment)\n",
    "    gold_comment_count = len(gold_comment)\n",
    "    pred_comment_count = len(pred_comment)\n",
    "    gold_has_comment = len(gold_comment) > 0\n",
    "    pred_has_comment = len(pred_comment) > 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    gold_diff_str = get_diff_str(input_code, gold)\n",
    "    pred_diff_str = get_diff_str(input_code, pred)\n",
    "    \n",
    "    comment_diff_bleu_score = 0\n",
    "    if len(pred_diff_str.split()) > 0:\n",
    "        comment_diff_bleu_score = sentence_bleu([gold_diff_str.split()], pred_diff_str.split(), auto_reweigh=True)\n",
    "    \n",
    "    comment_text_score = get_codebleu([[gold_comment_text]], [pred_comment_text], \"python\", '1,0,0,0')\n",
    "    \n",
    "    comment_code_scores += [comment_code_score]\n",
    "    comment_text_scores += [comment_text_score]\n",
    "    comment_diff_bleu_scores += [comment_diff_bleu_score]\n",
    "       \n",
    "    gold_comments += [gold_comment]\n",
    "    pred_comments += [pred_comment]\n",
    "    gold_comment_texts += [gold_comment_text]\n",
    "    pred_comment_texts += [pred_comment_text]\n",
    "    gold_comments_count += [gold_comment_count]\n",
    "    pred_comments_count += [pred_comment_count]\n",
    "    gold_has_comments_list += [gold_has_comment]\n",
    "    pred_has_comments_list += [pred_has_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0808cdcb-c92b-4c85-b8c6-02cba99e35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_bleu_scores = np.array([s[\"ngram\"] for s in comment_text_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8529e210-04c5-4346-807a-d2297bebfe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18750932499757741"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_bleu_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "61e79f11-1095-49d9-9ab9-230efdb6d495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Comment BLEU score on only comparing difference in prediction:',\n",
       " 0.2515634110214649)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Comment BLEU score on only comparing difference in prediction:\", np.mean(comment_diff_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9824b0-4798-4220-924e-8d7354dd9675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_bleu_scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f168f7-b81e-4c02-80ac-0c2ceb3c8f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013987750892306"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_bleu_scores[3236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f7f0728-0ba9-4e4e-a86f-bc75d2204ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================188-PREDICTION=====================\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "import os\n",
      "import worlds as my_world\n",
      "\n",
      "fldr = os.getcwd() + os.sep + 'data' + os.sep + 'worlds'\n",
      "\n",
      "class Planet(object):\n",
      "    \"\"\"\n",
      "    class to manage the simplified evolution of a planet to \n",
      "    build a virtual world. Takes basic atmospheric parameters\n",
      "    and *very* roughly uses these to guess what the world would\n",
      "    look like.\n",
      "    The idea is to be able to auto generate worlds as follows:\n",
      "    green lush worlds: sun > 0.15, rain > 0.15\n",
      "    earth like worlds: sun=0.2, rain=0.1, wind=0.1\n",
      "    metal rich worlds: sun<0.2, wind>0.2, seismic_activity>0.6\n",
      "    \"\"\"\n",
      "    def __init__(self, name, num_seeds, width, height, wind, rain, sun, lava):\n",
      "        \"\"\"\n",
      "        All parameters must be between 0 and 1 and show the probability of\n",
      "        that event. The numbers below are rough guidelines for normal planets\n",
      "        wind 0.0 -> 0.2 : determines air currents, rain movement, topsoil\n",
      "        rain 0.1 -> 0.6 : determines plant growth, river networks\n",
      "        sun  0.1 -> 0.6 : determines plant growth, river networks\n",
      "        lava 0.1 -> 0.6 : during formation only - determines mountains\n",
      "        \"\"\"\n",
      "        self.world = ''\n",
      "        self.name = name\n",
      "        self.num_seeds = num_seeds\n",
      "        self.grid_height = height\n",
      "        self.grid_width = width\n",
      "        self.wind = wind\n",
      "        self.sun = sun\n",
      "        self.rain = rain\n",
      "        self.lava = lava\n",
      "\n",
      "    def __str__(self):\n",
      "        res = '\\n-- Welcome to'+ self.name +'--\\n'\n",
      "        res += self._stats_as_str(delim=' = ', lf='\\n')\n",
      "        return res\n",
      "\n",
      "    def _stats_as_str\n",
      "\n",
      "=====================188-GOLD LABELS=====================\n",
      "\n",
      "#!/usr/bin/python3\n",
      "# -*- coding: utf-8 -*-\n",
      "# planet.py\n",
      "\n",
      "import os\n",
      "import worlds as my_world\n",
      " \n",
      "fldr = os.getcwd() + os.sep + 'data'  + os.sep + 'worlds' \n",
      "\n",
      "class Planet(object):\n",
      "    \"\"\"\n",
      "    class to manage the simplified evolution of a planet to \n",
      "    build a virtual world. Takes basic atmospheric parameters\n",
      "    and *very* roughly uses these to guess what the world would\n",
      "    look like.\n",
      "    The idea is to be able to auto generate worlds as follows:\n",
      "    green lush worlds: sun > 0.15, rain > 0.15\n",
      "    earth like worlds: sun=0.2, rain=0.1, wind=0.1\n",
      "    metal rich worlds: sun<0.2, wind>0.2, seismic_activity>0.6\n",
      "    \"\"\"\n",
      "    def __init__(self, name, num_seeds, width, height, wind, rain, sun, lava):\n",
      "        \"\"\"\n",
      "        All parameters must be between 0 and 1 and show the probability of\n",
      "        that event. The numbers below are rough guidelines for normal planets\n",
      "        wind 0.0 -> 0.2 : determines air currents, rain movement, topsoil\n",
      "        rain 0.1 -> 0.6 : determines plant growth, river networks\n",
      "        sun  0.1 -> 0.6 : determines plant growth, river networks\n",
      "        lava 0.1 -> 0.6 : during formation only - determines mountains\n",
      "        \"\"\"\n",
      "        self.world = ''     # aikif.environment.world object\n",
      "        self.name = name\n",
      "        self.num_seeds = num_seeds\n",
      "        self.grid_height = height\n",
      "        self.grid_width = width\n",
      "        self.wind = wind\n",
      "        self.sun = sun\n",
      "        self.rain = rain\n",
      "        self.lava = lava\n",
      "    \n",
      "    def __str__(self):\n",
      "        res = '\\n-- Welcome to'+ self.name +'--\\n'\n",
      "        res += self._stats_as_str(delim ='= ',\n",
      "\n",
      "=====================188-SCORE=====================\n",
      "\n",
      "0.34718201116725705\n"
     ]
    }
   ],
   "source": [
    "idx = 188\n",
    "print_split_line(f\"{idx}-prediction\")\n",
    "print(comment_preds[idx])\n",
    "print_split_line(f\"{idx}-gold labels\")\n",
    "print(comment_labels[idx])\n",
    "print_split_line(f\"{idx}-score\")\n",
    "print(comment_bleu_scores[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "200a5a9d-aaaa-44c5-9918-6e77ec28492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449, 2334)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_total = len(comment_preds)\n",
    "sum(pred_has_comments_list), sum(gold_has_comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bcb9b2-3053-4df1-85e4-990f8822ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(comment_total):\n",
    "    if comment_bleu_scores[idx] < 0.5 or comment_bleu_scores[idx] > 0.95:    \n",
    "        continue\n",
    "    \n",
    "    if not pred_has_comments_list[idx]:\n",
    "        continue\n",
    "    if not gold_has_comments_list[idx]:\n",
    "        continue\n",
    "        \n",
    "#     if \"copyright\" in pred_comment_texts[idx].lower():\n",
    "#         continue\n",
    "        \n",
    "#     if \"copyright\" in gold_comment_texts[idx].lower():\n",
    "#         continue\n",
    "        \n",
    "#     if \"license\" in pred_comment_texts[idx].lower():\n",
    "#         continue\n",
    "        \n",
    "#     if \"license\" in gold_comment_texts[idx].lower():\n",
    "#         continue\n",
    "        \n",
    "    \n",
    "        \n",
    "#     if \"\\n#\" in pred_comment_texts[idx].lower():\n",
    "#         continue\n",
    "        \n",
    "    # if \" #\" not in gold_comment_texts[idx].lower():\n",
    "    #     continue\n",
    "    \n",
    "    # if \" #\" in pred_comment_texts[idx].lower():\n",
    "    print_split_line(f\"{idx}-prediction\")\n",
    "    print(comment_preds[idx])\n",
    "    print_split_line(f\"{idx}-gold labels\")\n",
    "    print(comment_labels[idx])\n",
    "    print_split_line(f\"{idx}-score\")\n",
    "    print(comment_bleu_scores[idx])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27578397-ec84-420a-b964-dadaf1da6238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of whether both do or do not have comments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6509259259259259"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy of whether both do or do not have comments\")\n",
    "sum(np.array(pred_has_comments_list) == np.array(gold_has_comments_list)) / comment_total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9590f0d4-3da4-447d-8c97-9ba435cef63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of whether both have same comment counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4049382716049383"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy of whether both have same comment counts\")\n",
    "sum(np.array(gold_comments_count) == np.array(pred_comments_count)) / comment_total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "347bcc10-0c95-4865-acb2-e44d95db609d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and(comment_bleu_scores == 1, np.array(pred_has_comments_list), np.array(gold_has_comments_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3be5bb75-36b4-4995-8987-6e9b18354482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Prediction Rate: 0.09598765432098766\n",
      "Above 0.9 Comment BLEU Prediction Rate: 0.13425925925925927\n"
     ]
    }
   ],
   "source": [
    "print(\"Perfect Prediction Rate:\", sum(comment_bleu_scores == 1) / comment_total)\n",
    "print(\"Above 0.9 Comment BLEU Prediction Rate:\", sum(comment_bleu_scores >= 0.9) / comment_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e1c1efc-cbf3-48c8-a475-a496771e1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Prediction Rate: 0.09598765432098766\n",
      "Above 0.9 Comment BLEU Prediction Rate: 0.13425925925925927\n"
     ]
    }
   ],
   "source": [
    "print(\"Perfect Prediction Rate:\", sum(np.logical_and(comment_bleu_scores == 1, np.array(pred_has_comments_list), np.array(gold_has_comments_list))) / comment_total)\n",
    "print(\"Above 0.9 Comment CodeBLEU Prediction Rate:\", sum(np.logical_and(comment_bleu_scores >= 0.9, np.array(pred_has_comments_list), np.array(gold_has_comments_list))) / comment_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6572df29-ea42-4dcf-a916-bf917db9b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================PREDICTION=====================\n",
      "# coding=utf-8\n",
      "# Copyright 2022 The TensorFlow Datasets Authors.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "\"\"\"Tests for trajectory.\"\"\"\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "from tf_agents.drivers import dynamic_episode_driver\n",
      "from tf_agents.drivers import test_utils as drivers_test_utils\n",
      "from tf_agents.environments import tf_py_environment\n",
      "from tf_agents.trajectories import time_step as ts\n",
      "from tf_agents.trajectories import trajectory\n",
      "from tf_agents.utils import test_utils\n",
      "\n",
      "\n",
      "class TrajectoryTest(test_utils.TestCase):\n",
      "\n",
      "  def testFirstTensors(self):\n",
      "    observation = ()\n",
      "    action = ()\n",
      "    policy_info = ()\n",
      "    reward = tf.constant([1.0, 1.0, 2.0])\n",
      "    discount = tf.constant([1.0, 1.0, 1.0])\n",
      "    traj = trajectory.first(observation, action, policy_info, reward, discount)\n",
      "    self.assertTrue(tf.is_tensor(traj.step_type))\n",
      "    traj_val = self.evaluate(traj)\n",
      "    self.assertAllEqual(traj_val.step_type, [ts.StepType.FIRST] * 3)\n",
      "    self.assertAllEqual(traj_val.next_step_type, [ts.StepType.MID] * 3)\n",
      "\n",
      "  def testFirstArrays(self):\n",
      "    observation = ()\n",
      "    action = ()\n",
      "\n",
      "=====================GOLD LABELS=====================\n",
      "# coding=utf-8\n",
      "# Copyright 2020 The TF-Agents Authors.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "\"\"\"Tests for trajectory.\"\"\"\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
      "\n",
      "from tf_agents.drivers import dynamic_episode_driver\n",
      "from tf_agents.drivers import test_utils as drivers_test_utils\n",
      "from tf_agents.environments import tf_py_environment\n",
      "from tf_agents.trajectories import time_step as ts\n",
      "from tf_agents.trajectories import trajectory\n",
      "from tf_agents.utils import test_utils\n",
      "\n",
      "\n",
      "class TrajectoryTest(test_utils.TestCase):\n",
      "\n",
      "  def testFirstTensors(self):\n",
      "    observation = ()\n",
      "    action = ()\n",
      "    policy_info = ()\n",
      "    reward = tf.constant([1.0, 1.0, 2.0])\n",
      "    discount = tf.constant([1.0, 1.0, 1.0])\n",
      "    traj = trajectory.first(observation, action, policy_info, reward, discount)\n",
      "    self.assertTrue(tf.is_tensor(traj.step_type))\n",
      "    traj_val = self.evaluate(traj)\n",
      "    self.assertAllEqual(traj_val.step_type, [ts.StepType.FIRST] * 3)\n",
      "    self.assertAllEqual(traj_val.next_step_type, [ts.StepType.MID] * 3)\n",
      "\n",
      "  def testFirstArrays(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_split_line(\"prediction\")\n",
    "print(preds[3236])\n",
    "print_split_line(\"gold labels\")\n",
    "print(labels[3236])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de274092-1f1a-4004-9870-3c0ceeaf56c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.030049336124714957,\n",
       " 'weighted_ngram': 0.049595120779045175,\n",
       " 'syntax_match': 0.9565217391304348,\n",
       " 'dataflow_match': 1.0,\n",
       " 'code_bleu': 0.5090415490085487}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_codebleu([[labels[20]]], [preds[20]], \"python\", '0.25,0.25,0.25,0.25')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b571c7-1d8e-4166-b45b-e6b56b659bee",
   "metadata": {},
   "source": [
    "# Removed Class Parallel Corpus - with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f7eaf4-5954-47dd-ac0a-9c672ab20c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.9539663181494397,\n",
       " 'weighted_ngram': 0.955850824785441,\n",
       " 'syntax_match': 0.9574235970530824,\n",
       " 'dataflow_match': 0.8715078962664325,\n",
       " 'code_bleu': 0.9346871590635989}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier_class_codet5small\n",
    "evaluate_codebleu(\"seq2seq_results/outlier_class_codet5small/codet5_preds.csv\",  '0.25,0.25,0.25,0.25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bc4b396-5404-4474-9fc5-a26b4b85b8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_pred_df = pd.read_csv(\"seq2seq_results/outlier_class_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d429400d-0434-47d7-92f7-5ebc49d7cf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>preds</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"\"\"Sequence-to-sequence model with an attentio...</td>\n",
       "      <td>\"\"\"Sequence-to-sequence model with an attentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>from django.db import models, migrations\\n\\ncl...</td>\n",
       "      <td>from django.db import models, migrations\\n\\ncl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>from lampost.di.resource import Injected, modu...</td>\n",
       "      <td>from lampost.di.resource import Injected, modu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>import logging\\nfrom typing import Any, Dict\\n...</td>\n",
       "      <td>import logging\\nfrom typing import Any, Dict\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"\"\"Module for finding vulnerabilities based on...</td>\n",
       "      <td>\"\"\"Module for finding vulnerabilities based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>7840</td>\n",
       "      <td>from.dice import Dice\\nfrom.player import Play...</td>\n",
       "      <td>from.dice import Dice\\nfrom.player import Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>7841</td>\n",
       "      <td>from.views import BaseView\\nfrom forums.extens...</td>\n",
       "      <td>from.views import BaseView\\nfrom forums.extens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>7842</td>\n",
       "      <td>\"\"\"\\nutils.py\\n========\\nThis submodule contai...</td>\n",
       "      <td>\"\"\"\\nutils.py\\n========\\nThis submodule contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>7843</td>\n",
       "      <td>\"\"\"Tests for audio_classifier.\"\"\"\\nimport enum...</td>\n",
       "      <td>\"\"\"Tests for audio_classifier.\"\"\"\\nimport enum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>7844</td>\n",
       "      <td>import requests\\nimport re\\nimport logging\\nim...</td>\n",
       "      <td>import requests\\nimport re\\nimport logging\\nim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7845 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              preds  \\\n",
       "0              0  \"\"\"Sequence-to-sequence model with an attentio...   \n",
       "1              1  from django.db import models, migrations\\n\\ncl...   \n",
       "2              2  from lampost.di.resource import Injected, modu...   \n",
       "3              3  import logging\\nfrom typing import Any, Dict\\n...   \n",
       "4              4  \"\"\"Module for finding vulnerabilities based on...   \n",
       "...          ...                                                ...   \n",
       "7840        7840  from.dice import Dice\\nfrom.player import Play...   \n",
       "7841        7841  from.views import BaseView\\nfrom forums.extens...   \n",
       "7842        7842  \"\"\"\\nutils.py\\n========\\nThis submodule contai...   \n",
       "7843        7843  \"\"\"Tests for audio_classifier.\"\"\"\\nimport enum...   \n",
       "7844        7844  import requests\\nimport re\\nimport logging\\nim...   \n",
       "\n",
       "                                                 labels  \n",
       "0     \"\"\"Sequence-to-sequence model with an attentio...  \n",
       "1     from django.db import models, migrations\\n\\ncl...  \n",
       "2     from lampost.di.resource import Injected, modu...  \n",
       "3     import logging\\nfrom typing import Any, Dict\\n...  \n",
       "4     \"\"\"Module for finding vulnerabilities based on...  \n",
       "...                                                 ...  \n",
       "7840  from.dice import Dice\\nfrom.player import Play...  \n",
       "7841  from.views import BaseView\\nfrom forums.extens...  \n",
       "7842  \"\"\"\\nutils.py\\n========\\nThis submodule contai...  \n",
       "7843  \"\"\"Tests for audio_classifier.\"\"\"\\nimport enum...  \n",
       "7844  import requests\\nimport re\\nimport logging\\nim...  \n",
       "\n",
       "[7845 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12bd893b-fe2c-43fa-8b3d-97f452d298fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = class_pred_df[\"labels\"].to_numpy()\n",
    "class_preds = class_pred_df[\"preds\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05f1a3-f240-4dbd-a0c2-59db0055a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting unit score\n",
    "class_scores = []\n",
    "for idx in tqdm(range(class_preds.shape[0])):\n",
    "    refs = [\n",
    "        [class_labels[idx]]\n",
    "    ]\n",
    "    hyp = [class_preds[idx]]\n",
    "    score = get_codebleu(refs, hyp, \"python\", '0.25,0.25,0.25,0.25')\n",
    "    class_scores += [score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eea7945a-8668-4ba0-bd5d-32898ffebc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_total = class_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21b12ff0-5221-461e-adfa-9ce8bd975706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for idx, score in enumerate(class_scores):\n",
    "    if score[\"weighted_ngram\"] == 1:\n",
    "        print(idx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf8db7-8e84-497e-ac31-9d95b18b4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_from_disk, load_metric\n",
    "fname_prefix = \"\"\n",
    "\n",
    "test_codet5_dataset = load_from_disk(fname_prefix + 'datasets/codet5_test_class_bq_padded.hf') #codet5_train_class_bq_padded.hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62510218-ecc1-440d-ba75-3e38ea081558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 63833\n"
     ]
    }
   ],
   "source": [
    "keyword = \"Construct sequence encoder\"\n",
    "for idx, code in enumerate(test_codet5_dataset[\"content\"]):\n",
    "    if keyword in code:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e9b0e0a-3f36-44e0-a6a4-4539bad67f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code_bleus = np.array([s[\"code_bleu\"] for s in class_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30bf99ca-da29-49ec-bba8-299c39b3902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Prediction Rate: 0.28846398980242194\n",
      "Above 0.9 CodeBLEU Prediction Rate: 0.7445506692160612\n"
     ]
    }
   ],
   "source": [
    "print(\"Perfect Prediction Rate:\", sum(class_code_bleus == 1) / class_total)\n",
    "print(\"Above 0.9 CodeBLEU Prediction Rate:\", sum(class_code_bleus > 0.9) / class_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48869baf-3f1f-4d0b-86f1-8055bc73fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a perfect case\n",
    "print_split_line(\"input\")\n",
    "print(eval_dataset[\"train\"][\"no_class_content\"][63833])\n",
    "print_split_line(\"prediction\")\n",
    "print(class_preds[0])\n",
    "print_split_line(\"gold labels\")\n",
    "print(class_labels[0])\n",
    "print_split_line(\"score\")\n",
    "print(class_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e50e41-8226-456b-a5fe-3ec23adf49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_idx = 53092\n",
    "output_idx = 4293\n",
    "print_split_line(\"input\")\n",
    "print(eval_dataset[\"train\"][\"no_class_content\"][input_idx])\n",
    "print_split_line(\"prediction\")\n",
    "print(class_preds[output_idx])\n",
    "print_split_line(\"gold labels\")\n",
    "print(class_labels[output_idx])\n",
    "print_split_line(\"score\")\n",
    "print(class_scores[output_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16b50a80-234f-4828-bfa7-1192036b4671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import ctypes\n",
      "pass\n",
      "\n",
      "def __init__(message):\n",
      "    message += (' (%s)' % ctypes.WinError())\n",
      "    super(PyperclipWindowsException, self).__init__(message)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval_dataset[\"train\"][\"no_class_content\"][74459])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cff02d4c-106f-4a22-86dd-c4faf474ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RobertaTokenizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ecd68-a41c-4403-baf2-6f7c4dff9ca0",
   "metadata": {},
   "source": [
    "# Removed Doc String Parallel Corpus - with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a83418-e4e0-48ec-b3c6-c7508e893401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.6007622882171681,\n",
       " 'weighted_ngram': 0.6152656721984298,\n",
       " 'syntax_match': 0.8764716714385848,\n",
       " 'dataflow_match': 0.7972510418090768,\n",
       " 'code_bleu': 0.7224376684158149}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier_docstring_codet5small\n",
    "evaluate_codebleu(\"seq2seq_results/outlier_docstring_codet5small/codet5_preds.csv\",  '0.25,0.25,0.25,0.25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d20e1e56-3782-491c-96f7-a4031e53e642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docstr_pred_df = pd.read_csv(\"seq2seq_results/outlier_docstring_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97da03fc-6ad5-4dc6-be2a-bac180bdc2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstr_labels = docstr_pred_df[\"labels\"].to_numpy()\n",
    "docstr_preds = docstr_pred_df[\"preds\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46dd773a-3d36-4082-af22-eca3113ee588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_docstring(text):\n",
    "    regex_docstr = \"^\\s*\\'{3}([\\s\\S]*?)\\'{3}|^\\s*\\\"{3}([\\s\\S]*?)\\\"{3}\"\n",
    "    docstr_matches = re.findall(regex_docstr, text, re.M | re.S)\n",
    "    docstrs = []\n",
    "    for match in docstr_matches:\n",
    "        docstr_a, docstr_b = match\n",
    "        if docstr_a:\n",
    "            docstrs += [docstr_a]\n",
    "        else:\n",
    "            docstrs += [docstr_b]\n",
    "    return docstrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe1693-f846-449e-b61d-fb387782570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting unit score\n",
    "gold_docstrs = []\n",
    "pred_docstrs = []\n",
    "gold_docstr_counts = []\n",
    "pred_docstr_counts = []\n",
    "gold_docstr_texts = []\n",
    "pred_docstr_texts = []\n",
    "gold_has_docstr_list = []\n",
    "pred_has_docstr_list = []\n",
    "\n",
    "docstr_code_scores = []\n",
    "docstr_text_scores = []\n",
    "\n",
    "for idx in tqdm(range(docstr_preds.shape[0])):\n",
    "    \n",
    "    gold = docstr_labels[idx]\n",
    "    pred = docstr_preds[idx]\n",
    "    \n",
    "    refs = [\n",
    "        [gold]\n",
    "    ]\n",
    "    hyp = [pred]\n",
    "    \n",
    "    gold_docstr = get_docstring(gold)\n",
    "    pred_docstr = get_docstring(pred)\n",
    "    gold_docstr_text = \"\\n\".join(gold_docstr)\n",
    "    pred_docstr_text = \"\\n\".join(pred_docstr)\n",
    "    gold_docstr_count = len(gold_docstr)\n",
    "    pred_docstr_count = len(pred_docstr)\n",
    "    gold_has_docstr = len(gold_docstr) > 0\n",
    "    pred_has_docstr = len(pred_docstr) > 0\n",
    "    \n",
    "    \n",
    "    docstr_code_score = get_codebleu(refs, hyp, \"python\", '0.25,0.25,0.25,0.25')\n",
    "    docstr_text_score = get_codebleu([[gold_docstr_text]], [pred_docstr_text], \"python\", '1,0,0,0')\n",
    "    \n",
    "    docstr_code_scores += [docstr_code_score]\n",
    "    docstr_text_scores += [docstr_text_score]\n",
    "       \n",
    "    gold_docstrs += [gold_docstr]\n",
    "    pred_docstrs += [pred_docstr]\n",
    "    gold_docstr_texts += [gold_docstr_text]\n",
    "    pred_docstr_texts += [pred_docstr_text]\n",
    "    gold_docstr_counts += [gold_docstr_count]\n",
    "    pred_docstr_counts += [pred_docstr_count]\n",
    "    gold_has_docstr_list += [gold_has_docstr]\n",
    "    pred_has_docstr_list += [pred_has_docstr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30f1c0d3-2bd1-46de-a676-ee4118ac0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstr_text_bleus = np.array([s[\"ngram\"] for s in docstr_text_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e35344db-3345-43c3-89e2-cebb539198eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstr_code_bleus = np.array([s[\"code_bleu\"] for s in docstr_code_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d40f6655-95f6-44a5-aa75-d5762d11b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06557760175998402"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docstr_text_bleus.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95f87bc1-81c7-4943-8af8-cc375339bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstr_total = docstr_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf6a2f11-ae18-4079-84e7-ef4f0556c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Prediction Rate: 0.02549928673323823\n",
      "Above 0.9 CodeBLEU Prediction Rate: 0.03245363766048502\n"
     ]
    }
   ],
   "source": [
    "print(\"Perfect Prediction Rate:\", sum(docstr_text_bleus == 1) / docstr_total)\n",
    "print(\"Above 0.9 CodeBLEU Prediction Rate:\", sum(docstr_text_bleus > 0.9) / docstr_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b9e7b-87a0-43f1-9ca1-e21e88a37fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 760\n",
    "print_split_line(f\"{idx}-prediction\")\n",
    "print(docstr_preds[idx])\n",
    "print_split_line(f\"{idx}-gold labels\")\n",
    "print(docstr_labels[idx])\n",
    "print_split_line(f\"{idx}-score\")\n",
    "print(docstr_text_bleus[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b0b76-340d-41d7-8aff-43f7d555511e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(docstr_total):\n",
    "    if docstr_text_bleus[idx] >= 0.5:\n",
    "        print_split_line(f\"{idx}-prediction\")\n",
    "        print(pred_docstr_texts[idx])\n",
    "        print_split_line(f\"{idx}-gold labels\")\n",
    "        print(gold_docstr_texts[idx])\n",
    "        print_split_line(f\"{idx}-score\")\n",
    "        print(docstr_text_bleus[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23023b11-6979-4340-98bb-22b11e81d8a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c26d2b2-bede-423b-8122-75c29fb1b830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.9464984063637811,\n",
       " 'weighted_ngram': 0.9492120027209221,\n",
       " 'syntax_match': 0.9920926165526851,\n",
       " 'dataflow_match': 0.9604937079397652,\n",
       " 'code_bleu': 0.9620741833942883}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier_casing_codet5small\n",
    "evaluate_codebleu(\"seq2seq_results/outlier_casing_codet5small/codet5_preds.csv\",  '0.25,0.25,0.25,0.25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0170474c-fd38-4420-a716-6ea941ef5e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "casing_pred_df = pd.read_csv(\"seq2seq_results/outlier_casing_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fffdd6bd-73c6-4baa-87ea-281b9447d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding those input exactly same as the output\n",
    "exact_match_bool = casing_pred_df[\"inputs\"] == casing_pred_df[\"labels\"]\n",
    "cleaned_casing_pred_df = casing_pred_df.drop(casing_pred_df[exact_match_bool].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a785a428-52d6-4f76-a674-57f0b9ec538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.9440698608811208,\n",
       " 'weighted_ngram': 0.9469331824692371,\n",
       " 'syntax_match': 0.9917691355554074,\n",
       " 'dataflow_match': 0.9588187759294317,\n",
       " 'code_bleu': 0.9603977387087993}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_codebleu(\"\",  '0.25,0.25,0.25,0.25', replaced_df=cleaned_casing_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db8d61f8-51f0-4204-9fff-dfc2cf936dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "casing_pred_df = cleaned_casing_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80c3ce31-a379-427f-9180-81f2fabad05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "casing_inputs = casing_pred_df[\"inputs\"].to_numpy()\n",
    "casing_labels = casing_pred_df[\"labels\"].to_numpy()\n",
    "casing_preds = casing_pred_df[\"preds\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f45d1-2a22-4b26-8be8-6e6fd2e5c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting unit score\n",
    "\n",
    "# input_casing = []\n",
    "# gold_casing = []\n",
    "# pred_casing = []\n",
    "\n",
    "# gold_docstrs = []\n",
    "# pred_docstrs = []\n",
    "# gold_docstr_counts = []\n",
    "# pred_docstr_counts = []\n",
    "# gold_docstr_texts = []\n",
    "# pred_docstr_texts = []\n",
    "# gold_has_docstr_list = []\n",
    "# pred_has_docstr_list = []\n",
    "\n",
    "casing_code_scores = []\n",
    "casing_diff_bleu_scores = []\n",
    "# docstr_text_scores = []\n",
    "\n",
    "for idx in tqdm(range(casing_preds.shape[0])):\n",
    "    input_code = casing_inputs[idx]\n",
    "    gold = casing_labels[idx]\n",
    "    pred = casing_preds[idx]\n",
    "    \n",
    "    refs = [\n",
    "        [gold]\n",
    "    ]\n",
    "    hyp = [pred]\n",
    "    \n",
    "    gold_diff_str = get_diff_str(input_code, gold)\n",
    "    pred_diff_str = get_diff_str(input_code, pred)\n",
    "    \n",
    "    casing_diff_bleu_score = 0\n",
    "    if len(pred_diff_str) > 0:\n",
    "        casing_diff_bleu_score = sentence_bleu([gold_diff_str.split()], pred_diff_str.split(), auto_reweigh=True)\n",
    "    # gold_docstr = get_docstring(gold)\n",
    "    # pred_docstr = get_docstring(pred)\n",
    "    # gold_docstr_text = \"\\n\".join(gold_docstr)\n",
    "    # pred_docstr_text = \"\\n\".join(pred_docstr)\n",
    "    # gold_docstr_count = len(gold_docstr)\n",
    "    # pred_docstr_count = len(pred_docstr)\n",
    "    # gold_has_docstr = len(gold_docstr) > 0\n",
    "    # pred_has_docstr = len(pred_docstr) > 0\n",
    "    \n",
    "    \n",
    "    casing_code_score = get_codebleu(refs, hyp, \"python\", '0.25,0.25,0.25,0.25')\n",
    "    # docstr_text_score = get_codebleu([[gold_docstr_text]], [pred_docstr_text], \"python\", '1,0,0,0')\n",
    "    \n",
    "    casing_code_scores += [casing_code_score]\n",
    "    casing_diff_bleu_scores += [casing_diff_bleu_score]\n",
    "    # docstr_text_scores += [docstr_text_score]\n",
    "       \n",
    "    # gold_docstrs += [gold_docstr]\n",
    "    # pred_docstrs += [pred_docstr]\n",
    "    # gold_docstr_texts += [gold_docstr_text]\n",
    "    # pred_docstr_texts += [pred_docstr_text]\n",
    "    # gold_docstr_counts += [gold_docstr_count]\n",
    "    # pred_docstr_counts += [pred_docstr_count]\n",
    "    # gold_has_docstr_list += [gold_has_docstr]\n",
    "    # pred_has_docstr_list += [pred_has_docstr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a21acd58-399a-410a-bc1c-24181f9183c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Casing BLEU score on only comparing difference in prediction:',\n",
       " 0.7060336355803001)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Casing BLEU score on only comparing difference in prediction:\", np.mean(casing_diff_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7b5e76bd-1e1e-4999-a4cf-0b1c6ad51bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstr_text_bleus = np.array([s[\"ngram\"] for s in docstr_text_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fb5d0a4d-38d1-4c35-aa97-d66982b92140",
   "metadata": {},
   "outputs": [],
   "source": [
    "casing_code_bleus = np.array([s[\"code_bleu\"] for s in casing_code_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b4bdf31-72d4-49ac-be22-43c976791deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstr_text_bleus.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92e6cfab-5070-4c59-8d7d-bcb3bcf1a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "casing_total = casing_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08c404bc-e032-43ae-96aa-0e818b976f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Prediction Rate: 0.5115195663222091\n",
      "Above 0.9 CodeBLEU Prediction Rate: 0.8553277994240217\n"
     ]
    }
   ],
   "source": [
    "print(\"Perfect Prediction Rate:\", sum(casing_code_bleus == 1) / casing_total)\n",
    "print(\"Above 0.9 CodeBLEU Prediction Rate:\", sum(casing_code_bleus > 0.9) / casing_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c04d94-a715-45d7-baa8-ebf217e80ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 760\n",
    "print_split_line(f\"{idx}-prediction\")\n",
    "print(docstr_preds[idx])\n",
    "print_split_line(f\"{idx}-gold labels\")\n",
    "print(docstr_labels[idx])\n",
    "print_split_line(f\"{idx}-score\")\n",
    "print(docstr_text_bleus[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f5faf-b57a-4e19-ada2-d1963300a94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(casing_total):\n",
    "    if casing_code_bleus[idx] < 0.6 and casing_code_bleus[idx] > 0.5:\n",
    "        print_split_line(f\"{idx}-input\")\n",
    "        print(casing_inputs[idx])\n",
    "        print_split_line(f\"{idx}-prediction\")\n",
    "        print(casing_preds[idx])\n",
    "        print_split_line(f\"{idx}-gold labels\")\n",
    "        print(casing_labels[idx])\n",
    "        print_split_line(f\"{idx}-score\")\n",
    "        print(casing_code_bleus[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cd0dd-42a1-4af0-826e-4df8bcf6b487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4d9f14-a0b9-466c-8416-515345d22ce5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2b922e-0c82-4dba-ae70-1b4589e5ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.9872128913481273,\n",
       " 'weighted_ngram': 0.9873731766619129,\n",
       " 'syntax_match': 0.9819772416779816,\n",
       " 'dataflow_match': 0.9498150078983433,\n",
       " 'code_bleu': 0.9765945793965913}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier_comp_codet5small\n",
    "evaluate_codebleu(\"seq2seq_results/outlier_comp_codet5small/codet5_preds.csv\",  '0.25,0.25,0.25,0.25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc4ff9f4-4fa5-4be7-9230-cdd6b4b67cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comp_pred_df = pd.read_csv(\"seq2seq_results/outlier_comp_codet5small/codet5_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "055d452b-b991-41c3-81cf-fd404ce86324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding those input exactly same as the output\n",
    "exact_match_bool = comp_pred_df[\"inputs\"] == comp_pred_df[\"labels\"]\n",
    "cleaned_comp_pred_df = comp_pred_df.drop(comp_pred_df[exact_match_bool].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32af7d74-beb7-4cfa-82bf-7ca4c3ef8a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ngram': 0.968530550095664,\n",
       " 'weighted_ngram': 0.9689526941115969,\n",
       " 'syntax_match': 0.960221464239374,\n",
       " 'dataflow_match': 0.8916389008662929,\n",
       " 'code_bleu': 0.947335902328232}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_codebleu(\"\",  '0.25,0.25,0.25,0.25', replaced_df=cleaned_comp_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d885482c-0ae9-4c4a-8da0-e25bbbdf946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pred_df = cleaned_comp_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b728d1be-fb49-444f-86d1-45b10dcfe719",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_inputs = comp_pred_df[\"inputs\"].to_numpy()\n",
    "comp_labels = comp_pred_df[\"labels\"].to_numpy()\n",
    "comp_preds = comp_pred_df[\"preds\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "53155ce8-e73e-4e08-bed8-8b8fe017582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c098518b43264773a5b7587b42aba2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n"
     ]
    }
   ],
   "source": [
    "# getting unit score\n",
    "\n",
    "# input_casing = []\n",
    "# gold_casing = []\n",
    "# pred_casing = []\n",
    "\n",
    "# gold_docstrs = []\n",
    "# pred_docstrs = []\n",
    "# gold_docstr_counts = []\n",
    "# pred_docstr_counts = []\n",
    "# gold_docstr_texts = []\n",
    "# pred_docstr_texts = []\n",
    "# gold_has_docstr_list = []\n",
    "# pred_has_docstr_list = []\n",
    "\n",
    "comp_code_scores = []\n",
    "comp_diff_bleu_scores = []\n",
    "# docstr_text_scores = []\n",
    "\n",
    "for idx in tqdm(range(comp_preds.shape[0])):\n",
    "    gold = comp_labels[idx]\n",
    "    pred = comp_preds[idx]\n",
    "    \n",
    "    refs = [\n",
    "        [gold]\n",
    "    ]\n",
    "    hyp = [pred]\n",
    "    \n",
    "    input_code = casing_inputs[idx]\n",
    "    \n",
    "    gold_diff_str = get_diff_str(input_code, gold)\n",
    "    pred_diff_str = get_diff_str(input_code, pred)\n",
    "    \n",
    "    comp_diff_bleu_score = 0\n",
    "    if len(pred_diff_str) > 0:\n",
    "        comp_diff_bleu_score = sentence_bleu([gold_diff_str.split()], pred_diff_str.split(), auto_reweigh=True)\n",
    "    # gold_docstr = get_docstring(gold)\n",
    "    # pred_docstr = get_docstring(pred)\n",
    "    # gold_docstr_text = \"\\n\".join(gold_docstr)\n",
    "    # pred_docstr_text = \"\\n\".join(pred_docstr)\n",
    "    # gold_docstr_count = len(gold_docstr)\n",
    "    # pred_docstr_count = len(pred_docstr)\n",
    "    # gold_has_docstr = len(gold_docstr) > 0\n",
    "    # pred_has_docstr = len(pred_docstr) > 0\n",
    "    \n",
    "    \n",
    "    comp_code_score = get_codebleu(refs, hyp, \"python\", '0.25,0.25,0.25,0.25')\n",
    "    # docstr_text_score = get_codebleu([[gold_docstr_text]], [pred_docstr_text], \"python\", '1,0,0,0')\n",
    "    \n",
    "    comp_code_scores += [comp_code_score]\n",
    "    comp_diff_bleu_scores += [comp_diff_bleu_score]\n",
    "    # docstr_text_scores += [docstr_text_score]\n",
    "       \n",
    "    # gold_docstrs += [gold_docstr]\n",
    "    # pred_docstrs += [pred_docstr]\n",
    "    # gold_docstr_texts += [gold_docstr_text]\n",
    "    # pred_docstr_texts += [pred_docstr_text]\n",
    "    # gold_docstr_counts += [gold_docstr_count]\n",
    "    # pred_docstr_counts += [pred_docstr_count]\n",
    "    # gold_has_docstr_list += [gold_has_docstr]\n",
    "    # pred_has_docstr_list += [pred_has_docstr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e3172c7c-6af2-4905-96b5-203b4a380eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('List Comp BLEU score on only comparing difference in prediction:',\n",
       " 0.9597028263460841)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"List Comp BLEU score on only comparing difference in prediction:\", np.mean(comp_diff_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62613567-62ca-410e-95ad-d73e74e5e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstr_text_bleus = np.array([s[\"ngram\"] for s in docstr_text_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0688269d-429f-434f-a9b7-9d0c49191be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_code_bleus = np.array([s[\"code_bleu\"] for s in comp_code_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b09916d5-f5bb-49f6-9080-e6a4b772fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstr_text_bleus.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d47c01e-bffd-4b93-9a42-51280b2591f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_total = comp_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "36635d16-f945-4f2a-a10b-ee9092d4c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Prediction Rate: 0.237567084078712\n",
      "Above 0.9 CodeBLEU Prediction Rate: 0.8014311270125224\n"
     ]
    }
   ],
   "source": [
    "print(\"Perfect Prediction Rate:\", sum(comp_code_bleus == 1) / comp_total)\n",
    "print(\"Above 0.9 CodeBLEU Prediction Rate:\", sum(comp_code_bleus > 0.9) / comp_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866a57ce-1fb9-45ad-9b55-787395747321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = 760\n",
    "# print_split_line(f\"{idx}-prediction\")\n",
    "# print(docstr_preds[idx])\n",
    "# print_split_line(f\"{idx}-gold labels\")\n",
    "# print(docstr_labels[idx])\n",
    "# print_split_line(f\"{idx}-score\")\n",
    "# print(docstr_text_bleus[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37b21777-fc2e-4442-8768-9713e85277df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_code_bleus.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc4005-f71e-4cf0-8372-3a310d150a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97b62447-bfbb-43dd-8522-974946cf5ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================90-INPUT=====================\n",
      "\n",
      "def add_stacking_base_pairs(graph_list=None):\n",
      "    for g in graph_list:\n",
      "        for (n, d) in g.nodes_iter(data=True):\n",
      "            if d.get('position', False) == 0 or d.get('position', False) is not False:\n",
      "                pos = d['position']\n",
      "                neighbors = g.neighbors(n)\n",
      "                if len(neighbors) >= 2:\n",
      "                    greater_position_neighbors = []\n",
      "                    for v in neighbors:\n",
      "                        greater_position_neighbors.append(v)\n",
      "                    if len(greater_position_neighbors) >= 2:\n",
      "                        greater_position_neighbor_connected_by_backbone_list = []\n",
      "                        for v in greater_position_neighbors:\n",
      "                            greater_position_neighbor_connected_by_backbone_list.append(v)\n",
      "                        if len(greater_position_neighbor_connected_by_backbone_list) > 0:\n",
      "                            greater_position_neighbor_connected_by_backbone = greater_position_neighbor_connected_by_backbone_list[0]\n",
      "                            greater_position_neighbor_connected_by_basepair_list = []\n",
      "                            for v in greater_position_neighbors:\n",
      "                                greater_position_neighbor_connected_by_basepair_list.append(v)\n",
      "                            if len(greater_position_neighbor_connected_by_basepair_list) > 0:\n",
      "                                greater_position_neighbor_connected_by_basepair = greater_position_neighbor_connected_by_basepair_list[0]\n",
      "                                greater_position_neighbor_connected_by_backbone_neighbors = g.neighbors(greater_position_neighbor_connected_by_backbone)\n",
      "                                if len(greater_position_neighbor_connected_by_backbone_neighbors) > 0:\n",
      "                                    greater_position_neighbor_connected_by_backbone_greater_position_neighbor_connected_by_basepair_list = []\n",
      "                                    for v in greater_position_neighbor_connected_by_backbone_neighbors:\n",
      "                                        greater_position_neighbor_connected_by_backbone_greater_position_neighbor_connected_by_basepair_list.append(v)\n",
      "                                    if len(greater\n",
      "\n",
      "=====================90-PREDICTION=====================\n",
      "\n",
      "def add_stacking_base_pairs(graph_list=None):\n",
      "    for g in graph_list:\n",
      "        for (n, d) in g.nodes_iter(data=True):\n",
      "            if d.get('position', False) == 0 or d.get('position', False) is not False:\n",
      "                pos = d['position']\n",
      "                neighbors = g.neighbors(n)\n",
      "                if len(neighbors) >= 2:\n",
      "                    greater_position_neighbors = [v for v in neighbors if v.connected_by_backbone_list[v.connected_by_backbone_list[v.connected_by_backbone_list[v.connected_by_backbone_list[v.connected_by_backbone_list[0] == greater_position_neighbor_connected_by_basepair_list[0] == greater_position_neighbor_connected_by_basepair_list[0]\n",
      "                            greater_position_neighbor_connected_by_backbone_neighbors = g.neighbors(greater_position_neighbor_connected_by_backbone)\n",
      "                                if len(greater_position_neighbor_connected_by_backbone_neighbors) > 0:\n",
      "                                    greater_position_neighbor_connected_by_backbone_greater_position_neighbor_connected_by_basepair_list = [v for v in greater_position_neighbor_connected_by_backbone_neighbors if v.connected_by_basepair_neighbors[v.connected_by_basepair_neighbors[v.connected_by_backbone_neighbors[v.connected_by_basepair_list[0] == greater_position_neighbor_connected_by_backbone_neighbors[0] == greater_position_neighbor_connected_by_backbone_neighbors[0]\n",
      "                                    if len(greater_position_neighbor_connected_by_backbone_neighbors) > 0:\n",
      "\n",
      "\n",
      "=====================90-GOLD LABELS=====================\n",
      "\n",
      "def add_stacking_base_pairs(graph_list=None):\n",
      "    for g in graph_list:\n",
      "        for (n, d) in g.nodes_iter(data=True):\n",
      "            if d.get('position', False) == 0 or d.get('position', False) is not False:\n",
      "                pos = d['position']\n",
      "                neighbors = g.neighbors(n)\n",
      "                if len(neighbors) >= 2:\n",
      "                    greater_position_neighbors = [v for v in neighbors if g.node[v].get('position', False) and g.node[v]['position'] > pos]\n",
      "                    if len(greater_position_neighbors) >= 2:\n",
      "                        greater_position_neighbor_connected_by_backbone_list = [v for v in greater_position_neighbors if g.edge[n][v]['type'] == 'backbone']\n",
      "                        if len(greater_position_neighbor_connected_by_backbone_list) > 0:\n",
      "                            greater_position_neighbor_connected_by_backbone = greater_position_neighbor_connected_by_backbone_list[0]\n",
      "                            greater_position_neighbor_connected_by_basepair_list = [v for v in greater_position_neighbors if g.edge[n][v]['type'] == 'basepair']\n",
      "                            if len(greater_position_neighbor_connected_by_basepair_list) > 0:\n",
      "                                greater_position_neighbor_connected_by_basepair = greater_position_neighbor_connected_by_basepair_list[0]\n",
      "                                greater_position_neighbor_connected_by_backbone_neighbors = g.neighbors(greater_position_neighbor_connected_by_backbone)\n",
      "                                if len(greater_position_neighbor_connected_by_backbone_neighbors) > 0:\n",
      "                                    greater_position_neighbor_connected_by_backbone_greater_position_neighbor_connected_by_basepair_list = [v for v in greater_position_neighbor_connected_by_backbone_neighbors if g.edge[greater_position_neighbor_connected_by_backbone][v]['type'] == 'basepair']\n",
      "                                    if len(greater_position_neighbor_connected_by_backbone_greater\n",
      "\n",
      "=====================90-SCORE=====================\n",
      "\n",
      "0.5379108436207697\n",
      "\n",
      "=====================441-INPUT=====================\n",
      "\n",
      "import sys\n",
      "import subprocess\n",
      "import psutil\n",
      "\n",
      "def run_process(args):\n",
      "    proc_before = subprocess.check_output('ps aux | grep -v root', shell=True).decode().splitlines()\n",
      "    ret = subprocess.Popen(args)\n",
      "    ret.wait()\n",
      "    proc_after = subprocess.check_output('ps aux | grep -v root', shell=True).decode().splitlines()\n",
      "    pid_before = []\n",
      "    for x in proc_before:\n",
      "        pid_before.append(int(x.split()[1]))\n",
      "    pid_after = []\n",
      "    for x in proc_after:\n",
      "        pid_after.append(int(x.split()[1]))\n",
      "    possible_zombies = []\n",
      "    for (pid, name) in zip(pid_after, proc_after):\n",
      "        possible_zombies.append(name)\n",
      "    if possible_zombies:\n",
      "        sys.exit('\\nNew possible zoombie processes\\n{zombies}')\n",
      "    else:\n",
      "        print('\\nNo possible zombie process is detected')\n",
      "        sys.exit(ret.returncode)\n",
      "if __name__ == '__main__':\n",
      "    if '-h' in sys.argv:\n",
      "        print('Usage: python check_zombie.py regular command line')\n",
      "        print('This command executes the command and lists new processes after the completion of ')\n",
      "        print('the command. Processes that are child processes of processes before execution are ')\n",
      "        print('excluded. The rest of the processes could be zombie process left by the command, or ')\n",
      "        print('new processes created during the execution of the command.')\n",
      "    run_process(sys.argv[1:])\n",
      "\n",
      "=====================441-PREDICTION=====================\n",
      "\n",
      "import sys\n",
      "import subprocess\n",
      "import psutil\n",
      "\n",
      "def run_process(args):\n",
      "    proc_before = subprocess.check_output('ps aux | grep -v root', shell=True).decode().splitlines()\n",
      "    ret = subprocess.Popen(args)\n",
      "    ret.wait()\n",
      "    proc_after = subprocess.check_output('ps aux | grep -v root', shell=True).decode().splitlines()\n",
      "    pid_before = [int(x.split()[1]) for x in proc_before]\n",
      "    pid_after = [int(x.split()[1]) for x in proc_after]\n",
      "    possible_zombies = [name for (pid, name) in zip(pid_after, proc_after)]\n",
      "    if possible_zombies:\n",
      "        sys.exit('\\nNew possible zoombie processes\\n{zombies}')\n",
      "    else:\n",
      "        print('\\nNo possible zombie process is detected')\n",
      "        sys.exit(ret.returncode)\n",
      "if __name__ == '__main__':\n",
      "    if '-h' in sys.argv:\n",
      "        print('Usage: python check_zombie.py regular command line')\n",
      "        print('This command executes the command and lists new processes after the completion of ')\n",
      "        print('the command. Processes that are child processes of processes before execution are ')\n",
      "        print('excluded. The rest of the processes could be zombie process left by the command, or ')\n",
      "        print('new processes created during the execution of the command.')\n",
      "    run_process(sys.argv[1:])\n",
      "\n",
      "=====================441-GOLD LABELS=====================\n",
      "\n",
      "import sys\n",
      "import subprocess\n",
      "import psutil\n",
      "\n",
      "def run_process(args):\n",
      "    proc_before = subprocess.check_output('ps aux | grep -v root', shell=True).decode().splitlines()\n",
      "    ret = subprocess.Popen(args)\n",
      "    ret.wait()\n",
      "    proc_after = subprocess.check_output('ps aux | grep -v root', shell=True).decode().splitlines()\n",
      "    pid_before = [int(x.split()[1]) for x in proc_before if not 'PID' in x and 'TIME' in x]\n",
      "    pid_after = [int(x.split()[1]) for x in proc_after if not 'PID' in x and 'TIME' in x]\n",
      "    possible_zombies = [name for (pid, name) in zip(pid_after, proc_after) if pid not in pid_before and psutil.Process(pid).ppid() not in pid_before]\n",
      "    if possible_zombies:\n",
      "        sys.exit('\\nNew possible zoombie processes\\n{zombies}')\n",
      "    else:\n",
      "        print('\\nNo possible zombie process is detected')\n",
      "        sys.exit(ret.returncode)\n",
      "if __name__ == '__main__':\n",
      "    if '-h' in sys.argv:\n",
      "        print('Usage: python check_zombie.py regular command line')\n",
      "        print('This command executes the command and lists new processes after the completion of ')\n",
      "        print('the command. Processes that are child processes of processes before execution are ')\n",
      "        print('excluded. The rest of the processes could be zombie process left by the command, or ')\n",
      "        print('new processes created during the execution of the command.')\n",
      "    run_process(sys.argv[1:])\n",
      "\n",
      "=====================441-SCORE=====================\n",
      "\n",
      "0.6842965346186574\n",
      "\n",
      "=====================593-INPUT=====================\n",
      "\n",
      "import os\n",
      "__all__ = []\n",
      "for filename in os.listdir(os.path.dirname(__file__)):\n",
      "    __all__.append(filename[:-3])\n",
      "\n",
      "=====================593-PREDICTION=====================\n",
      "\n",
      "import os\n",
      "__all__ = [filename[:-3] for filename in os.listdir(os.path.dirname(__file__)) if filename.endswith('.py')]\n",
      "\n",
      "=====================593-GOLD LABELS=====================\n",
      "\n",
      "import os\n",
      "__all__ = [filename[:-3] for filename in os.listdir(os.path.dirname(__file__)) if filename.endswith('.py') and filename!= '__init__.py' and (filename not in [])]\n",
      "\n",
      "=====================593-SCORE=====================\n",
      "\n",
      "0.5739044783710286\n",
      "\n",
      "=====================952-INPUT=====================\n",
      "\n",
      "import os\n",
      "import bpy\n",
      "import logging\n",
      "baseLogger = logging.getLogger()\n",
      "baseLogger.setLevel(logging.DEBUG)\n",
      "from mathutils import *\n",
      "from math import *\n",
      "from.utilslib import *\n",
      "DEFORMABLE_ELEMENTS = {'beam3', 'beam2','shell4','membrane4'}\n",
      "import pdb\n",
      "\n",
      "def update_cd_index(self, context):\n",
      "    mbs = context.scene.mbdyn\n",
      "    comps = mbs.components\n",
      "    if len(comps):\n",
      "        if mbs.cd_index!= len(comps) - 1 and mbs.adding_component:\n",
      "            mbs.cd_index = len(comps) - 1\n",
      "        elif mbs.cd_index >= len(comps):\n",
      "            mbs.cd_index = len(comps) - 1\n",
      "\n",
      "def get_comp_mesh_objects(self, context):\n",
      "    mbs = context.scene.mbdyn\n",
      "    nd = mbs.nodes\n",
      "    ed = mbs.elems\n",
      "    comps = mbs.components\n",
      "    mesh_objs = []\n",
      "    for obj in bpy.data.objects:\n",
      "        mesh_objs.append(obj)\n",
      "    mo = []\n",
      "    for mesh_obj in mesh_objs:\n",
      "        mo.append((mesh_obj.name, mesh_obj.name, ''))\n",
      "    mo.append(('', '', ''))\n",
      "    return mo\n",
      "\n",
      "def update_elem_str_idx(self, context):\n",
      "    comp = eval('context.scene.mbdyn.' + self.path_from_id().split('.')[1])\n",
      "    if self.str_idx == len(comp.elements):\n",
      "        self.str_idx = 0\n",
      "    else:\n",
      "        for elem in comp.elements:\n",
      "            if elem!= self and elem.str_idx == self.str_idx:\n",
      "                elem.str_idx += 1\n",
      "                break\n",
      "\n",
      "def add_mesh_component(context, component):\n",
      "    \"\"\" Finalized a component definition by creating the armature \n",
      "        controlling the component deformation, based on the component\n",
      "        elements definitions, and (optionally) assigning it to the \n",
      "        selected mesh object \"\"\"\n",
      "    mbs = context.scene.mbdyn\n",
      "    nd = mbs.nodes\n",
      "    ed = m\n",
      "\n",
      "=====================952-PREDICTION=====================\n",
      "\n",
      "import os\n",
      "import bpy\n",
      "import logging\n",
      "baseLogger = logging.getLogger()\n",
      "baseLogger.setLevel(logging.DEBUG)\n",
      "from mathutils import *\n",
      "from math import *\n",
      "from.utilslib import *\n",
      "DEFORMABLE_ELEMENTS = {'beam3', 'beam2','shell4','membrane4'}\n",
      "import pdb\n",
      "\n",
      "def update_cd_index(self, context):\n",
      "    mbs = context.scene.mbdyn\n",
      "    comps = mbs.components\n",
      "    if len(comps):\n",
      "        if mbs.cd_index!= len(comps) - 1 and mbs.adding_component:\n",
      "            mbs.cd_index = len(comps) - 1\n",
      "        elif mbs.cd_index >= len(comps):\n",
      "            mbs.cd_index = len(comps) - 1\n",
      "\n",
      "def get_comp_mesh_objects(self, context):\n",
      "    mbs = context.scene.mbdyn\n",
      "    nd = mbs.nodes\n",
      "    ed = mbs.elems\n",
      "    comps = mbs.components\n",
      "    mesh_objs = [obj for obj in bpy.data.objects if obj.scene.mbdyn.' in obj.scene.mesh.scene.mesh.scene.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh.mesh\n",
      "\n",
      "=====================952-GOLD LABELS=====================\n",
      "\n",
      "import os\n",
      "import bpy\n",
      "import logging\n",
      "baseLogger = logging.getLogger()\n",
      "baseLogger.setLevel(logging.DEBUG)\n",
      "from mathutils import *\n",
      "from math import *\n",
      "from.utilslib import *\n",
      "DEFORMABLE_ELEMENTS = {'beam3', 'beam2','shell4','membrane4'}\n",
      "import pdb\n",
      "\n",
      "def update_cd_index(self, context):\n",
      "    mbs = context.scene.mbdyn\n",
      "    comps = mbs.components\n",
      "    if len(comps):\n",
      "        if mbs.cd_index!= len(comps) - 1 and mbs.adding_component:\n",
      "            mbs.cd_index = len(comps) - 1\n",
      "        elif mbs.cd_index >= len(comps):\n",
      "            mbs.cd_index = len(comps) - 1\n",
      "\n",
      "def get_comp_mesh_objects(self, context):\n",
      "    mbs = context.scene.mbdyn\n",
      "    nd = mbs.nodes\n",
      "    ed = mbs.elems\n",
      "    comps = mbs.components\n",
      "    mesh_objs = [obj for obj in bpy.data.objects if obj.type == 'MESH' and obj.mbdyn.dkey not in nd.keys() and (obj.mbdyn.dkey not in ed.keys())]\n",
      "    mo = [(mesh_obj.name, mesh_obj.name, '') for mesh_obj in mesh_objs]\n",
      "    mo.append(('', '', ''))\n",
      "    return mo\n",
      "\n",
      "def update_elem_str_idx(self, context):\n",
      "    comp = eval('context.scene.mbdyn.' + self.path_from_id().split('.')[1])\n",
      "    if self.str_idx == len(comp.elements):\n",
      "        self.str_idx = 0\n",
      "    else:\n",
      "        for elem in comp.elements:\n",
      "            if elem!= self and elem.str_idx == self.str_idx:\n",
      "                elem.str_idx += 1\n",
      "                break\n",
      "\n",
      "def add_mesh_component(context, component):\n",
      "    \"\"\" Finalized a component definition by creating the armature \n",
      "        controlling the component deformation, based on the component\n",
      "        elements definitions, and (optionally) assigning it to the \n",
      "        selected mesh object \"\"\"\n",
      "    mbs =\n",
      "\n",
      "=====================952-SCORE=====================\n",
      "\n",
      "0.5207914479944946\n",
      "\n",
      "=====================1109-INPUT=====================\n",
      "\n",
      "squares = []\n",
      "for i in range(5):\n",
      "    squares.append(i ** 2)\n",
      "print(squares)\n",
      "squares = []\n",
      "for i in range(5):\n",
      "    squares.append(i ** 2)\n",
      "print(squares)\n",
      "odds = []\n",
      "for i in range(10):\n",
      "    odds.append(i)\n",
      "print(odds)\n",
      "odds = []\n",
      "for i in range(10):\n",
      "    if i % 2 == 1:\n",
      "        odds.append(i)\n",
      "print(odds)\n",
      "odd_even = []\n",
      "for i in range(10):\n",
      "    odd_even.append('odd' if i % 2 == 1 else 'even')\n",
      "print(odd_even)\n",
      "odd_even = []\n",
      "for i in range(10):\n",
      "    if i % 2 == 1:\n",
      "        odd_even.append('odd')\n",
      "    else:\n",
      "        odd_even.append('even')\n",
      "print(odd_even)\n",
      "odd10 = []\n",
      "for i in range(10):\n",
      "    odd10.append(i * 10 if i % 2 == 1 else i)\n",
      "print(odd10)\n",
      "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "flat = []\n",
      "for row in matrix:\n",
      "    flat.append(x)\n",
      "print(flat)\n",
      "flat = []\n",
      "for row in matrix:\n",
      "    for x in row:\n",
      "        flat.append(x)\n",
      "print(flat)\n",
      "cells = []\n",
      "for row in range(3):\n",
      "    cells.append((row, col))\n",
      "print(cells)\n",
      "cells = []\n",
      "for row in range(3):\n",
      "    cells.append((row, col))\n",
      "print(cells)\n",
      "cells = []\n",
      "for row in range(3):\n",
      "    cells.append((row, col))\n",
      "print(cells)\n",
      "l_str1 = ['a', 'b', 'c']\n",
      "l_str2 = ['x', 'y', 'z']\n",
      "l_zip = []\n",
      "for (s1, s2) in zip(l_str1, l_str2):\n",
      "    l_zip.append((s1, s2))\n",
      "print(l_zip)\n",
      "l_zip = []\n",
      "for (s1, s2) in zip(\n",
      "\n",
      "=====================1109-PREDICTION=====================\n",
      "\n",
      "squares = [i ** 2 for i in range(5)]\n",
      "print(squares)\n",
      "squares = [i ** 2 for i in range(5)]\n",
      "print(squares)\n",
      "odds = [i for i in range(10)]\n",
      "print(odds)\n",
      "odds = ['odd' if i % 2 == 1 else 'even' for i in range(10)]\n",
      "print(odd_even)\n",
      "odd_even = [(row, col) for i in range(10)]\n",
      "print(odd_even)\n",
      "odd10 = [i * 10 if i % 2 == 1 else i for i in range(10)]\n",
      "print(odd10)\n",
      "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "flat = [x for row in matrix if not row in [7, 8, 9]]\n",
      "print(flat)\n",
      "flat = [(row, col) for row in matrix]\n",
      "print(flat)\n",
      "cells = [(row, col) for row in range(3)]\n",
      "print(cells)\n",
      "cells = [(row, col) for row in range(3)]\n",
      "print(cells)\n",
      "cells = [(row, col) for row in range(3)]\n",
      "print(cells)\n",
      "cells = [(row, col) for row in range(3)]\n",
      "print(cells)\n",
      "cells = [(row, col) for row in range(3)]\n",
      "print(cells)\n",
      "l_str1 = ['a', 'b', 'c']\n",
      "l_str2 = ['x', 'y', 'z']\n",
      "l_zip = [(s1, s2) for (s1, s2) in zip(l_str1, l_str2)]\n",
      "print(l_zip)\n",
      "l_zip = [(s1, s2) for (s1, s2) in zip(l_str1, l_str2)]\n",
      "print(l_zip)\n",
      "l_zip = [(s1, s2) for (s1, s2) in zip(l_str1, l_str2) for (s1, s2) in zip(l_str1, l_str2) for (s1, s2) in zip(l_str1, l_str2) if s2 ==\n",
      "\n",
      "=====================1109-GOLD LABELS=====================\n",
      "\n",
      "squares = [i ** 2 for i in range(5)]\n",
      "print(squares)\n",
      "squares = []\n",
      "for i in range(5):\n",
      "    squares.append(i ** 2)\n",
      "print(squares)\n",
      "odds = [i for i in range(10) if i % 2 == 1]\n",
      "print(odds)\n",
      "odds = []\n",
      "for i in range(10):\n",
      "    if i % 2 == 1:\n",
      "        odds.append(i)\n",
      "print(odds)\n",
      "odd_even = ['odd' if i % 2 == 1 else 'even' for i in range(10)]\n",
      "print(odd_even)\n",
      "odd_even = []\n",
      "for i in range(10):\n",
      "    if i % 2 == 1:\n",
      "        odd_even.append('odd')\n",
      "    else:\n",
      "        odd_even.append('even')\n",
      "print(odd_even)\n",
      "odd10 = [i * 10 if i % 2 == 1 else i for i in range(10)]\n",
      "print(odd10)\n",
      "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "flat = [x for row in matrix for x in row]\n",
      "print(flat)\n",
      "flat = []\n",
      "for row in matrix:\n",
      "    for x in row:\n",
      "        flat.append(x)\n",
      "print(flat)\n",
      "cells = [(row, col) for row in range(3) for col in range(2)]\n",
      "print(cells)\n",
      "cells = [(row, col) for row in range(3) for col in range(2) if col == row]\n",
      "print(cells)\n",
      "cells = [(row, col) for row in range(3) if row % 2 == 0 for col in range(2) if col % 2 == 0]\n",
      "print(cells)\n",
      "l_str1 = ['a', 'b', 'c']\n",
      "l_str2 = ['x', 'y', 'z']\n",
      "l_zip = [(s1, s2) for (s1, s2) in zip(l_str1, l_str2)]\n",
      "print(l_zip)\n",
      "l_zip = []\n",
      "for (s1, s2) in zip(l_str1, l_str2):\n",
      "    l_zip.append((s\n",
      "\n",
      "=====================1109-SCORE=====================\n",
      "\n",
      "0.5615918079392626\n",
      "\n",
      "=====================1848-INPUT=====================\n",
      "\n",
      "import unittest\n",
      "from sets import Set\n",
      "from common import DtraceTestCase\n",
      "from analyzer.darwin.lib.dtrace.dtruss import *\n",
      "\n",
      "class TestDtruss(DtraceTestCase):\n",
      "\n",
      "    def test_dtruss_helloworld(self):\n",
      "        expected_syscall = 'write_nocancel'\n",
      "        expected_args = [1, 'Hello, world!\\n', 14]\n",
      "        expected_result = 14\n",
      "        expected_errno = 0\n",
      "        output = []\n",
      "        for call in dtruss(self.current_target()):\n",
      "            output.append(call)\n",
      "        matched = []\n",
      "        for x in output:\n",
      "            matched.append(x)\n",
      "        self.assertEqual(len(matched), 1)\n",
      "\n",
      "    def test_dtruss_without_target(self):\n",
      "        with self.assertRaisesRegexp(Exception, 'Invalid target for dtruss()'):\n",
      "            for call in dtruss(None):\n",
      "                pass\n",
      "\n",
      "    def test_dtruss_specific_syscall(self):\n",
      "        expected_syscall = 'write_nocancel'\n",
      "        expected_args = [1, 'Hello, dtruss!\\n', 15]\n",
      "        expected_result = 15\n",
      "        expected_errno = 0\n",
      "        output = []\n",
      "        for call in dtruss(self.current_target(), syscall='write_nocancel', run_as_root=False):\n",
      "            output.append(call)\n",
      "        matched = []\n",
      "        for x in output:\n",
      "            matched.append(x)\n",
      "        self.assertEqual(len(matched), 1)\n",
      "\n",
      "    def test_dtruss_timeout(self):\n",
      "        expected_syscall = 'write'\n",
      "        expected_args = [1, 'Hello, world!\\n', 14]\n",
      "        expected_result = 14\n",
      "        expected_errno = 0\n",
      "        output = []\n",
      "        for call in dtruss(self.current_target(), timeout=2, run_as_root=True):\n",
      "            output.append(call)\n",
      "        matched = []\n",
      "        for x in output:\n",
      "            matched.append(x)\n",
      "        self.assertEqual(len(matched), 1)\n",
      "        self.assertEqual(sum((x.name == 'write' for x in\n",
      "\n",
      "=====================1848-PREDICTION=====================\n",
      "\n",
      "import unittest\n",
      "from sets import Set\n",
      "from common import DtraceTestCase\n",
      "from analyzer.darwin.lib.dtrace.dtruss import *\n",
      "\n",
      "class TestDtruss(DtraceTestCase):\n",
      "\n",
      "    def test_dtruss_helloworld(self):\n",
      "        expected_syscall = 'write_nocancel'\n",
      "        expected_args = [1, 'Hello, world!\\n', 14]\n",
      "        expected_result = 14\n",
      "        expected_errno = 0\n",
      "        output = [call for call in dtruss(self.current_target())]\n",
      "        matched = [x for x in output if not x.startswith('==')]\n",
      "        self.assertEqual(len(matched), 1)\n",
      "\n",
      "    def test_dtruss_without_target(self):\n",
      "        with self.assertRaisesRegexp(Exception, 'Invalid target for dtruss()'):\n",
      "            for call in dtruss(None):\n",
      "                pass\n",
      "\n",
      "    def test_dtruss_specific_syscall(self):\n",
      "        expected_syscall = 'write_nocancel'\n",
      "        expected_args = [1, 'Hello, dtruss!\\n', 15]\n",
      "        expected_result = 15\n",
      "        expected_errno = 0\n",
      "        output = [call for call in dtruss(self.current_target(), syscall='write_nocancel', run_as_root=False)]\n",
      "        matched = [x for x in output if x.startswith('==')]\n",
      "        self.assertEqual(len(matched), 1)\n",
      "\n",
      "    def test_dtruss_timeout(self):\n",
      "        expected_syscall = 'write'\n",
      "        expected_args = [1, 'Hello, world!\\n', 14]\n",
      "        expected_result = 14\n",
      "        expected_errno = 0\n",
      "        output = [call for call in dtruss(self.current_target(), timeout=2, run_as_root=True)]\n",
      "        matched = [x for x in output if x.startswith('==')]\n",
      "        self.assertEqual(len(matched), 1)\n",
      "        self.assertEqual(sum((x.name == 'write' for x in expected))\n",
      "        expected_result = 15\n",
      "        expected_errno = 0\n",
      "        output = [call for call in dtruss(\n",
      "\n",
      "=====================1848-GOLD LABELS=====================\n",
      "\n",
      "import unittest\n",
      "from sets import Set\n",
      "from common import DtraceTestCase\n",
      "from analyzer.darwin.lib.dtrace.dtruss import *\n",
      "\n",
      "class TestDtruss(DtraceTestCase):\n",
      "\n",
      "    def test_dtruss_helloworld(self):\n",
      "        expected_syscall = 'write_nocancel'\n",
      "        expected_args = [1, 'Hello, world!\\n', 14]\n",
      "        expected_result = 14\n",
      "        expected_errno = 0\n",
      "        output = []\n",
      "        for call in dtruss(self.current_target()):\n",
      "            output.append(call)\n",
      "        matched = [x for x in output if x.name == expected_syscall and x.args == expected_args and (x.result == expected_result) and (x.errno == expected_errno)]\n",
      "        self.assertEqual(len(matched), 1)\n",
      "\n",
      "    def test_dtruss_without_target(self):\n",
      "        with self.assertRaisesRegexp(Exception, 'Invalid target for dtruss()'):\n",
      "            for call in dtruss(None):\n",
      "                pass\n",
      "\n",
      "    def test_dtruss_specific_syscall(self):\n",
      "        expected_syscall = 'write_nocancel'\n",
      "        expected_args = [1, 'Hello, dtruss!\\n', 15]\n",
      "        expected_result = 15\n",
      "        expected_errno = 0\n",
      "        output = []\n",
      "        for call in dtruss(self.current_target(), syscall='write_nocancel', run_as_root=False):\n",
      "            output.append(call)\n",
      "        matched = [x for x in output if x.name == expected_syscall and x.args == expected_args and (x.result == expected_result) and (x.errno == expected_errno)]\n",
      "        self.assertEqual(len(matched), 1)\n",
      "\n",
      "    def test_dtruss_timeout(self):\n",
      "        expected_syscall = 'write'\n",
      "        expected_args = [1, 'Hello, world!\\n', 14]\n",
      "        expected_result = 14\n",
      "        expected_errno = 0\n",
      "        output = []\n",
      "        for call in dtruss(self.current_target(), timeout=2, run_as_root=True):\n",
      "            output.append(\n",
      "\n",
      "=====================1848-SCORE=====================\n",
      "\n",
      "0.6794594052732713\n",
      "\n",
      "=====================2058-INPUT=====================\n",
      "\n",
      "import importlib\n",
      "import pathlib\n",
      "__all__ = []\n",
      "for f in pathlib.Path(__file__).parent.glob('*.py'):\n",
      "    __all__.append(f.stem)\n",
      "for _ in __all__:\n",
      "    importlib.import_module('.' + _, 'cooltools.api')\n",
      "del pathlib\n",
      "del importlib\n",
      "\n",
      "=====================2058-PREDICTION=====================\n",
      "\n",
      "import importlib\n",
      "import pathlib\n",
      "__all__ = [f.stem for f in pathlib.Path(__file__).parent.glob('*.py')]\n",
      "for _ in __all__:\n",
      "    importlib.import_module('.' + _, 'cooltools.api')\n",
      "del pathlib\n",
      "del importlib\n",
      "\n",
      "=====================2058-GOLD LABELS=====================\n",
      "\n",
      "import importlib\n",
      "import pathlib\n",
      "__all__ = [f.stem for f in pathlib.Path(__file__).parent.glob('*.py') if f.is_file() and (not f.name == '__init__.py')]\n",
      "for _ in __all__:\n",
      "    importlib.import_module('.' + _, 'cooltools.api')\n",
      "del pathlib\n",
      "del importlib\n",
      "\n",
      "=====================2058-SCORE=====================\n",
      "\n",
      "0.6551026055958985\n",
      "\n",
      "=====================2317-INPUT=====================\n",
      "\n",
      "\"\"\"Classifier keyword analyzer.\n",
      "\n",
      "This module contains methods to extract keywords from texts. It provides 3\n",
      "different methods for 3 different types of keywords: single keywords, composite\n",
      "keywords and author keywords.\n",
      "\"\"\"\n",
      "from __future__ import print_function\n",
      "import re\n",
      "import time\n",
      "from flask import current_app\n",
      "from.errors import OntologyError\n",
      "\n",
      "def get_single_keywords(skw_db, fulltext):\n",
      "    \"\"\"Find single keywords in the fulltext.\n",
      "\n",
      "    :param skw_db: list of KeywordToken objects\n",
      "    :param fulltext: string, which will be searched\n",
      "\n",
      "    :return : dictionary of matches in a format {\n",
      "        <keyword object>, [[position, position...], ],\n",
      "       ..\n",
      "    }\n",
      "    \"\"\"\n",
      "    timer_start = time.clock()\n",
      "    records = []\n",
      "    for single_keyword in skw_db.values():\n",
      "        for regex in single_keyword.regex:\n",
      "            for match in regex.finditer(fulltext):\n",
      "                span = (match.span()[0], match.span()[1] - 1)\n",
      "                records = []\n",
      "                for record in records:\n",
      "                    records.append(record)\n",
      "                add = True\n",
      "                for previous_record in records:\n",
      "                    if (span, single_keyword) == previous_record or _contains_span(previous_record[0], span):\n",
      "                        add = False\n",
      "                        break\n",
      "                if add:\n",
      "                    records.append((span, single_keyword))\n",
      "    single_keywords = {}\n",
      "    for (span, single_keyword) in records:\n",
      "        single_keywords.setdefault(single_keyword, [[]])\n",
      "        single_keywords[single_keyword][0].append(span)\n",
      "    current_app.logger.info('Matching single keywords... %d keywords found in %.1f sec.' % (len(single_keywords), time.clock() - timer_start))\n",
      "    return single_keywords\n",
      "\n",
      "def get_composite_keywords(ckw_db, fulltext, skw_spans):\n",
      "    \"\"\"Return a list of composite keywords bound with number of occurrences.\n",
      "\n",
      "    :param ckw_db: list of KewordToken objects\n",
      "                   (they are supposed to be composite ones)\n",
      "    :param fulltext: string to search in\n",
      "    :param skw_spans:\n",
      "\n",
      "=====================2317-PREDICTION=====================\n",
      "\n",
      "\"\"\"Classifier keyword analyzer.\n",
      "\n",
      "This module contains methods to extract keywords from texts. It provides 3\n",
      "different methods for 3 different types of keywords: single keywords, composite\n",
      "keywords and author keywords.\n",
      "\"\"\"\n",
      "from __future__ import print_function\n",
      "import re\n",
      "import time\n",
      "from flask import current_app\n",
      "from.errors import OntologyError\n",
      "\n",
      "def get_single_keywords(skw_db, fulltext):\n",
      "    \"\"\"Find single keywords in the fulltext.\n",
      "\n",
      "    :param skw_db: list of KeywordToken objects\n",
      "    :param fulltext: string, which will be searched\n",
      "\n",
      "    :return : dictionary of matches in a format {\n",
      "        <keyword object>, [[position, position...], ],\n",
      "       ..\n",
      "    }\n",
      "    \"\"\"\n",
      "    timer_start = time.clock()\n",
      "    records = []\n",
      "    for single_keyword in skw_db.values():\n",
      "        for regex in single_keyword.regex:\n",
      "            for match in regex.finditer(fulltext):\n",
      "                span = (match.span()[0], match.span()[1] - 1)\n",
      "                records = [record for record in records if record.match(record.match(record.match(record.match(record.match(record.match(record.match(record.match(record.match(record.match(record.match(record.keyword))]\n",
      "                add = True\n",
      "                for previous_record in records:\n",
      "                    if (span, single_keyword) == previous_record or _contains_span(previous_record[0], span):\n",
      "                        add = False\n",
      "                        break\n",
      "                if add:\n",
      "                    records.append((span, single_keyword))\n",
      "    single_keywords = {}\n",
      "    for (span, single_keyword) in records:\n",
      "        single_keywords.setdefault(single_keyword, [[]])\n",
      "        single_keywords[single_keyword][0].append(span)\n",
      "    current_app.logger.info('Matching single keywords... %d keywords found in %.1f sec.' % (len(single_keywords), time.clock() - timer_start))\n",
      "    return single_keywords\n",
      "\n",
      "def get_composite_keywords(ckw_db, fulltext, skw_spans):\n",
      "    \"\"\"Return a list of composite keywords bound with number of occurrences.\n",
      "\n",
      "    :param ckw_db\n",
      "\n",
      "=====================2317-GOLD LABELS=====================\n",
      "\n",
      "\"\"\"Classifier keyword analyzer.\n",
      "\n",
      "This module contains methods to extract keywords from texts. It provides 3\n",
      "different methods for 3 different types of keywords: single keywords, composite\n",
      "keywords and author keywords.\n",
      "\"\"\"\n",
      "from __future__ import print_function\n",
      "import re\n",
      "import time\n",
      "from flask import current_app\n",
      "from.errors import OntologyError\n",
      "\n",
      "def get_single_keywords(skw_db, fulltext):\n",
      "    \"\"\"Find single keywords in the fulltext.\n",
      "\n",
      "    :param skw_db: list of KeywordToken objects\n",
      "    :param fulltext: string, which will be searched\n",
      "\n",
      "    :return : dictionary of matches in a format {\n",
      "        <keyword object>, [[position, position...], ],\n",
      "       ..\n",
      "    }\n",
      "    \"\"\"\n",
      "    timer_start = time.clock()\n",
      "    records = []\n",
      "    for single_keyword in skw_db.values():\n",
      "        for regex in single_keyword.regex:\n",
      "            for match in regex.finditer(fulltext):\n",
      "                span = (match.span()[0], match.span()[1] - 1)\n",
      "                records = [record for record in records if not _contains_span(span, record[0])]\n",
      "                add = True\n",
      "                for previous_record in records:\n",
      "                    if (span, single_keyword) == previous_record or _contains_span(previous_record[0], span):\n",
      "                        add = False\n",
      "                        break\n",
      "                if add:\n",
      "                    records.append((span, single_keyword))\n",
      "    single_keywords = {}\n",
      "    for (span, single_keyword) in records:\n",
      "        single_keywords.setdefault(single_keyword, [[]])\n",
      "        single_keywords[single_keyword][0].append(span)\n",
      "    current_app.logger.info('Matching single keywords... %d keywords found in %.1f sec.' % (len(single_keywords), time.clock() - timer_start))\n",
      "    return single_keywords\n",
      "\n",
      "def get_composite_keywords(ckw_db, fulltext, skw_spans):\n",
      "    \"\"\"Return a list of composite keywords bound with number of occurrences.\n",
      "\n",
      "    :param ckw_db: list of KewordToken objects\n",
      "                   (they are supposed to be composite ones)\n",
      "    :param fulltext: string to search in\n",
      "    :param sk\n",
      "\n",
      "=====================2317-SCORE=====================\n",
      "\n",
      "0.6898163337452524\n",
      "\n",
      "=====================2327-INPUT=====================\n",
      "\n",
      "\"\"\"\n",
      "Outlier Detection using Tukeys Filter Class\n",
      "\"\"\"\n",
      "import sys\n",
      "import itertools\n",
      "from time import time\n",
      "from lib.modules.base_task import BaseTask\n",
      "from lib.modules.helper import extract_service_name, get_closest_datapoint\n",
      "from lib.modules.models import TimeSeriesTuple\n",
      "\n",
      "class TukeysFilter(BaseTask):\n",
      "\n",
      "    def __init__(self, config, logger, options):\n",
      "        super(TukeysFilter, self).__init__(config, logger, resource={'metric_sink': 'RedisSink', 'output_sink': 'GraphiteSink'})\n",
      "        self.namespace = 'TukeysFilter'\n",
      "        self.service = options['service']\n",
      "        self.params = options['params']\n",
      "\n",
      "    def read(self):\n",
      "        quantile_25 = self.params['quantile_25']\n",
      "        quantile_75 = self.params['quantile_75']\n",
      "        metrics = self.params['metrics']\n",
      "        delay = self.params.get('offset', 0)\n",
      "        maximum_delay = self.params.get('maximum_delay', 600)\n",
      "        quantile_25 = []\n",
      "        for i in self.metric_sink.iread(quantile_25):\n",
      "            quantile_25.append(i)\n",
      "        quantile_75 = []\n",
      "        for i in self.metric_sink.iread(quantile_75):\n",
      "            quantile_75.append(i)\n",
      "        metrics = []\n",
      "        for i in self.metric_sink.iread(metrics):\n",
      "            metrics.append(i)\n",
      "        if not len(quantile_25) * len(quantile_75) * len(metrics):\n",
      "            self.logger.error('No data found for quantile/to be checked metrics. Exiting')\n",
      "            return None\n",
      "        quantile_25 = sorted(quantile_25, key=lambda tup: tup.timestamp)\n",
      "        quantile_75 = sorted(quantile_75, key=lambda tup: tup.timestamp)\n",
      "        metrics = sorted(metrics, key=lambda tup: (tup.name, tup.timestamp))\n",
      "        time_now = time() - delay\n",
      "        quantile_25 = get_closest_datapoint(quantile_25, time_now)\n",
      "        if time_now - quantile_25.\n",
      "\n",
      "=====================2327-PREDICTION=====================\n",
      "\n",
      "\"\"\"\n",
      "Outlier Detection using Tukeys Filter Class\n",
      "\"\"\"\n",
      "import sys\n",
      "import itertools\n",
      "from time import time\n",
      "from lib.modules.base_task import BaseTask\n",
      "from lib.modules.helper import extract_service_name, get_closest_datapoint\n",
      "from lib.modules.models import TimeSeriesTuple\n",
      "\n",
      "class TukeysFilter(BaseTask):\n",
      "\n",
      "    def __init__(self, config, logger, options):\n",
      "        super(TukeysFilter, self).__init__(config, logger, resource={'metric_sink': 'RedisSink', 'output_sink': 'GraphiteSink'})\n",
      "        self.namespace = 'TukeysFilter'\n",
      "        self.service = options['service']\n",
      "        self.params = options['params']\n",
      "\n",
      "    def read(self):\n",
      "        quantile_25 = self.params['quantile_25']\n",
      "        quantile_75 = self.params['quantile_75']\n",
      "        metrics = self.params['metrics']\n",
      "        delay = self.params.get('offset', 0)\n",
      "        maximum_delay = self.params.get('maximum_delay', 600)\n",
      "        quantile_25 = [i for i in self.metric_sink.iread(quantile_25) if i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile_25) and i.metric_sink.iread(quantile\n",
      "\n",
      "=====================2327-GOLD LABELS=====================\n",
      "\n",
      "\"\"\"\n",
      "Outlier Detection using Tukeys Filter Class\n",
      "\"\"\"\n",
      "import sys\n",
      "import itertools\n",
      "from time import time\n",
      "from lib.modules.base_task import BaseTask\n",
      "from lib.modules.helper import extract_service_name, get_closest_datapoint\n",
      "from lib.modules.models import TimeSeriesTuple\n",
      "\n",
      "class TukeysFilter(BaseTask):\n",
      "\n",
      "    def __init__(self, config, logger, options):\n",
      "        super(TukeysFilter, self).__init__(config, logger, resource={'metric_sink': 'RedisSink', 'output_sink': 'GraphiteSink'})\n",
      "        self.namespace = 'TukeysFilter'\n",
      "        self.service = options['service']\n",
      "        self.params = options['params']\n",
      "\n",
      "    def read(self):\n",
      "        quantile_25 = self.params['quantile_25']\n",
      "        quantile_75 = self.params['quantile_75']\n",
      "        metrics = self.params['metrics']\n",
      "        delay = self.params.get('offset', 0)\n",
      "        maximum_delay = self.params.get('maximum_delay', 600)\n",
      "        quantile_25 = [i for i in self.metric_sink.iread(quantile_25)]\n",
      "        quantile_75 = [i for i in self.metric_sink.iread(quantile_75)]\n",
      "        metrics = [i for i in self.metric_sink.iread(metrics)]\n",
      "        if not len(quantile_25) * len(quantile_75) * len(metrics):\n",
      "            self.logger.error('No data found for quantile/to be checked metrics. Exiting')\n",
      "            return None\n",
      "        quantile_25 = sorted(quantile_25, key=lambda tup: tup.timestamp)\n",
      "        quantile_75 = sorted(quantile_75, key=lambda tup: tup.timestamp)\n",
      "        metrics = sorted(metrics, key=lambda tup: (tup.name, tup.timestamp))\n",
      "        time_now = time() - delay\n",
      "        quantile_25 = get_closest_datapoint(quantile_25, time_now)\n",
      "        if time_now - quantile_25.timestamp > maximum_delay:\n",
      "            self.logger.error('Quantile25 Value is too old (Timestamp: %d) of: %s\n",
      "\n",
      "=====================2327-SCORE=====================\n",
      "\n",
      "0.47797383953509565\n",
      "\n",
      "=====================2347-INPUT=====================\n",
      "\n",
      "\"\"\"Python spiel example.\"\"\"\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "import pickle\n",
      "from absl import app\n",
      "from absl.testing import absltest\n",
      "from absl.testing import parameterized\n",
      "import numpy as np\n",
      "from open_spiel.python import games\n",
      "from open_spiel.python.algorithms import get_all_states\n",
      "from open_spiel.python.mfg import games as mfg_games\n",
      "import pyspiel\n",
      "from open_spiel.python.utils import file_utils\n",
      "MAX_ACTIONS_PER_GAME = 1000\n",
      "SPIEL_GAMES_LIST = pyspiel.registered_games()\n",
      "SPIEL_LOADABLE_GAMES_LIST = []\n",
      "for g in SPIEL_GAMES_LIST:\n",
      "    SPIEL_LOADABLE_GAMES_LIST.append(g)\n",
      "assert len(SPIEL_LOADABLE_GAMES_LIST) >= 38, len(SPIEL_LOADABLE_GAMES_LIST)\n",
      "SPIEL_SIMULTANEOUS_GAMES_LIST = []\n",
      "for g in SPIEL_LOADABLE_GAMES_LIST:\n",
      "    SPIEL_SIMULTANEOUS_GAMES_LIST.append(g)\n",
      "assert len(SPIEL_SIMULTANEOUS_GAMES_LIST) >= 14, len(SPIEL_SIMULTANEOUS_GAMES_LIST)\n",
      "SPIEL_MULTIPLAYER_GAMES_LIST = []\n",
      "for g in SPIEL_LOADABLE_GAMES_LIST:\n",
      "    SPIEL_MULTIPLAYER_GAMES_LIST.append((g, p))\n",
      "assert len(SPIEL_MULTIPLAYER_GAMES_LIST) >= 35, len(SPIEL_MULTIPLAYER_GAMES_LIST)\n",
      "\n",
      "class GamesSimTest(parameterized.TestCase):\n",
      "\n",
      "    def apply_action(self, state, action):\n",
      "        if state.is_simultaneous_node():\n",
      "            assert isinstance(action, list)\n",
      "            state.apply_actions(action)\n",
      "        else:\n",
      "            state.apply_action(action)\n",
      "\n",
      "    def apply_action_test_clone(self, state, action):\n",
      "        \"\"\"Applies\n",
      "\n",
      "=====================2347-PREDICTION=====================\n",
      "\n",
      "\"\"\"Python spiel example.\"\"\"\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "import pickle\n",
      "from absl import app\n",
      "from absl.testing import absltest\n",
      "from absl.testing import parameterized\n",
      "import numpy as np\n",
      "from open_spiel.python import games\n",
      "from open_spiel.python.algorithms import get_all_states\n",
      "from open_spiel.python.mfg import games as mfg_games\n",
      "import pyspiel\n",
      "from open_spiel.python.utils import file_utils\n",
      "MAX_ACTIONS_PER_GAME = 1000\n",
      "SPIEL_GAMES_LIST = pyspiel.registered_games()\n",
      "SPIEL_LOADABLE_GAMES_LIST = [g for g in SPIEL_GAMES_LIST if g.startswith('SPIEL_')]\n",
      "assert len(SPIEL_LOADABLE_GAMES_LIST) >= 38, len(SPIEL_LOADABLE_GAMES_LIST)\n",
      "SPIEL_SIMULTANEOUS_GAMES_LIST = [g for g in SPIEL_LOADABLE_GAMES_LIST if g.startswith('SPIEL_')]\n",
      "assert len(SPIEL_SIMULTANEOUS_GAMES_LIST) >= 14, len(SPIEL_SIMULTANEOUS_GAMES_LIST)\n",
      "SPIEL_MULTIPLAYER_GAMES_LIST = [(g, p) for g in SPIEL_LOADABLE_GAMES_LIST if g.startswith('SPIEL_')]\n",
      "assert len(SPIEL_MULTIPLAYER_GAMES_LIST) >= 35, len(SPIEL_MULTIPLAYER_GAMES_LIST)\n",
      "\n",
      "class GamesSimTest(parameterized.TestCase):\n",
      "\n",
      "    def apply_action(self, state, action):\n",
      "        if state.is_simultaneous_node():\n",
      "            assert isinstance(action, list)\n",
      "            state.apply_actions(action)\n",
      "        else:\n",
      "            state.apply_action(action)\n",
      "\n",
      "    def apply_action_test_clone(self, state, action):\n",
      "        \"\"\"Applies a action for a given action.\n",
      "\n",
      "        Parameters:\n",
      "            state.apply_action(state)\n",
      "        return self.apply\n",
      "\n",
      "=====================2347-GOLD LABELS=====================\n",
      "\n",
      "\"\"\"Python spiel example.\"\"\"\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "import pickle\n",
      "from absl import app\n",
      "from absl.testing import absltest\n",
      "from absl.testing import parameterized\n",
      "import numpy as np\n",
      "from open_spiel.python import games\n",
      "from open_spiel.python.algorithms import get_all_states\n",
      "from open_spiel.python.mfg import games as mfg_games\n",
      "import pyspiel\n",
      "from open_spiel.python.utils import file_utils\n",
      "MAX_ACTIONS_PER_GAME = 1000\n",
      "SPIEL_GAMES_LIST = pyspiel.registered_games()\n",
      "SPIEL_LOADABLE_GAMES_LIST = [g for g in SPIEL_GAMES_LIST if g.default_loadable]\n",
      "assert len(SPIEL_LOADABLE_GAMES_LIST) >= 38, len(SPIEL_LOADABLE_GAMES_LIST)\n",
      "SPIEL_SIMULTANEOUS_GAMES_LIST = [g for g in SPIEL_LOADABLE_GAMES_LIST if g.dynamics == pyspiel.GameType.Dynamics.SIMULTANEOUS]\n",
      "assert len(SPIEL_SIMULTANEOUS_GAMES_LIST) >= 14, len(SPIEL_SIMULTANEOUS_GAMES_LIST)\n",
      "SPIEL_MULTIPLAYER_GAMES_LIST = [(g, p) for g in SPIEL_LOADABLE_GAMES_LIST for p in range(max(g.min_num_players, 2), 1 + min(g.max_num_players, 6)) if g.max_num_players > 2 and g.max_num_players > g.min_num_players and (g.short_name!= 'tiny_hanabi') and (g.short_name!= 'universal_poker') and (g.short_name!='scotland_yard')]\n",
      "assert len(SPIEL_MULTIPLAYER_GAMES_LIST) >= 35, len(SPIEL_MULTIPLAYER_GAMES_LIST)\n",
      "\n",
      "class GamesSimTest(parameterized.Test\n",
      "\n",
      "=====================2347-SCORE=====================\n",
      "\n",
      "0.6738414986045694\n",
      "\n",
      "=====================2608-INPUT=====================\n",
      "\n",
      "\"\"\"\n",
      "Copyright 2018 Oliver Smith\n",
      "\n",
      "This file is part of pmbootstrap.\n",
      "\n",
      "pmbootstrap is free software: you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation, either version 3 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "pmbootstrap is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with pmbootstrap.  If not, see <http://www.gnu.org/licenses/>.\n",
      "\"\"\"\n",
      "import glob\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import pmb.helpers.mount\n",
      "import pmb.helpers.run\n",
      "import pmb.chroot\n",
      "\n",
      "def init(args):\n",
      "    if not os.path.isdir('/sys/module/loop'):\n",
      "        pmb.helpers.run.root(args, ['modprobe', 'loop'])\n",
      "    loopdevices = []\n",
      "    for loopdev in glob.glob('/dev/loop*'):\n",
      "        loopdevices.append(loopdev)\n",
      "    for loopdev in loopdevices:\n",
      "        pmb.helpers.mount.bind_blockdevice(args, loopdev, args.work + '/chroot_native/' + loopdev)\n",
      "\n",
      "def mount(args, img_path):\n",
      "    \"\"\"\n",
      "    :param img_path: Path to the img file inside native chroot.\n",
      "    \"\"\"\n",
      "    logging.debug('(native) mount'+ img_path +'(loop)')\n",
      "    init(args)\n",
      "    pmb.chroot.root(args, ['losetup', '-f', img_path])\n",
      "\n",
      "def device_by_back_file(args, back_file):\n",
      "    \"\"\"\n",
      "    Get the /dev/loopX device, that points to a specific image file.\n",
      "    \"\"\"\n",
      "    losetup_output = pmb.chroot.root(args, ['losetup', '--json', '--list'], return_stdout=True)\n",
      "    if not losetup_output:\n",
      "\n",
      "=====================2608-PREDICTION=====================\n",
      "\n",
      "\"\"\"\n",
      "Copyright 2018 Oliver Smith\n",
      "\n",
      "This file is part of pmbootstrap.\n",
      "\n",
      "pmbootstrap is free software: you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation, either version 3 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "pmbootstrap is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with pmbootstrap.  If not, see <http://www.gnu.org/licenses/>.\n",
      "\"\"\"\n",
      "import glob\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import pmb.helpers.mount\n",
      "import pmb.helpers.run\n",
      "import pmb.chroot\n",
      "\n",
      "def init(args):\n",
      "    if not os.path.isdir('/sys/module/loop'):\n",
      "        pmb.helpers.run.root(args, ['modprobe', 'loop'])\n",
      "    loopdevices = [loopdev for loopdev in glob.glob('/dev/loop*') if loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot(loopdev.chroot.root(args, ['losetup', '-f', img_path])\n",
      "\n",
      "def device_by_back_file(args, back_file):\n",
      "    \"\"\"\n",
      "    Get the /dev/loopX device, that points to a specific image file.\n",
      "    \"\"\"\n",
      "    losetup_output = pmb.chroot.root(args, ['losetup', '--json', '--list'], return_stdout=True)\n",
      "    if not losetup_output:\n",
      "        losetup_output.\n",
      "\n",
      "=====================2608-GOLD LABELS=====================\n",
      "\n",
      "\"\"\"\n",
      "Copyright 2018 Oliver Smith\n",
      "\n",
      "This file is part of pmbootstrap.\n",
      "\n",
      "pmbootstrap is free software: you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation, either version 3 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "pmbootstrap is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with pmbootstrap.  If not, see <http://www.gnu.org/licenses/>.\n",
      "\"\"\"\n",
      "import glob\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import pmb.helpers.mount\n",
      "import pmb.helpers.run\n",
      "import pmb.chroot\n",
      "\n",
      "def init(args):\n",
      "    if not os.path.isdir('/sys/module/loop'):\n",
      "        pmb.helpers.run.root(args, ['modprobe', 'loop'])\n",
      "    loopdevices = [loopdev for loopdev in glob.glob('/dev/loop*') if not os.path.isdir(loopdev)]\n",
      "    for loopdev in loopdevices:\n",
      "        pmb.helpers.mount.bind_blockdevice(args, loopdev, args.work + '/chroot_native/' + loopdev)\n",
      "\n",
      "def mount(args, img_path):\n",
      "    \"\"\"\n",
      "    :param img_path: Path to the img file inside native chroot.\n",
      "    \"\"\"\n",
      "    logging.debug('(native) mount'+ img_path +'(loop)')\n",
      "    init(args)\n",
      "    pmb.chroot.root(args, ['losetup', '-f', img_path])\n",
      "\n",
      "def device_by_back_file(args, back_file):\n",
      "    \"\"\"\n",
      "    Get the /dev/loopX device, that points to a specific image file.\n",
      "    \"\"\"\n",
      "    losetup_output = pmb.chroot.root(args, ['losetup', '--json', '--list'], return_stdout=True)\n",
      "    if not losetup_\n",
      "\n",
      "=====================2608-SCORE=====================\n",
      "\n",
      "0.6733067599190314\n"
     ]
    }
   ],
   "source": [
    "for idx in range(comp_total):\n",
    "    if comp_code_bleus[idx] == 1: continue\n",
    "    if comp_code_bleus[idx] >= 0.7: continue\n",
    "    if comp_code_bleus[idx] < 0.4: continue\n",
    "    print_split_line(f\"{idx}-input\")\n",
    "    print(comp_inputs[idx])\n",
    "    print_split_line(f\"{idx}-prediction\")\n",
    "    print(comp_preds[idx])\n",
    "    print_split_line(f\"{idx}-gold labels\")\n",
    "    print(comp_labels[idx])\n",
    "    print_split_line(f\"{idx}-score\")\n",
    "    print(comp_code_bleus[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d010ef0-3d3d-4cdf-8656-e79a53ce486c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
