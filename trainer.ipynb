{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset, load_from_disk, load_metric\n",
    "import pickle\n",
    "from utils.helper import read_py150k_code, read_file_to_string\n",
    "import regex as re\n",
    "from model.scratch_model import InRepPlusGAN\n",
    "\n",
    "#import model file\n",
    "#import \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plbart init\n",
    "#tokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-python-en_XX\", src_lang=\"python\", tgt_lang=\"python\" )\n",
    "#model = PLBartForConditionalGeneration.from_pretrained(\"uclanlp/plbart-python-en_XX\")\n",
    "train_plbart_dataset = load_from_disk('datasets/plbart_train.hf')\n",
    "test_plbart_dataset = load_from_disk('datasets/plbart_test.hf')\n",
    "train_plbart_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_plbart_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "#codet5 init\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base')\n",
    "train_codet5_dataset = load_from_disk('datasets/plbart_train.hf')\n",
    "test_codet5_dataset = load_from_disk('datasets/plbart_test.hf')\n",
    "\n",
    "train_codet5_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_codet5_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample and save data subset\n",
    "\n",
    "# sample_plbart = train_plbart_dataset.shuffle(seed=34).select(range(1000))\n",
    "# sample_codet5 = train_codet5_dataset.shuffle(seed=34).select(range(1000))\n",
    "# sample_plbart[0]\n",
    "# sample_plbart.save_to_disk(\"datasets/plbart_sample.hf\")\n",
    "# sample_codet5.save_to_disk(\"datasets/codet5_sample.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    #redefine this loss this is an example\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0]))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Downloading builder script: 4.21kB [00:00, 1.50MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(eval_pred): # this part prob wont work, parameter should be removed from trainer probably\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/uclanlp/plbart-multi_task-python/resolve/main/config.json not found in cache or force_download set to True, downloading to /soe/swade1/.cache/huggingface/transformers/tmpv2ig_30q\n",
      "Downloading: 100%|██████████████████████████████| 811/811 [00:00<00:00, 429kB/s]\n",
      "storing https://huggingface.co/uclanlp/plbart-multi_task-python/resolve/main/config.json in cache at /soe/swade1/.cache/huggingface/transformers/f7b387cf7785602ccd0994f177f6d66cf7a940399d7751d145c4c0e979cd6ec8.a2d21d48f57f004fa4d7bde6ae303fbc9ec8fcddc26626f1bc72809e1b5515e4\n",
      "creating metadata file for /soe/swade1/.cache/huggingface/transformers/f7b387cf7785602ccd0994f177f6d66cf7a940399d7751d145c4c0e979cd6ec8.a2d21d48f57f004fa4d7bde6ae303fbc9ec8fcddc26626f1bc72809e1b5515e4\n",
      "loading configuration file https://huggingface.co/uclanlp/plbart-multi_task-python/resolve/main/config.json from cache at /soe/swade1/.cache/huggingface/transformers/f7b387cf7785602ccd0994f177f6d66cf7a940399d7751d145c4c0e979cd6ec8.a2d21d48f57f004fa4d7bde6ae303fbc9ec8fcddc26626f1bc72809e1b5515e4\n",
      "Model config PLBartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"PLBartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"plbart\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50008\n",
      "}\n",
      "\n",
      "https://huggingface.co/uclanlp/plbart-multi_task-python/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /soe/swade1/.cache/huggingface/transformers/tmpgp34cg8q\n",
      "Downloading: 100%|███████████████████████████| 531M/531M [00:07<00:00, 71.2MB/s]\n",
      "storing https://huggingface.co/uclanlp/plbart-multi_task-python/resolve/main/pytorch_model.bin in cache at /soe/swade1/.cache/huggingface/transformers/a6c1a417d9ecdadba0b3dd2152c200d79226c62bc8c2d81f4cc929f13843ae0d.0d0232267d270f46f512a2b4ca7e40fe59714ef85df037b1c6114b03c491d4b1\n",
      "creating metadata file for /soe/swade1/.cache/huggingface/transformers/a6c1a417d9ecdadba0b3dd2152c200d79226c62bc8c2d81f4cc929f13843ae0d.0d0232267d270f46f512a2b4ca7e40fe59714ef85df037b1c6114b03c491d4b1\n",
      "loading weights file https://huggingface.co/uclanlp/plbart-multi_task-python/resolve/main/pytorch_model.bin from cache at /soe/swade1/.cache/huggingface/transformers/a6c1a417d9ecdadba0b3dd2152c200d79226c62bc8c2d81f4cc929f13843ae0d.0d0232267d270f46f512a2b4ca7e40fe59714ef85df037b1c6114b03c491d4b1\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'uclanlp/plbart-multi_task-python' at '/soe/swade1/.cache/huggingface/transformers/a6c1a417d9ecdadba0b3dd2152c200d79226c62bc8c2d81f4cc929f13843ae0d.0d0232267d270f46f512a2b4ca7e40fe59714ef85df037b1c6114b03c491d4b1'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m                     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1440\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /opt/conda/conda-bld/pytorch_1579022030672/work/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /opt/conda/conda-bld/pytorch_1579022030672/work/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7f6f9cc60627 in /data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7f6f9eaf7cbb in /data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7f6f9eaf8ed4 in /data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #3: <unknown function> + 0x69e366 (0x7f6fa2e98366 in /data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #4: <unknown function> + 0x26b876 (0x7f6fa2a65876 in /data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #5: _PyMethodDef_RawFastCallDict + 0x24c (0x55e16f11c71c in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #6: _PyObject_FastCallDict + 0x6e (0x55e16f0ecf5e in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #7: <unknown function> + 0x12f041 (0x55e16f102041 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #8: PyObject_Call + 0x66 (0x55e16f0ed7b6 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #9: <unknown function> + 0xc239e (0x55e16f09539e in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #10: _PyObject_FastCallKeywords + 0x54c (0x55e16f152c7c in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #11: <unknown function> + 0x1802d1 (0x55e16f1532d1 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #12: _PyEval_EvalFrameDefault + 0x48a2 (0x55e16f19a602 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #13: _PyEval_EvalCodeWithName + 0x79e (0x55e16f0ec0de in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #14: _PyObject_FastCallDict + 0x312 (0x55e16f0ed202 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #15: <unknown function> + 0x186bef (0x55e16f159bef in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #16: _PyObject_FastCallKeywords + 0x54c (0x55e16f152c7c in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x47e5 (0x55e16f19a545 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #18: _PyEval_EvalCodeWithName + 0x273 (0x55e16f0ebbb3 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #19: _PyFunction_FastCallKeywords + 0x693 (0x55e16f10c223 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #20: <unknown function> + 0x1800c5 (0x55e16f1530c5 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #21: _PyEval_EvalFrameDefault + 0x145c (0x55e16f1971bc in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #22: _PyEval_EvalCodeWithName + 0x273 (0x55e16f0ebbb3 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #23: _PyFunction_FastCallKeywords + 0x693 (0x55e16f10c223 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #24: <unknown function> + 0x1800c5 (0x55e16f1530c5 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x48a2 (0x55e16f19a602 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #26: _PyEval_EvalCodeWithName + 0x79e (0x55e16f0ec0de in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #27: _PyObject_FastCallDict + 0x312 (0x55e16f0ed202 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #28: <unknown function> + 0x186bef (0x55e16f159bef in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #29: _PyObject_FastCallKeywords + 0x54c (0x55e16f152c7c in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #30: _PyEval_EvalFrameDefault + 0x47e5 (0x55e16f19a545 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #31: _PyEval_EvalCodeWithName + 0x273 (0x55e16f0ebbb3 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #32: <unknown function> + 0x1d751e (0x55e16f1aa51e in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #33: _PyMethodDef_RawFastCallKeywords + 0xe9 (0x55e16f11c959 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x44f8 (0x55e16f19a258 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #35: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x19f1 (0x55e16f197751 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #37: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #38: _PyEval_EvalFrameDefault + 0x19f1 (0x55e16f197751 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #39: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #40: _PyMethodDescr_FastCallKeywords + 0xdb (0x55e16f15246b in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #41: <unknown function> + 0x1801ae (0x55e16f1531ae in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x621 (0x55e16f196381 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #43: _PyFunction_FastCallKeywords + 0x187 (0x55e16f10bd17 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #44: _PyEval_EvalFrameDefault + 0x3f5 (0x55e16f196155 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #45: _PyFunction_FastCallKeywords + 0x187 (0x55e16f10bd17 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #46: <unknown function> + 0x1800c5 (0x55e16f1530c5 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #47: _PyEval_EvalFrameDefault + 0x621 (0x55e16f196381 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #48: _PyEval_EvalCodeWithName + 0x273 (0x55e16f0ebbb3 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #49: _PyObject_FastCallDict + 0x5be (0x55e16f0ed4ae in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #50: <unknown function> + 0x12f041 (0x55e16f102041 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #51: PyObject_Call + 0x66 (0x55e16f0ed7b6 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #52: _PyEval_EvalFrameDefault + 0x1d0d (0x55e16f197a6d in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #53: _PyEval_EvalCodeWithName + 0x79e (0x55e16f0ec0de in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #54: _PyFunction_FastCallKeywords + 0x693 (0x55e16f10c223 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #55: <unknown function> + 0x1800c5 (0x55e16f1530c5 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #56: _PyEval_EvalFrameDefault + 0x145c (0x55e16f1971bc in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #57: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #58: _PyEval_EvalFrameDefault + 0x19f1 (0x55e16f197751 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #59: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #60: _PyEval_EvalFrameDefault + 0x19f1 (0x55e16f197751 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #61: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #62: _PyEval_EvalFrameDefault + 0x19f1 (0x55e16f197751 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\nframe #63: <unknown function> + 0x17f0b4 (0x55e16f1520b4 in /data/users/swade/Miniconda3/envs/NLP243/bin/python)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m                                 raise OSError(\n",
      "\u001b[0;32m/data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57784/1911942001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInRepPlusGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/users/team2_capstone/code-style-probing/model/scratch_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInRepPlusGAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLBartForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uclanlp/plbart-multi_task-python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users/swade/Miniconda3/envs/NLP243/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m                         raise OSError(\n\u001b[0;32m-> 1453\u001b[0;31m                             \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m                             \u001b[0;34mf\"at '{resolved_archive_file}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                             \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'uclanlp/plbart-multi_task-python' at '/soe/swade1/.cache/huggingface/transformers/a6c1a417d9ecdadba0b3dd2152c200d79226c62bc8c2d81f4cc929f13843ae0d.0d0232267d270f46f512a2b4ca7e40fe59714ef85df037b1c6114b03c491d4b1'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."
     ]
    }
   ],
   "source": [
    "model = InRepPlusGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57784/1662093089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer = CustomTrainer(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac9e7467ab50678fb25b34fbfebaa7dd0935f663e602be01974fdf6c9ce75ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
